['# Clinical Implementation and ‚ÄúMedical AI‚Äù\n', '\n', '![](HTML%20import/Attachments/image10.png)  \n', '[https://a16z.com/commercializing-ai-in-healthcare-the-jobs-to-be-done/](https://www.google.com/url?q=https://a16z.com/commercializing-ai-in-healthcare-the-jobs-to-be-done/&sa=D&source=editors&ust=1717021441026884&usg=AOvVaw1VSGIDHphpLomFLAAVHZWj)\xa0\n', '\n', '![](HTML%20import/Attachments/image112.png)\n', '\n', '![](HTML%20import/Attachments/image79.png)\n', '\n', 'European Hospital Survey (Digital) THE FUTURE OF DIGITAL HEALTH IN EUROPEAN HOSPITALS  \n', '[https://www.lek.com/insights/hea/eu/ei/european-hospital-survey-digital](https://www.google.com/url?q=https://www.lek.com/insights/hea/eu/ei/european-hospital-survey-digital&sa=D&source=editors&ust=1717021441027389&usg=AOvVaw1HhuD1UiN-BqCHBIAwkvH2)\xa0\n', '\n', '![](HTML%20import/Attachments/image165.png)\n', '\n', '[Bayesian Health](https://www.google.com/url?q=https://www.linkedin.com/company/bayesian-health/&sa=D&source=editors&ust=1717021441027678&usg=AOvVaw2P5XJXhsnnv_WbjabUKMa_)\xa0collaborated with [Oliver Wyman](https://www.google.com/url?q=https://www.linkedin.com/company/oliver-wyman/&sa=D&source=editors&ust=1717021441027821&usg=AOvVaw3rc5nD5vj5Tv3Gxk-jWIiy)\xa0to create 2 visuals that should be on every Health executives desk as they contemplate AI platforms and solutions. (Suchi Saria)\n', '\n', '## Open APIs\n', '\n', '$QUOTETOBEREPLACED$ *"Starting*******January 1, 2021*******, Medicare Advantage, Medicaid, CHIP and plans on the federal Exchanges (that begin in 2021) will be required to support a standardized API (HL7 FHIR version 4.0.1) that allows patients to access claims and various information related to their medical encounter, such as cost or clinical information, through a third-party app of their choice. The API could also be used to integrate a health plan\'s information to a patient\'s EHR." -*[Mobihealth](https://www.google.com/url?q=https://www.mobihealthnews.com/news/hhs-final-interoperability-rules-standardize-apis-patient-health-data-access-through-apps&sa=D&source=editors&ust=1717021441028234&usg=AOvVaw1BvFm9uaUKTqC6vUAHq8z8)\n', '\n', '### EHR\n', '\n', '[#HIMSS24 Update: AI/ Ambient technology for clinicians](https://www.google.com/url?q=https://www.linkedin.com/posts/junaidbajwa_himss24-how-epic-is-building-out-ai-ambient-activity-7174172519547949057-silD?utm_source%3Dshare%26utm_medium%3Dmember_desktop&sa=D&source=editors&ust=1717021441028595&usg=AOvVaw20WPfwBoIcjqOv1vaFkpLm)\n', '\n', '1. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Epic‚Äôs integration of AI & ambient tech into EHRs üßëüèΩ\u200düíªis a potential game-changer for clinical teams.\n', '2. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ 55hgj\n', '\n', '1. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Testonesto\n', '2. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ubunubu\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[#HIMSS24 Update: AI/ Ambient technology for clinicians](https://www.google.com/url?q=https://www.linkedin.com/posts/junaidbajwa_himss24-how-epic-is-building-out-ai-ambient-activity-7174172519547949057-silD?utm_source%3Dshare%26utm_medium%3Dmember_desktop&sa=D&source=editors&ust=1717021441029091&usg=AOvVaw0xmh7YojKNijm4xI-ct8qn)\n', '\n', '$QUOTETOBEREPLACED$ Epic‚Äôs integration of AI & ambient tech into EHRs üßëüèΩ\u200düíªis a potential game-changer for clinical teams.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ With >60 use cases in dev, these innovations could release time to care so that clinical teams can focus more on the patients they serve\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ **I'm impressed with Epic's work on integrating GPT-4 into clinical workflows. Already >150K clinical notes written and millions of patient messages drafted by AI in just one year, with incredibly high satisfaction. Proud to collaborate with them on this.**\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image105.png)\n', '\n', '[Apr 3, 2024](https://www.google.com/url?q=https://www.fiercehealthcare.com/ai-and-machine-learning/epic-plans-launch-ai-validation-software-healthcare-organizations-test&sa=D&source=editors&ust=1717021441029658&usg=AOvVaw3UNz_yZTBmNPntGqC3ER_R): Epic plans to launch AI validation software for healthcare organizations to test, monitor models\n', '\n', '$QUOTETOBEREPLACED$ EHR giant Epic plans to release an AI validation software suite to enable healthcare organizations to evaluate AI models at the local level and monitor those systems over time, Seth Hain, Epic senior vice president of R&D, said in an exclusive interview.\n', '\n', '### FHIR\n', '\n', 'Organizations new to FHIR often assume all FHIR decisions are technical.\n', '\n', 'They‚Äôre not. Implementation is technical. But in most cases a business decision has to be made first.\n', '\n', 'If your developers have full responsibility for any of the below, you have a problem.\n', '\n', '1. Choosing FHIR\n', '\n', 'Exposing data via a FHIR API is often a regulatory or legal requirement.\n', '\n', '- Not a technical decision: https://www.healthit.gov/topic/oncs-cures-act-final-rule\n', '\n', '2. Which FHIR version to use\n', '\n', 'The Cures Act in the US mandates version R4. Other countries and regions have different requirements.\n', '\n', '- Not a technical decision: [https://www.healthit.gov/sites/default/files/page2/2020-03/APICertificationCriterion.pdf](https://www.google.com/url?q=https://www.healthit.gov/sites/default/files/page2/2020-03/APICertificationCriterion.pdf&sa=D&source=editors&ust=1717021441030406&usg=AOvVaw27WDZrcIk5Hg-aj_XsN09t)\xa0\n', '\n', '3. Implementation Guides and Profiles\n', '\n', 'There are lots of IGs out there. You can even build your own. But in many jurisdictions and fields, specific IGs and Profiles are mandated.\n', '\n', '- Not a technical decision: [https://build.fhir.org/ig/HL7/US-Core/](https://www.google.com/url?q=https://build.fhir.org/ig/HL7/US-Core/&sa=D&source=editors&ust=1717021441030756&usg=AOvVaw3yHCD-aqkdMMNljSkoE5Q5)\xa0\n', '\n', '4. Which FHIR resources to use\n', '\n', 'There are 140+ resources in FHIR. But it‚Äôs not a ‚Äúpick n mix.‚Äù Their use cases are well defined and documented.\n', '\n', '- Not a technical decision. Example: [https://hl7.org/fhir/R4/financial-module.html](https://www.google.com/url?q=https://hl7.org/fhir/R4/financial-module.html&sa=D&source=editors&ust=1717021441031065&usg=AOvVaw10Vak8RE2zy5zI3mU5lkK9)\xa0\n', '\n', '5. Data Retention and Privacy\n', '\n', 'PI and PII data should not be retained once their use case is fulfilled. GDPR is the most well known example of where this is legally enforced. ‚ÄòUse case‚Äô in the medical context varies.\n', '\n', '- Not a technical decision.\n', '\n', '6. FHIR Architecture ‚Äî fa√ßade, hybrid or repository\n', '\n', 'The outlier in the list. Once the decision to share data using FHIR is made, the next decision is how to do it.\n', '\n', '- This is a technical AND a business decision: https://lnkd.in/dmCKb7a2\n', '\n', '[Dugas et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00994-6&sa=D&source=editors&ust=1717021441031554&usg=AOvVaw0qkl59iRbic0B5uhm_WrDr): ‚ÄúNext-generation study databases require FAIR, EHR-integrated, and scalable Electronic Data Capture for medical documentation and decision support‚Äù\n', '\n', '## Care Delivery Models\n', '\n', '[Ilan et al. (2023)](https://www.google.com/url?q=https://doi.org/10.3389/fdgth.2020.569178&sa=D&source=editors&ust=1717021441031820&usg=AOvVaw0aqbhZ_gXpCQ0lYT7kcBRf): ‚ÄúSecond-Generation[[a]](#cmnt1)\xa0Digital Health Platforms: Placing the Patient at the Center and Focusing on Clinical Outcomes‚Äù\n', '\n', "$QUOTETOBEREPLACED$ This paper reviews some of the achievements of first-generation AI systems, and the barriers facing their implementation into medical practice. The development of second-generation AI systems is discussed with a focus on overcoming some of these obstacles. ****Second-generation systems****\xa0are aimed at****focusing on a single subject****\xa0and on improving patients' clinical outcomes. A personalized closed-loop system designed to improve end-organ function and the patient's response to chronic therapies is presented. The system introduces a platform which implements a ****personalized therapeutic regimen****\xa0and introduces****quantifiable individualized-variability patterns****into its algorithm. The platform is designed to achieve a clinically meaningful endpoint by ensuring that chronic therapies will have sustainable effect while overcoming compensatory mechanisms associated with disease progression and drug resistance.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The AI ‚Äúquadruple aim‚Äù of improving care, improving overall population health, reducing healthcare costs, and improving the work life of healthcare providers, is still an unreachable objective for the majority of first-generation systems ([8](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B8&sa=D&source=editors&ust=1717021441032469&usg=AOvVaw0gL7R74AXKomCaUpajPy8w)). These platforms were designed to promote the 4P model of medicine: Predictive, Preventive, Personalized, and Participatory, providing patient autonomy ([9](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B9&sa=D&source=editors&ust=1717021441032616&usg=AOvVaw2M9VfOpS8C14WVMuSP7j12)). Most algorithms do not inevitably result in better outcomes ([10](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B10&sa=D&source=editors&ust=1717021441032742&usg=AOvVaw1Nntt-BsE3ge1TlnxYDvQW)). The term **"AI chasm"**\xa0is sometimes used, and this term suggests that the improved accuracy sought by most platforms ****does not necessarily represent better clinical efficacy****\xa0([15](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B15&sa=D&source=editors&ust=1717021441032934&usg=AOvVaw3zEwAfcpzRRDaZZjVPjbiZ)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Precision medicine****-based AI is aimed at optimizing diagnostic pathways, therapeutic interventions, and prognoses using large datasets comprising individual genes, other phenotypic parameters, and environmental measures. The algorithms are largely designed to tailor their outputs on an individual basis ([30](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B30&sa=D&source=editors&ust=1717021441033180&usg=AOvVaw1WpaORnR89TkIAobodMRFn)).\n', '\n', '$QUOTETOBEREPLACED$ **Second-Generation Systems Provide the "5th P": Focus on Improving the Clinical Condition of a Single Patient**\xa0Healthcare applications of AI research have received extensive investments in recent last year\'s ([76](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B76&sa=D&source=editors&ust=1717021441033404&usg=AOvVaw2P7nNeBos77nedatAa74d4), [150](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B150&sa=D&source=editors&ust=1717021441033530&usg=AOvVaw2LUjFr-fgwU_yDTUcKGVZx)). However, the stereotypical ‚ÄúSilicon Valley mindset‚Äù calling for engineers to **"move fast and break things" is clearly inappropriate for applying AI to healthcare**\xa0([143](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B143&sa=D&source=editors&ust=1717021441033685&usg=AOvVaw1INPrQn5JJXf1vy_JY3ChQ), [151](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B151&sa=D&source=editors&ust=1717021441033814&usg=AOvVaw2srN-kAOvH8Te2QFXMHPZy)). Second-generation AI systems are anticipated to add the ‚Äú5th P:‚Äù Progress,****an improvement of a clinically meaningful endpoint in a subject-tailored manner****. Rather than analyzing data for assisting in diagnosis, prediction, or tailoring therapy, second-generation platforms focus on improving biological processes. Several fundamental changes needed for achievement of the ‚Äú5th P‚Äù are described below.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Controlling for the Dynamic Nature of Host and Disease****Biological systems are dynamic by nature. Subjects, disease processes, and responses to therapies continually change. Chronic diseases move along a ****dynamic trajectory****, creating a challenge of ****unpredictable progression****, which is often disregarded by first-generation AI ([30](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B30&sa=D&source=editors&ust=1717021441034197&usg=AOvVaw1Lh76quiBoA_sKCJBUSO-C)). The internal and external parameters that determine the progression of chronic disease and host response vary constantly. These ****require constant adaptation of therapeutic regimens****\xa0([154](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B154&sa=D&source=editors&ust=1717021441034359&usg=AOvVaw1tkdC5sjVCdEAh4tW9h-yk)). Furthermore, many therapies do not show efficacy or loss of response until considerable time has passed. Subjects may remain essentially untreated for several months in cases where reaching an effect requires several attempts. For many drugs, secondary loss of response occurs following an initial benefit ([155](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B155&sa=D&source=editors&ust=1717021441034492&usg=AOvVaw2UC7vVAtW3ZPmFPXg_gN4T), [156](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B156&sa=D&source=editors&ust=1717021441034620&usg=AOvVaw0IAtEcvnq2X551ZPoZsXGk)). Second-generation AI systems which are designed to improve response to therapies, must therefore ****facilitate analyzing inter-subject and intra-subject variabilities in response to therapies over time****\xa0([157](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B157&sa=D&source=editors&ust=1717021441034777&usg=AOvVaw2rMzkS-5yNIjhmhuvyUpTp)‚Äì[160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441034896&usg=AOvVaw2MTyE9ZyMpQNZbMyJ0ukL7)). The dynamicity of biological systems requires algorithms to implement continual, periodic system-wide updates and identification of performance deficits ****over time in an individual subject****\xa0([10](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B10&sa=D&source=editors&ust=1717021441035045&usg=AOvVaw3bu2BwARLtFr73wyGvzFKr)).\n', '\n', '$QUOTETOBEREPLACED$ ****Overcoming Big Data Challenges by Implementing an n = 1 Concept****Second-generation AI systems must therefore ****focus on a single patient****\xa0as the epicenter of an algorithm and to adapt their output in a timely manner. They are required to ****continually respond to feedback in an individualized manner****while generating an insightful database that can be used to further improve the algorithm for other patients.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Generalizing from large datasets to a single patient is unsuccessful in many cases, due to a large heterogeneity among subjects, and to ongoing individualized changes in disease triggers and host responses. The ******n**********= 1 concept can be implemented into second-generation platforms by focusing on dynamicity of disease and response to intervention in a single patient.****\xa0The multiple host, disease, and environment-related variables learned from big datasets can be implemented into a single subject-based algorithm that analyzes input from, and generates output to, that subject ([158](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B158&sa=D&source=editors&ust=1717021441035516&usg=AOvVaw0RCPL9Ta5qqXhwdVGb-WtD)‚Äì[160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441035672&usg=AOvVaw0JS5J4dml54Q3Lk-zfEOMj)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ In addition to the above four requirements for second-generation platforms, several additional parameters must be considered. These platforms should ****improve patient care, cost-effectiveness, and workflow****\xa0for everyday clinical practice in terms of decision making and the physicians' workload ([1](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B1&sa=D&source=editors&ust=1717021441035927&usg=AOvVaw0AGZ3nt_Qb6tyaijJpJfmC), [161](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B161&sa=D&source=editors&ust=1717021441036047&usg=AOvVaw3L7MQS6EgB8Ctpn5-axK0y)). They must use metrics which are clinically important and intuitive to clinicians ([10](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B10&sa=D&source=editors&ust=1717021441036167&usg=AOvVaw2cTMDozsNof-WOYl6SBDjW)). Reducing bias, using explainable approaches, and using common statistical methods are also desirable, as they improve transparency and trust, and encourage adoption by clinicians ([10](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B10&sa=D&source=editors&ust=1717021441036297&usg=AOvVaw0FIJ1W7nMs-b5lTYCWXVRD), [162](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B162&sa=D&source=editors&ust=1717021441036414&usg=AOvVaw00mj_5qsrA8gsru-o3xE6Q)‚Äì[164](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B164&sa=D&source=editors&ust=1717021441036573&usg=AOvVaw3NTd-Uw_lgw9Zop2GZBaGb)).\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Variability should be viewed ****as a property of causal processes that contribute to proper functions of systems****([158](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B158&sa=D&source=editors&ust=1717021441036836&usg=AOvVaw1_fa_loTaOJH2jUL3VvAUs), [159](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B159&sa=D&source=editors&ust=1717021441036966&usg=AOvVaw198PNzUUxTPf3Cw-n8FmWv), [196](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B196&sa=D&source=editors&ust=1717021441037084&usg=AOvVaw01_3YJoM-_O04fQQXxSR7s)). Keeping **"steadiness" is not a mandatory objective**of physiologic control under all conditions. It can prohibit normal adaptation to ongoing changes ([158](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B158&sa=D&source=editors&ust=1717021441037239&usg=AOvVaw3IgnRNXnWdI8C4Tyg-wXXe)‚Äì[160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441037363&usg=AOvVaw2NtdQEMHODLAfiffwOTSDe), [194](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B194&sa=D&source=editors&ust=1717021441037482&usg=AOvVaw0GG6RzkssKCNQoT9ZgJ7c0), [195](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B195&sa=D&source=editors&ust=1717021441037601&usg=AOvVaw3KAfHf0-sPSpALsUO_UJ4j)). Non-linear systems can function far from equilibrium, and their dynamicity is part of the plasticity required for optimizing their function ([203](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B203&sa=D&source=editors&ust=1717021441037733&usg=AOvVaw1qczqZtWSOLbBBW-FmrCol), [215](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B215&sa=D&source=editors&ust=1717021441037872&usg=AOvVaw35CWgaDxmzGGixVEjxcKR0)‚Äì[217](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B217&sa=D&source=editors&ust=1717021441037990&usg=AOvVaw1z0zahxAPN6veBHCFETaFA)). ****Biological variability is desirable****\xa0for the evolutionary dynamics that contribute to stability through adaptation ([153](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B153&sa=D&source=editors&ust=1717021441038138&usg=AOvVaw2_TQjPWsUU8wkUu_IHE09l), [160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441038269&usg=AOvVaw2a5oJIqVobNSdl2lV1AWa0), [180](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B180&sa=D&source=editors&ust=1717021441038398&usg=AOvVaw0DJiTC0oFOy5eAGwH-hQUf), [218](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B218&sa=D&source=editors&ust=1717021441038556&usg=AOvVaw3kAaH6fdB1zm_eRy0k4vyp), [219](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B219&sa=D&source=editors&ust=1717021441038678&usg=AOvVaw0A61kCXQSuirPYKvbDF-pl)). It should be regarded as a method used for generating ‚Äúnew order,‚Äù assisting in overcoming errors in assembly and functions ([166](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B166&sa=D&source=editors&ust=1717021441038805&usg=AOvVaw1hYK6D1GzEeuiGm_vZ37uk), [220](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B220&sa=D&source=editors&ust=1717021441038925&usg=AOvVaw0wHZnOUwrxq3Svz8OEMGA3)). For stochastic cellular processes such as single-cell responses, randomness-based modeling improves deterministic models ([221](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B221&sa=D&source=editors&ust=1717021441039045&usg=AOvVaw1BNA2IR_BNnCAKnvcUjwKz)‚Äì[223](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B223&sa=D&source=editors&ust=1717021441039159&usg=AOvVaw0tj3lidnWN2kJBYo5XISL2)). Additional examples include gatherings of cells within heterogeneous spaces and random control of associations of biomolecules, which lead to an array of synchronized functions, including transcription, translation, ribosome biogenesis, chromosome replication, and metabolism ([160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441039305&usg=AOvVaw3U0BvD4suKkDZsmRWQutzV), [196](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B196&sa=D&source=editors&ust=1717021441039427&usg=AOvVaw0N6XSgJw0LNvqNkFaFMh5Y), [224](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B224&sa=D&source=editors&ust=1717021441039548&usg=AOvVaw0qfl80T-l1_IlYrJy2J90h)‚Äì[226](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B226&sa=D&source=editors&ust=1717021441039665&usg=AOvVaw3w9B-m1AXhBtspR8yBWQKP)). The dynamic instability of microtubules likewise demonstrates that variability is required for their normal structure and function ([196](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B196&sa=D&source=editors&ust=1717021441039806&usg=AOvVaw3yX0wTjjsEMghxe0GIi1iP), [227](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B227&sa=D&source=editors&ust=1717021441039922&usg=AOvVaw1X8uGRBH4inyV8CUSUrH9V)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ It has been proposed that the****type and magnitude of variability in a biological system should ideally be personalized****([158](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B158&sa=D&source=editors&ust=1717021441040210&usg=AOvVaw3zVHAHvOon_V8tofWDY0CG), [159](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B159&sa=D&source=editors&ust=1717021441040343&usg=AOvVaw3vVhELle076Ck3YPUOPjb3)). It has been suggested that continuously quantifying individualized variability patterns and implementing them into algorithms ****enables personalized and dynamic tailoring of therapeutic regimens****. Patterns of variability can be quantified from genetic profiling, immune testing, chronotherapy measures, heart rate variability, and additional host and disease-related variability signatures ([162](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B162&sa=D&source=editors&ust=1717021441040505&usg=AOvVaw0wWkuieeZ9ZoIrst5DJHc5), [163](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B163&sa=D&source=editors&ust=1717021441040622&usg=AOvVaw11UqNRUcHGjyJlfSS8giJX), [170](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B170&sa=D&source=editors&ust=1717021441040758&usg=AOvVaw2VK0yGHxG1ti3n7-abnqNo), [171](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B171&sa=D&source=editors&ust=1717021441040886&usg=AOvVaw1ts79cF9x4sUv8qwn9yCWV)). This type of ****improved precision medicine****\xa0is compatible with the principles according to which diseases and hosts behave. Rather than imposing a rigid artificial regimen, algorithms continuously adapt to individual changes in disease and the patient's responses to interventions ([158](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B158&sa=D&source=editors&ust=1717021441041039&usg=AOvVaw1T2PBs6F8LV8zXHqZ8OoR-)‚Äì[160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441041156&usg=AOvVaw1q55KzX8-JbRbYD0QLui2m), [166](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B166&sa=D&source=editors&ust=1717021441041287&usg=AOvVaw0WB021TBv16j59hroCqJEI)). Therefore, a patient-tailored approach based on individualized variability patterns implemented into AI systems is expected to improve the efficiency and sustainability of the beneficial effects of chronic therapies.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image76.png)\n', '\n', '$QUOTETOBEREPLACED$ [Figure 1](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23F1&sa=D&source=editors&ust=1717021441041565&usg=AOvVaw1Ho33IuerKVHB9irUVA_oH)\xa0shows a schematic presentation of a closed-loop algorithm where a single subject with a chronic disease is at the focus. A feedback loop is responsive to the effect of therapy on a clinically meaningful endpoint. The algorithm aims at this endpoint and adapts itself in a dynamic manner. The AI platform then quantifies personalized variability patterns relevant to the disease, host response, and environment-related variables. It combines these variables into a dynamic therapeutic regimen. In parallel, the algorithm generates its own insightful database which evolves from analyzing its outputs on organ function ([160](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B160&sa=D&source=editors&ust=1717021441041721&usg=AOvVaw1g3DEasSgeszTMAolZlQFa), [166](https://www.google.com/url?q=https://www.frontiersin.org/articles/10.3389/fdgth.2020.569178/full%23B166&sa=D&source=editors&ust=1717021441041839&usg=AOvVaw1cEpAcyRpnUIVBFlLFLF_v)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Trinkley et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1186/s13012-024-01346-y&sa=D&source=editors&ust=1717021441042142&usg=AOvVaw08ocmJlTOzqRDYbIbpKnUm): ‚ÄúLeveraging artificial intelligence to advance implementation science: potential opportunities and cautions‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The field of implementation science was developed to **==**==address the significant time delay between establishing an evidence-based practice and its widespread use==**==**. Although implementation science has contributed much toward bridging this gap, the **==**==evidence-to-practice chasm remains a challenge==**==**. There are some key aspects of implementation science in which advances are needed, including speed and assessing causality and mechanisms. The increasing availability of artificial intelligence applications offers opportunities to help address specific issues faced by the field of implementation science and expand its methods.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Artificial intelligence holds **promise to advance implementation science methods ("why")**\xa0and **accelerate its goals of closing the evidence-to-practice gap ("purpose")**. However, evaluation of artificial intelligence‚Äôs potential unintended consequences must be considered and proactively monitored. Given the technical nature of artificial intelligence applications as well as their potential impact on the field, transdisciplinary collaboration is needed and may suggest the need for a subset of implementation scientists cross-trained in both fields to ensure artificial intelligence is used optimally and ethically.\n', '\n', '[Wachter et al. (2018)](https://www.google.com/url?q=https://doi.org/10.1001/jama.2018.5605&sa=D&source=editors&ust=1717021441042732&usg=AOvVaw2soUp4Eri6LxQSBJqew1HZ): ‚ÄúResolving the Productivity Paradox of Health Information Technology‚Äù\n', '\n', '$QUOTETOBEREPLACED$ During the past decade, the US health care system has gone digital. In 2008, fewer than 1 in 10 US hospitals had an electronic health record (EHR) system; today, fewer than 1 in 10 does not. The increase in use of an EHR system in ambulatory practices has been similarly steep.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Although the evidence that health care digitization has led to improvements in quality and safety is generally positive,1 these have been context-dependent improvements and relatively small. Moreover, rates of physician self-reported burnout are high, partly because little useful intelligence is delivered back to physicians despite all their time spent performing data entry. In addition, the presence of the computer often separates the physician from the patient, rather than enhancing communication.\n', '\n', '### Virtual Clinics\n', '\n', '[Li et al. (2020](https://www.google.com/url?q=https://doi.org/10.1016/j.preteyeres.2020.100900&sa=D&source=editors&ust=1717021441043176&usg=AOvVaw3TIlNjx5YdbdSWgcuLzzJe)): ‚ÄúDigital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Virtual clinics are ****increasingly adopted in the UK****\xa0to facilitate remote glaucoma management. Virtual clinics use electronic patient records****collected by technicians and consultants****\xa0in community clinics or from a mobile clinic facility, and then delivers feedback on the decisions made by ophthalmologists for patients being examined remotely ([Wright and Diamond, 2015](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib338&sa=D&source=editors&ust=1717021441043571&usg=AOvVaw2hfmoL7LmbU3UknXJQeLqv)). As the****largest tele-glaucoma study to date****, this program reported an 87% level of agreement on disease stratification status between optometrists and specialists. In the UK, around 50% of the Hospital Eye Service units are using glaucoma virtual clinics ([Court and Austin, 2015](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib67&sa=D&source=editors&ust=1717021441043784&usg=AOvVaw3_tfs1ZGoyxDr9CjZaIRYW); [Kotecha et al., 2015](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib163&sa=D&source=editors&ust=1717021441043963&usg=AOvVaw2m1gkINeK56EVoUwtLzbeQ)), and their rate efficiency, patient safety and acceptability have been shown to be at least equivalent to that of standard care ([Gunn et al., 2018](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib109&sa=D&source=editors&ust=1717021441044142&usg=AOvVaw25SB8udKbMs5cbGGpr4rn1); [Clarke et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib64&sa=D&source=editors&ust=1717021441044332&usg=AOvVaw0xlcBwz1yJLYlKbeMJ6XQc)). While virtual clinics may have limitations in detecting unstable diseases, they may serve important functions for more slowly progressive diseases ([Clarke et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib64&sa=D&source=editors&ust=1717021441044502&usg=AOvVaw1kP4fVCbZEWzo-l6iMH9dx)). Glaucoma is typically slowly progressive and as such, telemedicine strategies may facilitate ****periodic monitoring****, timely referral and screening ([Sreelatha and Ramesh, 2016](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib282&sa=D&source=editors&ust=1717021441044698&usg=AOvVaw2cLWw6mR7lM4txt8e2h9kT)).\n', '\n', '$QUOTETOBEREPLACED$ In the past 20 years, a large number of pilot teleophthalmology programs were carried out around the world, demonstrating the feasibility in the detection and management of glaucoma ([Labiris et al., 2003](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib170&sa=D&source=editors&ust=1717021441044942&usg=AOvVaw2GfCGcIU3UcZkNx_BuoyFE); [Owsley et al., 2015](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib220&sa=D&source=editors&ust=1717021441045107&usg=AOvVaw04Y1I5a0w7K-8cwTzr5-0j); [Rathi et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib241&sa=D&source=editors&ust=1717021441045284&usg=AOvVaw15O1lrSaf5qeikCmQ9kiX0); [Zhao et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib354&sa=D&source=editors&ust=1717021441045447&usg=AOvVaw3A7ot1Xsat8GeDtcd7v0Yz)). For example, the Wills Eye Glaucoma Research Center designed a 5-year telemedicine screening program, the Philadelphia Telemedicine Glaucoma Detection and Follow-up Study ([Hark et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib118&sa=D&source=editors&ust=1717021441045618&usg=AOvVaw0B3MkNd6syDjTs92Wqg3do)). This program illustrated how to improve access to eye care and reduce glaucoma-related vision loss in high-risk populations ([Waisbourd et al., 2016](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib320&sa=D&source=editors&ust=1717021441045780&usg=AOvVaw1FFa6mQZFgxTyM7GlvAhiM); [Hark et al., 2016](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib117&sa=D&source=editors&ust=1717021441045966&usg=AOvVaw33IF6QKvZLEyHd__xCkcBM)). Another telemedicine glaucoma program in Northern Canada at University of Alberta relied on****real-time consultations with glaucoma specialists via VoIP****(Voice-over Internet Protocol) in primary eye care clinics ([Kassam et al., 2013](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib150&sa=D&source=editors&ust=1717021441046156&usg=AOvVaw0M656IV3raO0R1ucbdiyoY)). Overall, several studies reported that about half of the examined patients had favorable attitudes towards such programs ([Gagnon et al., 2004](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib90&sa=D&source=editors&ust=1717021441046329&usg=AOvVaw3OPa_Bi4ZevHN4lcOQ8eCz); [Valikodath et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib313&sa=D&source=editors&ust=1717021441046532&usg=AOvVaw1cX2_z0uSaeEJczt6C1H36); [Rhodes et al., 2019](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib246&sa=D&source=editors&ust=1717021441046742&usg=AOvVaw3G6BSGQIPKXyzogTNvDXwb)), with positive implications for further improvement.\n', '\n', '$QUOTETOBEREPLACED$ In ****China, where more than 90% of glaucoma may be undiagnosed****\xa0([Song et al., 2011](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib280&sa=D&source=editors&ust=1717021441046995&usg=AOvVaw1qMvhB5UhbNkijTv6cMyFz); [Liang et al., 2011](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib186&sa=D&source=editors&ust=1717021441047162&usg=AOvVaw2eDLiD0aFgy2X4T28f_x3B)), telemedicine-based public health care delivery in ophthalmology has been adopted since 2012 ([Xu et al., 2012](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib343&sa=D&source=editors&ust=1717021441047376&usg=AOvVaw1N4PS4hXnv47FtW_OAUX4g)). This population-based public health care project was designed to ****screen all elderly people (age 55‚Äì85 years) of the rural areas****. Based on fundus images, 1606 of 37,281 (4.31%) participants were found to have glaucoma. Moreover, a novel teleophthalmology system was developed and centered at Zhongshan Ophthalmic Center, linking with 10 rural hospitals in Guangdong province ([Xiao et al., 2017](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1350946220300720?casa_token%3DMj4KMMnidLkAAAAA:wtWmn5QuxgbrIhGypGwW8Y3wrmW3GC7f575ZdfMEOADuCM7SahnpShNtpzoUHUnNZ8N4Gbvj%23bib341&sa=D&source=editors&ust=1717021441047604&usg=AOvVaw1NM3_OGDNBp5KTpqUOPXV6)). This integrated system combines colour fundus imaging, cloud-based web application and tablet applications for providing glaucoma and DR grading, comprehensive eye examination, eye disease diagnosis and treatment. In addition, the system****automatically sends mobile messages****\xa0to patients reminding them about upcoming visits, which can ****improve their medical compliance****. Moreover, from a ****quality control perspective****, educational modules within the system train image graders and rural doctors regarding fundus image grading on glaucoma and DR.\n', '\n', '[Rahimy et al. (2020)](https://www.google.com/url?q=https://www.retinalphysician.com/issues/2020/october-2020/parallel-in-office-and-virtual-clinics-for-retina&sa=D&source=editors&ust=1717021441047931&usg=AOvVaw2_1V0-iz5HvfaspkqEXoSU): ‚ÄúParallel In-Office and Virtual Clinics for Retina Practice Post COVID-19‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image139.png)\n', '\n', 'And you have service providers[[b]](#cmnt2)\xa0like Saccadio providing you the whole pipeline\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image117.png)\n', '\n', '$QUOTETOBEREPLACED$ [http://www.saccadio.com/?page_id=25119](https://www.google.com/url?q=http://www.saccadio.com/?page_id%3D25119&sa=D&source=editors&ust=1717021441048455&usg=AOvVaw0o_KEM9So_pJnD_xM9eVxH)\n', '\n', '$QUOTETOBEREPLACED$ [https://youtu.be/ntEKT-C_km4](https://www.google.com/url?q=https://youtu.be/ntEKT-C_km4&sa=D&source=editors&ust=1717021441048620&usg=AOvVaw0B3JFfgUArtBNsMFH_nvAb)\n', '\n', '### ‚ÄúMultimodal‚Äù\n', '\n', '[Topol (2023)](https://www.google.com/url?q=https://doi.org/10.1126/science.adk6139&sa=D&source=editors&ust=1717021441048838&usg=AOvVaw0oklhYHUOQMkUDSyDVh2gd): ‚ÄúAs artificial intelligence goes multimodal, medical applications multiply‚Äù\n', '\n', '$QUOTETOBEREPLACED$ This multimodal AI has the potential for a wide range of data-driven applications. For people at risk for developing chronic medical conditions, a ****virtual health assistant could provide frequent feedback****about their data to achieve prevention or better manage preexisting conditions. Take the example of a person who has high blood pressure and diabetes, and has a high polygenic risk score for developing heart disease. The virtual assistant ****would not only help achieve blood pressure and glucose control****, to diminish the toll of these modifiable risk factors, but also analyze and **==**==coach the person==**==**\xa0on the basis of their physical activity, sleep, stress, retinal photos, unstructured text from medical records, and the latest medical literature. There are already virtual AI chatbot health assistants for specific conditions such as [diabetes](https://www.google.com/url?q=https://www.virtahealth.com/&sa=D&source=editors&ust=1717021441049191&usg=AOvVaw3awOIv9x_33SbZyADw-IRU), [hypertension](https://www.google.com/url?q=https://www.helloheart.com/&sa=D&source=editors&ust=1717021441049354&usg=AOvVaw0NJY1dEkG22ZuW2J9hSpfV), [obesity](https://www.google.com/url?q=https://www.noom.com/lp/weightLossGoal&sa=D&source=editors&ust=1717021441049465&usg=AOvVaw2ZA4ZiaN3femcsqxuYv1jo), and [depression](https://www.google.com/url?q=https://woebothealth.com/&sa=D&source=editors&ust=1717021441049568&usg=AOvVaw2RzY4_IXcYwxgEHkMua3LG), but none have yet become holistic or preventive.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Multimodal data for an individual can also make ****remote monitoring a reality****, allowing a [‚Äúhospital-at-home‚Äù](https://www.google.com/url?q=https://www.commonwealthfund.org/publications/newsletter-article/hospital-home-programs-improve-outcomes-lower-costs-face-resistance&sa=D&source=editors&ust=1717021441049923&usg=AOvVaw1d8xP5Q1y_9YCSGaH5wNDI)********with continuous vital-sign capture that ****is equivalent to an intensive care unit****. With algorithms that are validated to accurately foresee signs of a person‚Äôs deterioration well before any symptoms occur and the need to intervene, be it remotely or dispatching medical personnel, many patients could avoid being admitted to hospitals in the future. There are several other use cases of multimodal AI, such as a ****digital twin****\xa0that would be informative for a person with a new diagnosis by providing a digital facsimile on which to find a successful treatment. Another application is [pandemic surveillance](https://www.google.com/url?q=https://www.nature.com/articles/s41587-022-01350-x&sa=D&source=editors&ust=1717021441050143&usg=AOvVaw361NYVKF0X5_wMwvi-523w)\xa0for individualized spatiotemporal, real-time risk assessment with geolocation, wearable sensors, symptoms, vaccination status, wastewater results, and other layers of data.  \n', '  \n', 'So far there has been****integration of a few layers of data****, such as electronic heath records and genomics, but nothing has approached the complexity, depth, and breadth of what can be relevant and analyzed. That **==**==represents a considerable ongoing challenge to actualize the extraordinary potential of multimodal AI in medicine==**==**.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### Prevention and Public health\n', '\n', '[Jonathan Anomaly (2023)](https://www.google.com/url?q=https://doi.org/10.1007/s11127-021-00908-8&sa=D&source=editors&ust=1717021441050480&usg=AOvVaw3qCay57Nu224MtdPB3hRio): ‚ÄúWhat is public health? public goods, publicized goods, and the conversion problem‚Äù\n', '\n', '$QUOTETOBEREPLACED$ But the concept and practice of public health has ballooned to encompass an expanding list of controversial public policy goals ranging from ****reducing obesity to raising self-esteem****. As the list of controversial goals expands, support for ‚Äúpublic health‚Äù measures contracts. I‚Äôll briefly defend the view that ****we should define public health as the provision of health-related public goods****. I‚Äôll then show that being a health-related public good is not a sufficient condition for counting as a public health goal, since virtually any private good can be converted into a public good by government fiat. This is the conversion problem, which challenges the way we ordinarily think about public goods and public health.\n', '\n', '## UX Importance\n', '\n', '[Miliard (Sept 2023)](https://www.google.com/url?q=https://www.healthcareitnews.com/news/user-unfriendly-ehrs-pose-serious-risks-patient-safety?mkt_tok%3DNDIwLVlOQS0yOTIAAAGOLkZzP-q9veHocoEQqxcMzkEpAwDQABvnbJ4VEQmc5IfscKzhGy5kRY2lmPMHGsRGAdAKP5xuf2w-ff6FjgW53-caPaBzWD7ivrb4W6ej6fY&sa=D&source=editors&ust=1717021441050936&usg=AOvVaw1L8_26C-_bDp4dUEkgKTOG): ‚ÄúUser-unfriendly EHRs pose serious risks to patient safety‚Äù\n', '\n', '[Classen et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1001/jamanetworkopen.2023.33152&sa=D&source=editors&ust=1717021441051094&usg=AOvVaw2URlfb_qm9fgQOm5rJX-fF): ‚ÄúInpatient EHR User Experience and Hospital EHR Safety Performance‚Äù\n', '\n', "$QUOTETOBEREPLACED$ EHRs' built-in safety mechanisms [need to be redesigned](https://www.google.com/url?q=https://www.healthcareitnews.com/news/how-one-hospital-tweaks-its-ehr-fight-alert-fatigue&sa=D&source=editors&ust=1717021441051406&usg=AOvVaw2YIDGwFM-LdiCYjEMmr2mU), the study suggests. Classen, Bates and their researchers studied EHR systems in 112 U.S. hospitals, comparing a survey of user experience for more than 5,000 clinicians with outcomes from \xa0the [Leapfrog CPOE Evaluation tool](https://www.google.com/url?q=https://www.leapfroggroup.org/survey-materials/prepare-cpoe-tool&sa=D&source=editors&ust=1717021441051589&usg=AOvVaw0QQ-lOAtV0zi0fS_CE7BkP), which examines whether medication orders that could potentially harm a patient are actually detected by alert systems.\n", '\n', '## Clinician Resistance\n', '\n', '[https://www.linkedin.com/feed/update/urn:li:activity:7123292192600690688/](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7123292192600690688/&sa=D&source=editors&ust=1717021441051889&usg=AOvVaw3Vg11shmYIg-KU4pbe12tS)\xa0-> ‚ÄúDoctors like to be in control. Artificial intelligence may threaten their sense of agency. Recently, a surgeon colleague proudly told me he doesn‚Äôt have a type A personality. He has a type A-plus personality! An underappreciated challenge for implementing healthcare AI is that it forces us to relinquish a degree of control.‚Äù ->\n', '\n', "[Astrid Galsgaard et al (2022)](https://www.google.com/url?q=https://doi.org/10.1016/j.ejrad.2022.110231&sa=D&source=editors&ust=1717021441052087&usg=AOvVaw21L5MRJZu9Boj_oxKH92JU): ‚ÄúArtificial intelligence and multidisciplinary team meetings; a communication challenge for radiologists' sense of agency and position as spider in a web?‚Äù\n", '\n', '[Hua et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.artmed.2023.102698&sa=D&source=editors&ust=1717021441052302&usg=AOvVaw1ScgG929q_Egtqf0PBjkoK): ‚ÄúUnderstanding the factors influencing acceptability of AI in medical imaging domains among healthcare professionals: A scoping review‚Äù\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Poor acceptability of AI among healthcare professionals in medical imaging domains threatens to prevent its promising benefits from being realised\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ This ****review summarises the key factors influencing AI acceptabilit****y that have been studeid and analyses the methodological approaches adopted by past research\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Important factors underpinning AI acceptability in medical imaging contexts are often overlooked due to the use of theoretical frameworks and ad-hoc approaches that are not designed to capture its complexities\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ A meaningful combination of the factors identified in this review should be addressed to ensure comprehensive evaluations of medical AI acceptability\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Future work should synthesise evidence of the causal importance of different factors in achieving high medical AI acceptance\n', '\n', '[HBR 2024](https://www.google.com/url?q=https://hbr.org/2024/03/why-physicians-resist-using-algorithm-based-apps&sa=D&source=editors&ust=1717021441052892&usg=AOvVaw1ja-U6cNFp38ywF-OqnuZw): ‚ÄúWhy Physicians Resist Using Algorithm-Based Apps‚Äù\n', '\n', '$QUOTETOBEREPLACED$ But our interviews with 32 physicians (across 12 specialties) that work in the United Kingdom‚Äôs National Health Service (NHS) found that doctors are reluctant to use algorithms to help them make diagnoses. All 32 of the people were hesitant even though they recognized the value. There were several reasons:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ They lacked guidance or support on how to use technology. ‚ÄúYou know absolutely nothing, and yet ‚Äúyou‚Äôre not told anything,‚Äù one physician said.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The technology was [not formally integrated](https://www.google.com/url?q=https://hbr.org/2019/11/3-myths-about-machine-learning-in-health-care&sa=D&source=editors&ust=1717021441053272&usg=AOvVaw1Rh6JXwBEzzXXt4BiJ4PU2)\xa0into their workflows. ‚ÄúIt‚Äôs all a bit niche right now,‚Äù one doctor named Paul said. Another complained that the technology was incompatible with his role.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ They felt that they needed to behave ‚Äúprofessionally‚Äù in the presence of patients and worried about how patients, colleagues, and senior management would perceive their use of the technology. One physician explained that ‚ÄúI think looking at your phone might be perceived by onlookers or patients as something social rather than actually work-related and assume [that I am] not doing work.‚Äù\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ They feared that if they heavily depended on technology to make diagnoses and come up with treatment plans, their own expertise would deteriorate. One physician explained: ‚ÄúI think what you learn as a doctor in training you need to nurture ‚Ä¶ because if you don‚Äôt ‚Ä¶ you‚Äôre going to lose the skill of how to talk to patients [and] how to come up with a treatment plan. And if you become too dependent on things like [technology], you‚Äôre potentially de-skilling yourself in other more important ways.‚Äù\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Capturing artificial intelligence applications‚Äô value proposition in healthcare ‚Äì a qualitative research study](https://www.google.com/url?q=https://doi.org/10.1186/s12913-024-10894-4&sa=D&source=editors&ust=1717021441053666&usg=AOvVaw35iKi4WnhOicqvVwbDYM4-)\n', '\n', '## Human-AI Co-operation\n', '\n', '[Li et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00991-9&sa=D&source=editors&ust=1717021441053920&usg=AOvVaw0Zm4yIMqdD3xDDPi5syfLJ): ‚ÄúThe performance of a deep learning system in assisting junior ophthalmologists in diagnosing 13 major fundus diseases: a prospective multi-center clinical trial‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image219.png)\n', '\n', '$QUOTETOBEREPLACED$ The DLS was consisted of a quality assessment model and a diagnostic model.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image62.png)\n', '\n', '$QUOTETOBEREPLACED$ The AI‚Äôs suggested label is presented at the upper right corner. The doctors could choose the disease label at the bottom.\n', '\n', '[Subramanian et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.artmed.2024.102780&sa=D&source=editors&ust=1717021441054351&usg=AOvVaw0tWQJLURPCyr8sIma4jvTu): ‚ÄúDesigning explainable AI to improve human-AI team performance: A medical stakeholder-driven scoping review‚Äù\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Soliciting user input early helps identify scope of AI in transplant decision-making.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ AI can provide additional information or a second opinion for decision support.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Users need both system-level and prediction-level information for mental model.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Users need complementary explainability where novices get more and experts get less.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Users may self-regulate the amount of explainability depending on case difficulty.\n', '\n', '[D√≥ra G√∂nd√∂cs and Viktor D√∂rfler (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.artmed.2024.102769&sa=D&source=editors&ust=1717021441054909&usg=AOvVaw0us0R9Tn_xKiTAWelPS06v): ‚ÄúAI in medical diagnosis: AI prediction & human judgment‚Äù\n', '\n', '- Medical doctors expressed preference for three distinct ways of using AI: as a tool, as an assistant, or as a ‚Äòpeer college‚Äô.\n', '- Medical doctors seek to keep responsibility for the outcome (diagnosis), and this does not stem from worry for their jobs.\n', '- In explainability, medical doctors seek a scientific understanding of AI rather than how a specific outcome was arrived at.\n', '- Medical doctors recognize the need for a new mindset when thinking about AI, which involves revising the diagnostic process.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image128.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image5.png)\n', '\n', '[Co-Intelligence LIVING AND WORKING WITH AI By Ethan Mollick](https://www.google.com/url?q=https://twitter.com/emollick/status/1763994015320436903&sa=D&source=editors&ust=1717021441055347&usg=AOvVaw0xqqOncaRBe_epqu0HH9Hr)\n', '\n', '$QUOTETOBEREPLACED$ Something new entered our world in November 2022 ‚Äî the first general purpose AI that could pass for a human and do the kinds of creative, innovative work that only humans could do previously. Wharton professor Ethan Mollick immediately understood what ChatGPT meant: after millions of years on our own, humans had developed a kind of co-intelligence that could augment, or even replace, human thinking. Through his writing, speaking, and teaching, Mollick has become one of the most prominent and provocative explainers of AI, focusing on the practical aspects of how these new tools for thought can transform our world.\n', '\n', '$QUOTETOBEREPLACED$ In Co-Intelligence, Mollick urges us to engage with AI as co-worker, co-teacher, and coach. He assesses its profound impact on business and education, using dozens of real-time examples of AI in action. Co-Intelligence shows what it means to think and work together with smart machines, and why it‚Äôs imperative that we master that skill.\n', '\n', '$QUOTETOBEREPLACED$ Mollick challenges us to utilize AI‚Äôs enormous power without losing our identity, to learn from it without being misled, and to harness its gifts to create a better human future. Wide ranging, hugely thought-provoking, optimistic, and lucid, Co-Intelligence reveals the promise and power of this new era.\n', '\n', '[Yu et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41591-024-02850-w&sa=D&source=editors&ust=1717021441055661&usg=AOvVaw2yhXYXD1pCy2UovZ4Smd5s): ‚ÄúHeterogeneity and predictors of the effects of AI assistance on radiologists‚Äù\n', '\n', '$QUOTETOBEREPLACED$ This large-scale study explored the effects of AI assistance on 140 radiologists across 15 chest X-ray diagnostic tasks. It aimed to understand how AI impacts individual clinicians, exploring predictors of these effects. [Jan Beger](https://www.google.com/url?q=https://www.linkedin.com/posts/janbeger_heterogeneity-predictors-of-the-effects-activity-7176080062054621184-ezNt?utm_source%3Dshare%26utm_medium%3Dmember_desktop&sa=D&source=editors&ust=1717021441056004&usg=AOvVaw0amJXtEUVXCup1M0ouNHRe)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The integration of artificial intelligence (AI) in medical image interpretation requires **==**==effective collaboration between clinicians and AI algorithms==**==**. Although previous studies demonstrated the potential of AI assistance in improving overall clinician performance, the individual impact on clinicians remains unclear. This large-scale study examined the ****heterogeneous effects of AI assistance on 140 radiologists across 15 chest X-ray diagnostic tasks****\xa0and identified predictors of these effects. Surprisingly, conventional experience-based factors, such as years of experience, subspecialty and familiarity with AI tools, fail to reliably predict the impact of AI assistance. Additionally, ****lower-performing radiologists do not consistently benefit more from AI assistance,****\xa0challenging prevailing assumptions. Instead, we found that the occurrence of AI errors strongly influences treatment outcomes, with inaccurate AI predictions adversely affecting radiologist performance on the aggregate of all pathologies and on half of the individual pathologies investigated. Our findings **==**==highlight the importance of personalized approaches to clinician‚ÄìAI collaboration==**==**and the importance of accurate AI models. By understanding the factors that shape the effectiveness of AI assistance, this study provides valuable insights for targeted implementation of AI, enabling maximum benefits for individual clinicians in clinical practice.\n', '\n', '## Data models\n', '\n', '[Sophia Ly et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1007/s13555-023-01031-w&sa=D&source=editors&ust=1717021441056659&usg=AOvVaw3GOGZFBpTOAnvp0Jg1raiA): ‚ÄúPublic Perceptions, Factors, and Incentives Influencing Patient Willingness to Share Clinical Images for Artificial Intelligence-Based Healthcare Tools‚Äù\n', '\n', '$QUOTETOBEREPLACED$ This study aims to understand ****individuals‚Äô willingness to share****their images for AI and variables that influence willingness. ‚Ä¶ Ultimately, addressing public attitudes is not only essential for the equitable development of AI-based tools but also crucial for fostering patient trust and engagement with AI in healthcare.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Zhang et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1016/S2589-7500(23)00157-7&sa=D&source=editors&ust=1717021441056982&usg=AOvVaw0bvFEGa9oskSN0kSOe__yq): ‚ÄúMapping and evaluating national data flows: transparency, privacy, and guiding infrastructural transformation‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The importance of big health data is recognised worldwide. Most UK National Health Service (NHS) care interactions are recorded in electronic health records, resulting in an unmatched potential for population-level datasets. However, policy reviews have highlighted challenges from a complex data-sharing landscape relating to transparency, privacy, and analysis capabilities. In response, we used public information sources to map all electronic patient data flows across England, from providers to more than 460 subsequent academic, commercial, and public data consumers. Although NHS data support a global research ecosystem, we found that multistage data flow chains limit transparency and risk public trust, most data interactions do not fulfil recommended best practices for safe data access, and existing infrastructure produces aggregation of duplicate data assets, thus limiting diversity of data and added value to end users. We provide recommendations to support data infrastructure transformation and have produced a website ([https://DataInsights.uk](https://www.google.com/url?q=https://datainsights.uk/&sa=D&source=editors&ust=1717021441057199&usg=AOvVaw0nRGiBy5s3bl9gfM8q2q2J)) to promote transparency and showcase NHS data assets.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image72.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image63.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image189.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image107.png)\n', '\n', '[Schwabe et al. (2024)](https://www.google.com/url?q=https://arxiv.org/abs/2402.13635&sa=D&source=editors&ust=1717021441057583&usg=AOvVaw03FYlYIOozsvfqm-xplqJ2): ‚ÄúThe METRIC-framework for assessing data quality for trustworthy AI in medicine: a systematic review‚Äù\n', '\n', "The development of trustworthy AI is especially important in medicine due to the large implications for patients' lives. While trustworthiness concerns various aspects including ethical, technical and privacy requirements, we focus on the importance of data quality (training/test) in DL. Since ****data quality dictates the behaviour of ML products****, evaluating data quality will play a key part in the regulatory approval of medical AI products. From this literature, we synthesise the existing knowledge on data quality frameworks and combine it with the perspective of ML applications in medicine. As a result, we propose the ****METRIC-framework****, a ****specialised data quality framework for medical training data****\xa0comprising 15 awareness dimensions, along which developers of medical ML applications should investigate a dataset. This knowledge helps to reduce biases as a major source of unfairness, increase robustness, facilitate interpretability and thus lays the foundation for trustworthy AI in medicine. ****Incorporating such systematic assessment of medical datasets into regulatory approval processes****\xa0has the potential to accelerate the approval of ML products and builds the basis for new standards.\n", '\n', 'One of the drivers for evidence-based medicine approaches was the****introduction of scientific standards in clinical practice****\xa0[24]. Since then, data integrity (defined by the ALCOA-principles or ALCOA+ [25]) has become an essential requirement of several guidelines, such as good clinical practice (GCP) [26], good laboratory practice (GLP) [27] or good manufacturing practice (GMP) [28]. In the pharmaceutical industry, data integrity plays a similarly important role as a requirement for drug trials. While ****data integrity****\xa0focuses on maintaining accuracy and consistency of a dataset over its entire life cycle, ****data quality****is concerned with the ****fitness of data for use****.\n', '\n', 'The scientific investigation of data quality ****was initiated roughly 30 years ago****. The term data quality was famously broken down into so-called data quality dimensions by Wang and Strong in 1996 [47]. These dimensions represent different characteristics of a dataset which together constitute the quality of the data. Throughout the years, general data quality frameworks have taken advantage of this approach and have produced refined lists of data quality dimensions for various fields of application and types of data.\n', '\n', '![](HTML%20import/Attachments/image177.png)\n', '\n', '![](HTML%20import/Attachments/image85.png)\n', '\n', '![](HTML%20import/Attachments/image124.png)\n', '\n', '![](HTML%20import/Attachments/image93.png)\n', '\n', '![](HTML%20import/Attachments/image37.png)\n', '\n', '![](HTML%20import/Attachments/image151.png)\n', '\n', '![](HTML%20import/Attachments/image140.png)\n', '\n', '![](HTML%20import/Attachments/image64.png)\n', '\n', '![](HTML%20import/Attachments/image153.png)\n', '\n', '![](HTML%20import/Attachments/image176.png)\n', '\n', '## Health Economics\n', '\n', '### Ophthalmology Examples\n', '\n', '![](HTML%20import/Attachments/image210.png)![](HTML%20import/Attachments/image3.png)  \n', '[https://zoom.us/webinar/register/4316243925596/WN_2_2qydBzSIqd_U2u2c5Z9Q](https://www.google.com/url?q=https://zoom.us/webinar/register/4316243925596/WN_2_2qydBzSIqd_U2u2c5Z9Q&sa=D&source=editors&ust=1717021441059336&usg=AOvVaw26hFVl5ZrJ0vrlE-7pJpYC)\n', '\n', 'CPT code 92229 and Eyenuk AI screening\n', '\n', '$QUOTETOBEREPLACED$  \n', '[https://www.ophthalmologymanagement.com/issues/2021/february-2021/coding-amp;-reimbursement](https://www.google.com/url?q=https://www.ophthalmologymanagement.com/issues/2021/february-2021/coding-amp;-reimbursement&sa=D&source=editors&ust=1717021441059674&usg=AOvVaw1iYOvUBs7hWYzkIW9yityE)  \n', '[https://www.aapc.com/codes/cpt-codes/92229](https://www.google.com/url?q=https://www.aapc.com/codes/cpt-codes/92229&sa=D&source=editors&ust=1717021441059829&usg=AOvVaw3_oQjhJ7_TKg0tkXPGTaeW)\n', '\n', '$QUOTETOBEREPLACED$ [https://www.findacode.com/cpt/92229-cpt-code.html](https://www.google.com/url?q=https://www.findacode.com/cpt/92229-cpt-code.html&sa=D&source=editors&ust=1717021441059980&usg=AOvVaw3i7PR4Krvwi2KYX_9sGBnx)\xa0\n', '\n', '****Coding & Reimbursement****Coding news for the new year  \n', '****By****[Suzanne L. Corcoran, COE](https://www.google.com/url?q=https://www.ophthalmologymanagement.com/authorsarticles?authorId%3De600335d-0535-4cb7-80a5-59eb0a204037&sa=D&source=editors&ust=1717021441060208&usg=AOvVaw2Vze-wsgWIvHcFYyvOHFd6)\xa0February 1, 2021  \n', '[https://www.ophthalmologymanagement.com/issues/2021/february-2021/coding-amp;-reimbursement](https://www.google.com/url?q=https://www.ophthalmologymanagement.com/issues/2021/february-2021/coding-amp;-reimbursement&sa=D&source=editors&ust=1717021441060401&usg=AOvVaw2ZbkgmAe-rR70WUT6dxb2h)\n', '\n', '$QUOTETOBEREPLACED$ Also for telemedicine, ophthalmology has new codes for remote imaging with**==**==OCT performed at home.==**==**These codes were effective July 1, 2020, so they aren‚Äôt completely new, but most practices are not aware of them.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 0604T: NEW **==**==Optical coherence tomography (OCT) of retina, remote, patient-initiated image capture==**==**\xa0and transmission to a remote surveillance center, unilateral or bilateral; initial device provision, set-up and patient education on use of equipment\n', '\n', '$QUOTETOBEREPLACED$ 0605T: NEW ... remote surveillance center technical support, data analyses and reports, with a minimum of eight daily recordings, each 30 days\n', '\n', '$QUOTETOBEREPLACED$  \n', 'Q. What other changes are happening?\n', '\n', '$QUOTETOBEREPLACED$ A.****Remote imaging has become more crucial for telemedicine during the pandemic.****There are two revised and one new code to help.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 92227: REVISED Imaging of retina for detection or monitoring of disease; remote clinical staff review and report, unilateral or bilateral\n', '\n', '$QUOTETOBEREPLACED$ 92228: REVISED ... with remote physician or other qualified health care professional interpretation and report, unilateral or bilateral\n', '\n', '$QUOTETOBEREPLACED$ 92229: NEW Imaging of retina for detection or monitoring of disease; point-of-care automated analysis and report, unilateral or bilateral\n', '\n', '$QUOTETOBEREPLACED$ CPT 92229 is remote imaging via point-of-care automated analysis. ====CPT describes it as======"augmented intelligence,"==********which means **==**==the software identifies unusual findings for a physician to review==**==**.\n', '\n', '[Nguyen et al. (2016)](https://www.google.com/url?q=https://doi.org/10.1016/j.ophtha.2016.08.021&sa=D&source=editors&ust=1717021441061462&usg=AOvVaw2-oICIwVX0N5C0wqp7-kDn): ‚ÄúCost-effectiveness of a National Telemedicine Diabetic Retinopathy Screening Program in Singapore‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image92.png)![](HTML%20import/Attachments/image217.png)\n', '\n', '[Xie et al. (2020)](https://www.google.com/url?q=https://doi.org/10.1016/S2589-7500(20)30060-1&sa=D&source=editors&ust=1717021441061811&usg=AOvVaw37LVPo9Y_7fKbrPwU9e0CV): ‚ÄúArtificial intelligence for teleophthalmology-based diabetic retinopathy screening in a national programme: an economic analysis modelling study‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Findings****From the health system perspective, the ****semi-automated screening model was the least expensive of the three models, at US$62 per patient per year****. The fully automated model was $66 per patient per year, and the human assessment model was $77 per patient per year. The savings to the Singapore health system associated with switching to the semi-automated model are estimated to be $489 000, which is roughly 20% of the current annual screening cost. By 2050, Singapore is projected to have 1 million people with diabetes; at this time, the estimated annual savings would be $15 million.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image178.png)  \n', '**Automated diabetic retinopathy screening models using deep learning system versus the current human assessment model in SiDRP**\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Interpretation****This study provides a strong economic rationale for using deep learning systems as an assistive tool to screen for diabetic retinopathy.\n', '\n', '$QUOTETOBEREPLACED$  \n', '![](HTML%20import/Attachments/image53.png)  \n', '****Tornado diagram showing how individual parameters affect incremental cost****Tornado diagrams showing the extent to which uncertainty in the individual parameters affects the incremental cost from the health system perspective of (A) semi-automated versus human assessment models, (B) fully automated versus human assessment models, and (C) semi-automated versus fully automated models. DLS=deep learning system. DR=diabetic retinopathy. EV=expected value.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Rossi et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1001/jamanetworkopen.2022.0269&sa=D&source=editors&ust=1717021441062679&usg=AOvVaw0LOAV9LRGYJOxlILbri_ak): ‚ÄúCost-effectiveness of Artificial Intelligence as a Decision-Support System Applied to the Detection and Grading of Melanoma, Dental Caries, and Diabetic Retinopathy‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The findings of this study suggest that ****marginal improvements in diagnostic accuracy****\xa0when using AI may translate into a ****marginal improvement in outcomes****. The current evidence supporting AI as decision support****from a cost-effectiveness perspective is limited****; AI should be evaluated on a case-specific basis to capture not only differences in costs and payment mechanisms but also treatment after diagnosis.  \n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image215.png)  \n', '****Cost-effectiveness of AI vs Standard of Care in Ophthalmology****. In panel A, each dot and square represents a single individual‚Äôs lifetime costs accrued (Brazilian reales, R$) after receiving either standard of care diagnostics or AI-assisted screening. In panel B, AI was more likely to be less cost-effective at a lower willingness to pay based on study assumptions, although this certainty was sensitive to the willingness to pay (WTP) for additional quality-adjusted life years (QALYs).\n', '\n', '## Novel methods\n', '\n', '### Omics, precision medicine, etc. novelties\n', '\n', 'Democratized when the price is right?\n', '\n', '![](HTML%20import/Attachments/image98.png)  \n', 'To get a sense of how powerful digital transformation is on genomics, in 2005, a single sequencing run could only produce one gigabase (one billion base pairs) of data and cost $14 million. \xa0By late 2014, that rate had climbed to 1.8 terabases of data (1,800x increase) while the cost has come down to $4,000 (3,500x decrease). \xa0And just this year, Illumina‚Äôs HiSeq X machine broke $1,000. [https://digital.hbs.edu/platform-rctom/submission/illumina-shining-a-light-on-your-dna/](https://www.google.com/url?q=https://digital.hbs.edu/platform-rctom/submission/illumina-shining-a-light-on-your-dna/&sa=D&source=editors&ust=1717021441063564&usg=AOvVaw3CaxwnTczbaEHv7QTxIgej)\xa0\n', '\n', '![](HTML%20import/Attachments/image181.png)[https://doi.org/10.1038/nature.2014.14530](https://www.google.com/url?q=https://doi.org/10.1038/nature.2014.14530&sa=D&source=editors&ust=1717021441063787&usg=AOvVaw22c5VEcYGPAu6JQYNVijji)\xa0\n', '\n', '## Device ‚ÄúStandardization‚Äù\n', '\n', '### Ophthalmology\n', '\n', '![](HTML%20import/Attachments/image200.png)\n', '\n', '[https://www.nei.nih.gov/about/news-and-events/news/nei-joins-call-standardization-ophthalmic-imaging-devices](https://www.google.com/url?q=https://www.nei.nih.gov/about/news-and-events/news/nei-joins-call-standardization-ophthalmic-imaging-devices&sa=D&source=editors&ust=1717021441064159&usg=AOvVaw2epHxHDhvS1C8Jyu7FBBKf)\xa0: ‚ÄùFor more information, see ‚Äú[Recommendations for Standardization of Images in Ophthalmology](https://www.google.com/url?q=https://www.aaojournal.org/article/S0161-6420(21)00164-0/fulltext%23articleInformation&sa=D&source=editors&ust=1717021441064302&usg=AOvVaw226hBqkiTIw7coF479b0n6),‚Äù published March 5, 2021, in Ophthalmology. DOI: \xa0[https://doi.org/10.1016/j.ophtha.2021.03.003](https://www.google.com/url?q=https://doi.org/10.1016/j.ophtha.2021.03.003&sa=D&source=editors&ust=1717021441064417&usg=AOvVaw1J_ekew0bjKABUkX8UCJHk). Michael F. Chiang, M.D., is director of the National Eye Institute at the National Institutes of Health in Bethesda, Maryland.\n', '\n', '$QUOTETOBEREPLACED$ ‚Äú****DICOM compliance is low for ophthalmic imaging technologies****. Even so-called DICOM-compliant devices fail to meet DICOM standards with significant limitations, such as the embedding of patient identifiers on the image. In the past, the Academy has used its resources extensively to encourage standard-setting activities and to develop standards collaboratively with device manufacturers.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ **Recommendations**\n', '\n', '$QUOTETOBEREPLACED$ The Academy strongly encourages imaging device manufacturers and PACS manufacturers ****to implement existing DICOM standards.****\xa0These are 2 specific examples of implementation that would benefit ophthalmologists:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Provide machine-readable, discrete data for user-selected reports of ophthalmic imaging or functional testing.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Use lossless compression for pixel or voxel data to encode the same raw data as used by manufacturers.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The Academy‚Äôs efforts are focused on making sure that medical technology is more relevant to the needs of the end user, the ophthalmologist, by ensuring that **==**==there is interoperability==**==**, that is, that there can be a seamless interface that allows the communication and comprehension of image data between 2 parties. Once ophthalmic imaging device manufacturers implement globally recommended standards, then the field of ophthalmology can ****rapidly progress along the path of efficient electronic workflow****, interoperability, and artificial intelligence systems that will meet an increased demand for ophthalmic services to the public.\n', '\n', '## Equity & Fairness\n', '\n', '[Equity in medical devices: independent review - summary report](https://www.google.com/url?q=https://www.gov.uk/government/publications/equity-in-medical-devices-independent-review-final-report/equity-in-medical-devices-independent-review-summary-report%23our-recommendations&sa=D&source=editors&ust=1717021441065272&usg=AOvVaw1pVOpiccMsEzfB5iJgQpjA)\n', '\n', '$QUOTETOBEREPLACED$ The initial stimulus for this review was growing concern about a specific medical device - the pulse oximeter, which estimates the level of oxygen in the blood - in common use throughout the NHS. The COVID-19 pandemic highlighted that the pulse oximeter may not be as accurate for patients with darker skin tones as for those with lighter skin. An inaccurate reading could lead to harm if there was a delay in identifying dangerously low oxygen levels in patients with darker skin tones, which normally would have triggered referral for more intensive care.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '## ‚ÄúClinical AI‚Äù\n', '\n', '[Zhang et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1016/S2589-7500(22)00032-2&sa=D&source=editors&ust=1717021441065740&usg=AOvVaw1Qw-6Pt_MGD3YEvkgUsSLD): ‚ÄúAn interactive dashboard to track themes, development maturity, and global equity in clinical artificial intelligence research‚Äù\n', '\n', '$QUOTETOBEREPLACED$ [https://aiforhealth.app](https://www.google.com/url?q=https://aiforhealth.app&sa=D&source=editors&ust=1717021441066055&usg=AOvVaw1cSt3QoFXaSf17deiqsNN-)\xa0\n', '\n', '[Wu et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1056/AIoa2300030&sa=D&source=editors&ust=1717021441066341&usg=AOvVaw3gbfEtqbhtLuL30iZ-CjVO): ‚ÄúCharacterizing the Clinical Adoption of Medical AI Devices through U.S. Insurance Claims‚Äù\n', '\n', '[William Boag et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-024-01061-4&sa=D&source=editors&ust=1717021441066515&usg=AOvVaw3ERzv2b-Jj0-o6eIIy8u7k): The algorithm journey map: a tangible approach to implementing AI solutions in healthcare\n', '\n', '$QUOTETOBEREPLACED$ When integrating AI tools in healthcare settings, complex interactions between technologies and primary users are not always fully understood or visible. This deficient and ambiguous understanding hampers attempts by healthcare organizations to adopt AI/ML, and it also creates new challenges for researchers to identify opportunities for simplifying adoption and developing best practices for the use of AI-based solutions. Our study fills this gap by **==**==documenting the process of designing, building, and maintaining an AI solution called SepsisWatch==**==**\xa0at Duke University Health System. We conducted 20 interviews with the team of engineers and scientists that led the multi-year effort to build the tool, integrate it into practice, and maintain the solution.\n', '\n', '$QUOTETOBEREPLACED$ This**"Algorithm Journey Map"**\xa0enumerates all social and technical activities throughout the AI solution‚Äôs procurement, development, integration, and full lifecycle management. In addition to mapping the ‚Äúwho?‚Äù and ‚Äúwhat?‚Äù of the adoption of the AI tool, we also show several ‚Äòlessons learned‚Äô throughout the algorithm journey maps including modeling assumptions, stakeholder inclusion, and organizational structure. In doing so, we identify generalizable insights about how to recognize and navigate barriers to AI/ML adoption in healthcare settings. We expect that this effort will further the development of best practices for operationalizing and sustaining ethical principles‚Äîin algorithmic systems.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image18.png)\n', '\n', '$QUOTETOBEREPLACED$ Different tasks that arise throughout post-rollout lifecycle management.\n', '\n', '[Jasmin Hennrich et al. (2024)](https://www.google.com/url?q=https://bmchealthservres.biomedcentral.com/articles/10.1186/s12913-024-10894-4&sa=D&source=editors&ust=1717021441066986&usg=AOvVaw3EnXvN6SSzAoJrWrOlWbPw): ‚ÄúCapturing artificial intelligence applications‚Äô value proposition in healthcare ‚Äì a qualitative research study‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image2.png)\n', '\n', '## Precision Medicine\n', '\n', '[R. Laubenbacher et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s43588-024-00607-6&sa=D&source=editors&ust=1717021441067427&usg=AOvVaw14GuYP7wBOQK-ibYCgZKcd): ‚ÄúDigital twins in medicine‚Äù **feat by**[Frank Kumli](https://www.google.com/url?q=https://www.linkedin.com/posts/kumli_healthcare-innovation-healthdata-activity-7179393640329273346-V0lD?utm_source%3Dshare%26utm_medium%3Dmember_desktop&sa=D&source=editors&ust=1717021441067643&usg=AOvVaw0y1z0frr6h7gec2qDIiOTN)\n', '\n', '$QUOTETOBEREPLACED$ ****Medical digital twins****, which are potentially ****vital for personalized medicine****, have become a recent focus in medical research. Here we present an overview of the state of the art in medical digital twin development, especially in oncology and cardiology, where it is most advanced. We discuss major challenges, such as data integration and privacy, and provide an outlook on future advancements. Emphasizing the importance of this technology in healthcare, we highlight the potential for substantial improvements in patient-specific treatments and diagnostics.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image161.png)\n', '\n', '$QUOTETOBEREPLACED$ ****a****, Keeping healthy patients healthy. For a given patient (in yellow), a safe cholesterol level is determined, using genetic information, family history and other data. The yellow line indicates the trend of the patient‚Äôs cholesterol levels over time, if untreated. Yellow boxes represent measurements. The patient‚Äôs digital twin (blue), on the other hand, forecasts the trajectory and recommends periodic preventive interventions (blue arrows), resulting in cholesterol levels following the blue curve.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****b****, Restoring health in ill patients. Upon admission to the ICU, the patient (green) is evaluated and receives initial treatment for an infection. A computer algorithm personalizes an appropriate computational disease model, together with information from a database of reference patients to recommend optimal interventions. As more repeated measurements are taken from the patient, the reference population is refined, the model is recalibrated to the patient at later time points, and the recommendations for optimal treatment are refined. The cones represent the likely trajectory of the infection as determined by the digital twin. With time and a larger number of patient data points, the uncertainty in the predictions decreases (the cone becomes narrower) and subsequent patient time points fall closer to the center of the previous prediction cone. The improvement in the parameter ensemble that describes the patient is reflected by the corresponding virtual cohort that describes the patient at each time point, which is depicted as increasingly containing more green subjects, like the patient being treated.********\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****c****, Development of novel therapeutics. Currently, clinical trials typically involve the use of animals and patient cohorts (left panel). With the advent of MDTs, it will be possible to reduce the number of animals used in preclinical trials and to optimize patient trials using virtual patients. They can be used to screen large numbers of drug targets and drug candidates, and to perform initial optimization studies using large numbers of patient MDTs and virtual patients (middle panel). Optimal drug regimes, doses and combinations can also be inferred by MDT before administering drugs to patients, thus minimizing side effects (right panel).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '## Regulatory dimension\n', '\n', '[Reuter (Nov 2022)](https://www.google.com/url?q=https://www.medtechdive.com/news/FDA-AI-ML-medical-devices-5-takeaways/635908/&sa=D&source=editors&ust=1717021441068623&usg=AOvVaw0X_j2QtYQGGi8IzG899V_1): ‚Äú5 takeaways from the FDA‚Äôs list of AI-enabled medical devices‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image84.png)![](HTML%20import/Attachments/image41.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image212.png)\xa0![](HTML%20import/Attachments/image100.png)\n', '\n', '$QUOTETOBEREPLACED$ AI- and machine-learning-enabled devices will become increasingly complex as companies move toward algorithms that **"learn"**\xa0as opposed to algorithms that are**"locked and deployed,"**wrote IQVIA‚Äôs Miller.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ‚ÄúOne thing that is really peculiar for AI devices, the core of the device is an AI algorithm, a piece of software. The piece of software ****may evolve over time****, so there needs to be periodic surveillance of how the software inside of the device is changing,‚Äù said Scripps‚Äô Quer.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The FDA also has discussed a [predetermined change control plan](https://www.google.com/url?q=https://www.fda.gov/files/medical%2520devices/published/US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf&sa=D&source=editors&ust=1717021441069332&usg=AOvVaw0qcjlDKqy6Ylboaz3hBRbV), where companies could outline anticipated modifications to software-based devices, allowing them to make changes within those boundaries without making another time-consuming submission to the agency.\n', '\n', '[Lennerz et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-022-00721-7&sa=D&source=editors&ust=1717021441069560&usg=AOvVaw2cUI1vhrrTg2ugRv-IwuaC): ‚ÄúA unifying force for the realization of medical AI‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Artificial Intelligence (AI) in medicine has grown rapidly, yet few algorithms have been deployed. It is not the problem with the AI itself but with the way functions and results are communicated. ****Regulatory science****\xa0provides the appropriate language and solutions to this problem for three reasons: First, there is value in the intentionally ****interdisciplinary regulatory language****. Second, regulatory concepts are important for AI researchers because these concepts enable tackling of risk and safety concerns as well as understanding of recently proposed regulations in the US and Europe. Third, regulatory science is a scientific discipline that evaluates and challenges current regulation‚Äîaiming for evidence-based improvements. **==**==Knowledge of the regulatory language, concepts, and science should be regarded a core competency for communicating medical innovation==**==**. Regulatory grade communication will be the key to bringing medical AI from hype to standard of care. Foregoing the possible benefits of regulatory science as a unifying force for the realization of medical AI is a missed opportunity.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image25.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Nannini et al. (2023)](https://www.google.com/url?q=https://arxiv.org/abs/2304.11218&sa=D&source=editors&ust=1717021441070123&usg=AOvVaw1eQBzuAieUKZEv0XjKFy0a): ‚ÄúExplainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Public attention towards explainability****\xa0of artificial intelligence (AI) systems has been rising in recent years to offer methodologies for human oversight. This has translated into the proliferation of research outputs, such as from Explainable AI, to ****enhance transparency****\xa0and control for system debugging and monitoring, and intelligibility of system process and output for user services. Yet, such outputs are ****difficult to adopt on a practical level due to a lack of a common regulatory baseline****, and the ****contextual nature of explanations****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Governmental policies are now attempting to tackle such exigence, however it remains unclear to what extent published communications, regulations, and standards adopt an informed perspective to support research, industry, and civil interests. In this study, we perform the first thematic and gap analysis of this****plethora of policies and standards on explainability in the EU, US, and UK****. Through a**==**==rigorous survey of policy documents==**==**, we first contribute an overview of governmental regulatory trajectories within AI explainability and its sociotechnical impacts. We find that ****policies are often informed by coarse notions****and requirements for explanations. This might be due to the willingness to conciliate explanations foremost as a risk management tool for AI oversight, but also due to the lack of a consensus on what constitutes a valid algorithmic explanation, and how feasible the implementation and deployment of such explanations are across stakeholders of an organization. Informed by AI explainability research, we conduct **==**==a gap analysis of existing policies==**==**, leading us to formulate a set of recommendations on how to address explainability in regulations for AI systems, especially discussing the definition, feasibility, and usability of explanations, as well as allocating accountability to explanation providers.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image145.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Brajovic et al. (2023)](https://www.google.com/url?q=https://arxiv.org/pdf/2307.11525.pdf&sa=D&source=editors&ust=1717021441070812&usg=AOvVaw1pavT5C1usWrxlbV9k5oUY): ‚ÄúModel Reporting for Certifiable AI: A Proposal from Merging EU Regulation into AI Development‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Despite large progress in Explainable and Safe AI, practitioners suffer from a lack of regulation and standards for AI safety. In this work **==**==we merge recent regulation efforts by the European Union and first proposals for AI guidelines with recent trends in research: data and model cards.==**==**\xa0We propose the use of standardized cards to document AI applications throughout the development process. Our main contribution is the ****introduction of use-case and operation cards****, along with updates for data and model cards to cope with regulatory requirements. We reference both recent research as well as the source of the regulation in our cards and provide references to additional support material and toolboxes whenever possible. The goal is to design cards that help practitioners develop safe AI systems throughout the development process, while ****enabling efficient third-party auditing of AI applications****, being easy to understand, and building trust in the system. Our work incorporates insights from interviews with certification experts as well as developers and individuals working with the developed AI applications.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ We conduct interviews with standardization experts, developers and consumers of the final AI product and incorporate their feedback into our proposal. Furthermore, our framework serves as a solid foundation for prospective system certification. By adhering to our guidance, developers can ensure they are adequately equipped to meet forthcoming legal obligations within their domain. The ****key contributions of our work is fourfold****:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Our guideline is meant to be ****used during the development process****.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ We combine requirements from non-technical users as well as certification and standardization bodies.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ We include references to support material and toolboxes and link the source of the requirement whenever possible.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ We ****lay the foundations for a future certification of the system****. With our framework, developers should be well-positioned when legal requirements come into force.\n', '\n', '$QUOTETOBEREPLACED$ In certain product categories like ****medical devices****, third-party conformity assessments are mandatory to ensure compliance with technical regulations before entering specific markets ([European Commission, 2023a](https://www.google.com/url?q=https://trade.ec.europa.eu/access-to-markets/en/content/standards-and-conformity-assessment&sa=D&source=editors&ust=1717021441071654&usg=AOvVaw3H6GUo8GdnxpX1SdAHu1m5)). Apart from such certificates, so called ****guidelines have no legally binding effect****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image38.png)  \n', '[Bommasani et al. (2023)](https://www.google.com/url?q=https://crfm.stanford.edu/2023/06/15/eu-ai-act.html&sa=D&source=editors&ust=1717021441071899&usg=AOvVaw3aHc0s8SMVhD6sgO93rrqa): ‚ÄúDo foundation model providers comply with the eu ai act?‚Äù\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image6.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image202.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image183.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[https://www.statnews.com/2024/02/20/health-ai-regulation-tech-startups-compliance/](https://www.google.com/url?q=https://www.statnews.com/2024/02/20/health-ai-regulation-tech-startups-compliance/&sa=D&source=editors&ust=1717021441072306&usg=AOvVaw3XzrR6CEyS0bUZAihZPztI)\xa0\n', '\n', '### Regulatory pathways\n', '\n', '[Incubator Webinar: Regulation of LLMs ‚ÄòHow to get regulatory approval for an LLM-enabled medical device‚Äô](https://www.google.com/url?q=https://www.regulatoryscience.ai/webinar-regulation-of-llms&sa=D&source=editors&ust=1717021441072575&usg=AOvVaw1gXKODtemfCpDFTua0-HUk): Presented by Dr Hugh Harvey\n', '\n', '$QUOTETOBEREPLACED$ Get ready to explore:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What makes LLMs distinct from other AI as a medical device\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The practical steps that a LLM-enabled medical device vendor would need to take to get approval\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The key barriers to gaining approval\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '#### FDA\n', '\n', '[Muehlematter et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1016/S2589-7500(23)00126-7&sa=D&source=editors&ust=1717021441073078&usg=AOvVaw2i12qF9DijbQcUUl1RL1Me): ‚ÄúFDA-cleared artificial intelligence and machine learning-based medical devices and their 510(k) predicate networks‚Äù\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ The US Food and Drug Administration is clearing an increasing number of artificial intelligence and machine learning (AI/ML)-based medical devices through the ****510(k) pathway.****\xa0This pathway allows clearance if the device is substantially equivalent to a former cleared device (ie, ****predicate****). We analysed the predicate networks of cleared AI/ML-based medical devices (cleared between 2019 and 2021), their underlying tasks, and recalls. More than****a third of cleared AI/ML-based medical devices originated from non-AI/ML-based medical devices****in the first generation. Devices with the longest time since the last predicate device with an AI/ML component were haematology (2001), radiology (2001), and cardiovascular devices (2008). Especially for devices in radiology, the AI/ML ****tasks changed frequently****along the device's predicate network, ****raising safety concerns****. To date, only a few recalls might have affected the AI/ML components. To improve patient care, a stronger focus should be placed on the distinctive characteristics of AI/ML when defining substantial equivalence between a new AI/ML-based medical device and predicate devices.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ On the basis of the risks of the devices, the FDA ****clears medical devices through three main pathways****: approval through the premarket approval pathway, authorisation via the de novo premarket review, and clearance via the 510(k) pathway.[3](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00126-7/fulltext%23&sa=D&source=editors&ust=1717021441073703&usg=AOvVaw0ya7Bc6JFxIV9aDmS44YTF), \xa0[7](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00126-7/fulltext%23&sa=D&source=editors&ust=1717021441073858&usg=AOvVaw1ZDDTm_2KDHtebAmsCQHiJ)\xa0For simplicity, we use the term clearance to refer to the marketing authorisation of the devices via all pathways.\n', '\n', '[Aboy et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-024-01021-y&sa=D&source=editors&ust=1717021441074149&usg=AOvVaw2j37RY205L2xTNNJ5iNe0l): ‚ÄúBeyond the 510(k): The regulation of novel moderate-risk medical devices, intellectual property considerations, and innovation incentives in the FDA‚Äôs De Novo pathway‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Moderate-risk medical devices constitute 99%****\xa0of those that have been regulated by the U.S. Food and Drug Administration (FDA) since it gained authority to regulate medical technology nearly five decades ago. This article presents an analysis of the interaction between the****510(k) process****\xa0‚Äîthe historically dominant path to market for most medical devices‚Äî and the****De Novo pathway****, a more recent alternative that ****targets more novel devices****, including those involving new technologies, diagnostics, hardware, and software.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ **==**==The De Novo pathway holds significant potential for innovators==**==**\xa0seeking to define new categories of medical devices, as it represents a **==**==less burdensome approach==**==**\xa0than would have otherwise been needed historically. Moreover, it supports the FDA in its effort to modernize the long-established 510(k) pathway by promoting the availability of up-to-date device ‚Äúpredicates‚Äù upon which subsequent device applications can be based, reflecting positive spillovers that are likely to encourage manufacturers to adopt current state-of-the-art technologies and modern standards of safety and effectiveness. We analyze the of characteristics all the De Novo classification requests to date, including the submission type, trends, FDA review times, and device types. After characterizing how the De Novo process has been used over time, we discuss its unique challenges and opportunities with respect to medical device software and AI-enabled devices, including considerations for intellectual property, innovation, and competition economics.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image73.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image20.png)\n', '\n', '****510(k) Search****Created by\xa0[Innolitics](https://www.google.com/url?q=https://innolitics.com/&sa=D&source=editors&ust=1717021441074995&usg=AOvVaw3NDTX6srXALPs-IIsaisVv). Your SaMD Engineers.\n', '\n', '$QUOTETOBEREPLACED$ This FDA search engine allows you to quickly search through the publicly available 510(k) summaries and any of the additional data that we have extracted. For example, you can search for device indications, specific pathologies, or even narrow down submissions that have clinical studies and get a sense of their study design, including sample size, without having to dig through a PDF.\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Allows searching the current FDA clearance database, similar to using Google to search for information\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Eliminates the need to manually dig through PDF files to find details like indications for use, clinical study information, and sample sizes\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Has a search functionality to find specific terms anywhere they appear in the full text of the original 510(k) summary PDFs\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Allows viewing the searchable full text of the original FDA PDF for each entry\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Enables searching for predicate devices and finding similar devices more easily\n', '\n', '$QUOTETOBEREPLACED$ Note: Currently the Indications for use, predicate, clinical study, and sample size are AI generated. We are in the process of manually checking them for accuracy.\n', '\n', '$QUOTETOBEREPLACED$ Note: We are working on making the 510(k) summaries easier read like\xa0[](https://www.google.com/url?q=https://510k.innolitics.com/K232613-8591cb53f49e43e58f46292b140c0227?pvs%3D21&sa=D&source=editors&ust=1717021441075561&usg=AOvVaw3TURxYMrefwkWg-EzLOJOk)[K232613](https://www.google.com/url?q=https://510k.innolitics.com/K232613-8591cb53f49e43e58f46292b140c0227?pvs%3D21&sa=D&source=editors&ust=1717021441075709&usg=AOvVaw0lvDMTBLdK6sfD-VoDVpL2)\n', '\n', '$QUOTETOBEREPLACED$ Note: We are working on adding educational commentary to 510(k) summaries like\xa0[](https://www.google.com/url?q=https://510k.innolitics.com/K232613-8591cb53f49e43e58f46292b140c0227?pvs%3D21&sa=D&source=editors&ust=1717021441075947&usg=AOvVaw0ahVgduWpVVHdWybhPijn7)[K232613](https://www.google.com/url?q=https://510k.innolitics.com/K232613-8591cb53f49e43e58f46292b140c0227?pvs%3D21&sa=D&source=editors&ust=1717021441076084&usg=AOvVaw0_u2D9hPsqSPZAWvBOzUL5)\n', '\n', '$QUOTETOBEREPLACED$ [Tool Demo.mp4](https://www.google.com/url?q=https://prod-files-secure.s3.us-west-2.amazonaws.com/db330276-bae0-48e7-b9af-63e33e8920fd/1c3bb988-5666-4bd6-8def-8dfcfe9aeebf/Tool_Demo.mp4&sa=D&source=editors&ust=1717021441076447&usg=AOvVaw3nPHP4Xm38-lGwF5nkJ2KO)\n', '\n', '$QUOTETOBEREPLACED$ [510(k) Search](https://www.google.com/url?q=https://510k.innolitics.com/917f93f44984457c934072b48289e965?pvs%3D21&sa=D&source=editors&ust=1717021441076672&usg=AOvVaw1bcHjVh3zkqFq0pHHfRJ-4)\n', '\n', '[510(k) / De Novo / PMA](https://www.google.com/url?q=https://www.linkedin.com/posts/esugalski_medtech-medicaldevices-regulatory-activity-7170780413429174272-GgTq?utm_source%3Dshare%26utm_medium%3Dmember_desktop&sa=D&source=editors&ust=1717021441076907&usg=AOvVaw0prAMNishsjIK-PLlZfMba)\n', '\n', '$QUOTETOBEREPLACED$ Have you heard the 510(k) fallacy?\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image144.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image31.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image201.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image36.png)\n', '\n', '[J. David Giese](https://www.google.com/url?q=https://www.linkedin.com/in/jdavidgiese?miniProfileUrn%3Durn%253Ali%253Afsd_profile%253AACoAAAXu48gB-h3ImcTTAp2FEI-bOT5hWUvSedI%26lipi%3Durn%253Ali%253Apage%253Ad_flagship3_detail_base%253BwI1pmCz2TQmXxRD0be%252BNsg%253D%253D&sa=D&source=editors&ust=1717021441077720&usg=AOvVaw3yjLOTeuqy7bcVjahrm2OE)\xa0New FDA Draft Guidance on the use of LLMs and ChatGPT in FDA review and quality systems!\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image116.png)  \n', '[https://innolitics.com/articles/april-fools-joke-2024/](https://www.google.com/url?q=https://innolitics.com/articles/april-fools-joke-2024/&sa=D&source=editors&ust=1717021441077958&usg=AOvVaw3vBjbBszS9i72HugtuTsC0)\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ I\'m very excited about this guidance and continue to be impressed with FDA\'s engagement within the evolving AI/ML space. The full title of the draft guidance is "Recommendations and Risk Assessment of Generative (AI/ML)-Enabled Quality Management and Premarket Submission Review"\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ This guidance outlines the FDA's approach to leveraging the capabilities of large language models (LLMs) like ChatGPT, Llama, Claude, and PaLM to streamline quality management and FDA's premarket submission review process.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Here are my key takeaways from the draft guidance:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 1Ô∏è‚É£ Least Burdensome Approach: The guidance identifies generative AI as the least burdensome approach for achieving numerous regulatory and quality management objectives, thereby accelerating the delivery of innovative healthcare solutions to the market while balancing it with the need to ensure devices are safe and effective.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 2Ô∏è‚É£ Scope: The scope is limited to Premarket Notification (510(k)), Product Development Protocols (PDPs), Investigational Device Exemption (IDE) submissions, Humanitarian Device Exemption (HDE) submissions. It specifically excludes De Novo requests and Premarket Approval Applications (PMAs).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 3Ô∏è‚É£ Adoption of Generative AI: Recognizing the widespread use of generative AI tools (e.g., ChatGPT, Llama, Claude, and PaLM), this guidance emphasizes how these technologies can enhance review efficiencies, balancing the need to ensure safe and effective medical innovation with the least-burdensome approach.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 4Ô∏è‚É£ Risk-Based Application: The guidance recommends a risk-based approach to the application of generative AI, advocating for broader use in reviewing submissions for commonly used devices.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ 5Ô∏è‚É£ Generative AI for Quality Systems Improvement: The draft guidance also highlights the potential for medical device manufacturers and quality professionals to employ generative AI in enhancing their quality management systems. It suggests a risk-based approach to validating the use of generative AI which is consistent with the Software Validation Guidance.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Seeking FDA clearance for AI/ML? Read these FDA guidance "hiding" üôà in plain sight!](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7179197220695478273/?updateEntityUrn%3Durn%253Ali%253Afs_updateV2%253A%2528urn%253Ali%253Aactivity%253A7179197220695478273%252CFEED_DETAIL%252CEMPTY%252CDEFAULT%252Cfalse%2529&sa=D&source=editors&ust=1717021441079164&usg=AOvVaw1wo83uSu1VRbFUY6MWktkF)\n', '\n', "$QUOTETOBEREPLACED$ It's true that FDA hasn't finalized any AI/ML-specific guidance. (They do have the draft PCCP guidance.) However, these three guidance may be worth reading:\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ üìó 2022 September - Clinical Performance Assessment: Considerations for Computer-Assisted Detection Devices Applied to Radiology Images and Radiology Device Data in - Premarket Notification (510(k)) Submissions ([https://lnkd.in/eFF5XFCD](https://www.google.com/url?q=https://lnkd.in/eFF5XFCD&sa=D&source=editors&ust=1717021441079497&usg=AOvVaw0deJt5z2bbuaOhEUsTFcjX))\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ üìó 2022 September - Computer-Assisted Detection Devices Applied to Radiology Images and Radiology Device Data - Premarket Notification [510(k)] Submissions ([https://lnkd.in/edaB8u3H](https://www.google.com/url?q=https://lnkd.in/edaB8u3H&sa=D&source=editors&ust=1717021441079691&usg=AOvVaw37HtJN-k9VbAfJeYumiJ9a))\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ üìó 2022 June - Technical Performance Assessment of Quantitative Imaging in Device Premarket Submissions ([https://lnkd.in/eHfyNM8e](https://www.google.com/url?q=https://lnkd.in/eHfyNM8e&sa=D&source=editors&ust=1717021441079873&usg=AOvVaw0eTxvj3u1-6iCpKJ0JyKuB))\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ "But wait, David, these are for radiology software! My SaMD is for {cardiology, neurology, ophthalmology, dentistry, neurology, ...}"\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ True. The first two of these are for radiology, and the last is for imaging. (After all, in 2022, 87% of cleared AI/ML devices were in radiology.)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ Until FDA releases general AI/ML guidance, there is a lot to learn from these. They reveal some of FDA's thinking on topics such as:\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ‚û° How to describe your models in your 510(k) submissions\n', '\n', '$QUOTETOBEREPLACED$ ‚û° Generalizability testing\n', '\n', '$QUOTETOBEREPLACED$ ‚û° Reporting training details\n', '\n', '$QUOTETOBEREPLACED$ ‚û° Pooling non-US data\n', '\n', '$QUOTETOBEREPLACED$ ‚û° Test data re-use\n', '\n', '$QUOTETOBEREPLACED$ ‚û° Contraints on test dataset design\n', '\n', '$QUOTETOBEREPLACED$ ‚û° Sources of bias in study design\n', '\n', '$QUOTETOBEREPLACED$ ‚û° And more.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ üí° You'll need to read between the lines to see what applies to you, but they are useful beyond their explicit scope and better than nothing. We've even had FDA refer to these guidance a couple of times on submissions in other areas.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ I hope they are useful! If you find anything specific useful, post in the comments. Also, if there are other FDA guidance you think would be useful to AI/ML medtech companies, post that in the comments too!\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ üîó BTW The links are to our Innolitics HTML-transcripts of the guidance. We use these since they're linkable, unlike the PDFs.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ üìö You may also want to see all of our AI/ML resources here:\xa0[](https://www.google.com/url?q=https://lnkd.in/e5fUJJFb&sa=D&source=editors&ust=1717021441080828&usg=AOvVaw0pTv2kGPvYkViSeak4soJZ)[https://lnkd.in/e5fUJJFb](https://www.google.com/url?q=https://lnkd.in/e5fUJJFb&sa=D&source=editors&ust=1717021441080919&usg=AOvVaw3IDPcREoM9J5UEtF1PrjkT)\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Rudolf Wagner](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAEsJakBitC2el5NxXkkkWOh_whajmFTMvw?lipi%3Durn%253Ali%253Apage%253Ad_flagship3_detail_base%253BYiDsg5J5TQCZSRZzNE2a6A%253D%253D&sa=D&source=editors&ust=1717021441081131&usg=AOvVaw3KNHk-LrRd9dqLp3LSWeMv)\xa0And how do you think AI radiology and the other 800 AI / ML have been approved ? Right, all of them as Software as a Medical Device (SaMD). As defined here for ALL AI / ML:\xa0[https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device&sa=D&source=editors&ust=1717021441081351&usg=AOvVaw2xVJGKOr9VwcrvM2VeoSmj)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Yujan Shrestha, MD](https://www.google.com/url?q=https://www.linkedin.com/in/yujanshrestha?miniProfileUrn%3Durn%253Ali%253Afsd_profile%253AACoAABdjo3MBZr5zp8qjGVxqIcSB2fyAXbxFGnM%26lipi%3Durn%253Ali%253Apage%253Ad_flagship3_detail_base%253Bo111w%252Fj2TViuoTLMcuQB8w%253D%253D&sa=D&source=editors&ust=1717021441081640&usg=AOvVaw2gAPGkLtU_MjAuIKHrYeG6)\xa0[Here are some common cybersecurity objections from FDA.](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7181337034978988032/?updateEntityUrn%3Durn%253Ali%253Afs_updateV2%253A%2528urn%253Ali%253Aactivity%253A7181337034978988032%252CFEED_DETAIL%252CEMPTY%252CDEFAULT%252Cfalse%2529&sa=D&source=editors&ust=1717021441081845&usg=AOvVaw0Rju8NJDkYINv0aicrnW8h)\n', '\n', '$QUOTETOBEREPLACED$ Sometimes I am able to convince FDA that some cybersecurity requirements do not apply for a device. However, the following objections are more difficult to overcome and sponsors should comply instead of trying to push back.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image82.png)\n', '\n', '##### FDA AI Devices\n', '\n', 'Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices\n', '\n', '[https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices&sa=D&source=editors&ust=1717021441082431&usg=AOvVaw2WbHl6qxGzccJRU9FRiCj-)\xa0\n', '\n', "[Young Joon Kim et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.joitmc.2024.100220&sa=D&source=editors&ust=1717021441082625&usg=AOvVaw3fTcwbpj5sLXS7V5qEqxaB): ‚ÄúMedical Professionals' Adoption of AI-based Medical Devices: UTAUT Model with Trust Mediation‚Äù\n", '\n', "$QUOTETOBEREPLACED$ The purpose of this study is to identify **==**==the factors impacting medical professionals‚Äô adoption intention of AI-based innovative medical devices focused on the mediating role of trust==**==**. Drawing on the UTAUT model, we examined the mediating effect of trust in the relationships between these factors (performance expectancy, effort expectancy, facilitating conditions, and social influence). This study collected survey data through convenient sampling from ****248 medical professionals****\xa0working in medical institutions located in the metropolitan areas in Republic of ****Korea****. The result showed that performance expectancy, effort expectancy, facilitating conditions, and social influence have a positive impact on trust, and this trust, in turn, has a significant influence on acceptance intentions. The results emphasize that **==**==the success of introducing innovative medical devices in institutions hinges not only on the devices' innovation level but also on the psychological factors of the professionals==**==**. By taking into account these factors and building trust, medical institutions can elevate service quality and efficiency, fostering greater acceptance of advanced medical devices.\n", '\n', '[Marium M. Raza](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00988-4%23auth-Marium_M_-Raza-Aff1&sa=D&source=editors&ust=1717021441083053&usg=AOvVaw1P3-wyyb45sBe4w4KjvsjK)\xa0et al. (2024): ‚ÄúGenerative AI and large language models in health care: pathways to implementation‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image211.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ [https://www.linkedin.com/posts/rudolfwagner_doi101038s41746-023-00988-4-activity-7171806868229595139-qkqQ?utm_source=share&utm_medium=member_desktop](https://www.google.com/url?q=https://www.linkedin.com/posts/rudolfwagner_doi101038s41746-023-00988-4-activity-7171806868229595139-qkqQ?utm_source%3Dshare%26utm_medium%3Dmember_desktop&sa=D&source=editors&ust=1717021441083373&usg=AOvVaw0g-xNedr2yVulZn104thhC)\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Another peer-reviewed #Nature paper with incorrect regulatory statements citing an already incorrect paper\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What is wrong?\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Quote of page2: "While the FDA has begun to adapt its regulatory framework to address AI technology as medical devices it must move from discussion to action, and provide specific guidance for LLMs13,14."\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The #FDA has not BEGUN to adapt. The Regulation of AI in healthcare as Software as a medical device is in place since at least 2017 internationally and with the FDA. Over [700 approved AI show that](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices&sa=D&source=editors&ust=1717021441083844&usg=AOvVaw0bSnb8xpvjkqiL1pYPRoZ3). The first AI / ML was approved in 1995 (!!!!!!!) as a medical device, picking up in widespread approvals in 2008.\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ LLM are Software and the current SaMD regulation is lean, comprehensive, agile and absolutely doable as MANY developers show that it is NOT stopping innovation.\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Next Quote: "The FDA can learn from the strengths as well as the criticisms of the EU‚Äôs AI Act, one of the first formal regulations for generative AI15"\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ That is ridiculous. EU AI ACT is deferring LLM, AI and ML for and in Healthcare to the EU MDR 2017/745 as Software as a medical device. EXACTLY the same as with US #FDA. NO DIFFERENCE.\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ **==**==My take on that is, that more and more papers are not really well researched for regulatory obligations.==**==**\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ When you look in the past - every NEW regulation was more complex and thorough than the previous one. I would not bet for an update of regulation but use the one we have, SaMD approval is doable in 6 months and udpates are possible in a higher frequency than ChatGPT and Claude have been updated.\n', '\n', '[March 2024](https://www.google.com/url?q=https://www.fda.gov/media/177030/download?utm_medium%3Demail%26utm_source%3Dgovdelivery&sa=D&source=editors&ust=1717021441084674&usg=AOvVaw38ez3bpIycuQgSh7sH8R5w)\xa0Artificial Intelligence & Medical Products: How CBER, CDER, CDRH, and OCP are Working Together\n', '\n', '$QUOTETOBEREPLACED$ Artificial intelligence (AI) has the potential to revolutionize health care by advancing medical product development, improving patient care, and augmenting the capabilities of health care practitioners. Aligned with its mission of protecting, promoting, and advancing public health, and building on the Agency‚Äôs longstanding commitment to support innovative work in the development and regulation of medical products, the Food and Drug Administration‚Äôs (FDA‚Äôs) Center for Biologics Evaluation and Research (CBER), Center for Drug Evaluation and Research (CDER), Center for Devices and Radiological Health (CDRH), and Office of Combination Products (OCP) are jointly publishing this paper to provide greater transparency regarding how FDA‚Äôs medical product Centers are collaborating to safeguard public health while fostering responsible and ethical innovation.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### Traditional (non-AI) medical software\n', '\n', '[FDA-2021-D-0775](https://www.google.com/url?q=https://www.regulations.gov/docket/FDA-2021-D-0775&sa=D&source=editors&ust=1717021441085237&usg=AOvVaw1OhfZXla0CJ7NbzhWOghLd): ‚ÄúContent of Premarket Submissions for Device Software Functions (Guidance for Industry and Food and Drug Administration Staff JUNE 2023)‚Äù\n', '\n', '$QUOTETOBEREPLACED$ This guidance document is intended to provide information regarding the ****recommended documentation for premarket submissions for FDA‚Äôs evaluation****\xa0of the safety and effectiveness of device software functions, which are software functions that meet the definition of a device under section 201(h) of the Federal Food, Drug, and Cosmetic Act (FD&C Act). The FDA ****recognizes this evolving landscape****\xa0and seeks to provide our latest thinking on regulatory considerations for device software functions, which considers current standards and best practices. The recommendations in this guidance are intended to ****facilitate FDA‚Äôs premarket review****. This guidance document replaces FDA‚Äôs Guidance for the Content of Premarket Submissions for Software Contained in Medical Devices issued on May 11, 2005.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The recommendations in this guidance are intended to facilitate FDA‚Äôs premarket review. This guidance describes information that would be typically generated and documented[[c]](#cmnt3)\xa0during software development, verification, and validation. During premarket review, FDA may request additional information that is needed to evaluate the submission. For example, in order to demonstrate a reasonable assurance of safety and effectiveness for devices that use software, documentation related to the requirements of the [Quality System Regulation (QSR) (21 CFR Part 820)](https://www.google.com/url?q=https://www.fda.gov/medical-devices/postmarket-requirements-devices/quality-system-qs-regulationmedical-device-good-manufacturing-practices&sa=D&source=editors&ust=1717021441085886&usg=AOvVaw12gi0TdAIdiX6pAIDz1RHM)\xa0is often a necessary part of the premarket submission. As part of QSR design controls, a manufacturer must ‚Äúestablish and maintain procedures for validating the device design,‚Äù which ‚Äúshall include software validation and risk analysis, where appropriate‚Äù (21 CFR 820.30(g)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ For the current edition(s) of the FDA-recognized consensus standard(s) referenced in this document, see the [FDA Recognized Consensus Standards Database](https://www.google.com/url?q=https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfStandards/search.cfm&sa=D&source=editors&ust=1717021441086127&usg=AOvVaw1KoMEdIKmGcndYf0MjadqI). For more information regarding use of consensus standards in regulatory submissions, please refer to the FDA guidance titled [Appropriate Use of Voluntary Consensus Standards in Premarket Submissions for Medical Devices](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/appropriate-use-voluntary-consensus-standards-premarket-submissions-medical-devices&sa=D&source=editors&ust=1717021441086308&usg=AOvVaw0EOLHuBLmmXAgUWWeh-xQ8)\xa0and [Standards Development and the Use of Standards in Regulatory Submissions Reviewed in the Center for Biologics Evaluation and Research](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/standards-development-and-use-standards-regulatory-submissions-reviewed-center-biologics-evaluation&sa=D&source=editors&ust=1717021441086492&usg=AOvVaw1uF1CBd30V-XWSwbuBClDZ).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The following guidance documents represent a subset of FDA guidances with digital health content6 relevant to premarket software documentation activities. Please note the list is not exhaustive and is subject to change:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Multiple Function Device Products: Policy and Considerations](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/multiple-function-device-products-policy-and-considerations&sa=D&source=editors&ust=1717021441086809&usg=AOvVaw0h8rdNvItzIki_N5EINl7p)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Off-The-Shelf Software Use in Medical Devices](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/shelf-software-use-medical-devices&sa=D&source=editors&ust=1717021441087009&usg=AOvVaw1-lMzG0MZQuTDRxY2_VXNt)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Design Considerations and Premarket Submission Recommendations for Interoperable Medical Devices](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/design-considerations-and-pre-market-submission-recommendations-interoperable-medical-devices&sa=D&source=editors&ust=1717021441087225&usg=AOvVaw1Bk4ucwrKXsVI9Ku8D9ea1)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [General Principles of Software Validation](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-principles-software-validation&sa=D&source=editors&ust=1717021441087416&usg=AOvVaw0x_m6vxWyXUa8jGBpnhBLV)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Content of Premarket Submissions for Management of Cybersecurity in Medical Devices](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/content-premarket-submissions-management-cybersecurity-medical-devices&sa=D&source=editors&ust=1717021441087641&usg=AOvVaw1ULh7lWwSPog7-0KE07PG6)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Cybersecurity for Networked Medical Devices Containing Off-The-Shelf (OTS) Software](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/cybersecurity-networked-medical-devices-containing-shelf-ots-software&sa=D&source=editors&ust=1717021441087857&usg=AOvVaw3AN3hQlzjfYm7fqgRNHTsi)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Applying Human Factors and Usability Engineering to Medical Devices](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/applying-human-factors-and-usability-engineering-medical-devices&sa=D&source=editors&ust=1717021441088084&usg=AOvVaw37r0tEI0SXD4qxz64wGZrB)\n', '\n', '$QUOTETOBEREPLACED$ When possible, FDA harmonized the terminology and recommendations in this guidance with software-related consensus standards, such as the following examples. The following standards are not intended to represent an exhaustive list and [are subject to change](https://www.google.com/url?q=https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfStandards/search.cfm&sa=D&source=editors&ust=1717021441088398&usg=AOvVaw36D9vLePDgpDWrlHtMRsDs):\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [ANSI/AAMI/ISO 14971](https://www.google.com/url?q=https://webstore.ansi.org/standards/aami/ansiaamiiso149712019&sa=D&source=editors&ust=1717021441088605&usg=AOvVaw0W2opU2-PeH81Dken731xO): Medical devices - Applications of risk management to medical devices\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [ANSI/AAMI/IEC 62304](https://www.google.com/url?q=https://webstore.ansi.org/standards/aami/ansiaamiiec623042006a12016&sa=D&source=editors&ust=1717021441088789&usg=AOvVaw2Y4u7Wzmu036oDKXljgCbc): Medical Device Software - Software Life Cycle Processes\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [ANSI/AAMI SW91](https://www.google.com/url?q=https://webstore.ansi.org/standards/aami/ansiaamisw912018&sa=D&source=editors&ust=1717021441088957&usg=AOvVaw3a4HUnphLFk1iizgO6Xe0a): Classification of defects in health software\n', '\n', '$QUOTETOBEREPLACED$ This guidance recommends the information to provide in a premarket submission that includes a\n', '\n', '$QUOTETOBEREPLACED$ device software function(s). For the purposes of this guidance, the term premarket submission\n', '\n', '$QUOTETOBEREPLACED$ includes, but is not limited to:  \n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ premarket notification (510(k)) submission,\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ De Novo classification request,\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Premarket Approval (PMA) application,\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Investigational Device Exemption (IDE)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Humanitarian Device Exemption (HDE)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Biologics License Application (BLA).\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Certain devices are subject to premarket review through a BLA under section 351 of the Public\n', '\n', '$QUOTETOBEREPLACED$ Health Service Act.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image114.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image30.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image167.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image149.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ If the device software function uses ML models trained through ML methods\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What methods, models, ****frameworks****, and/or platforms were used?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What ****data****\xa0(populations, samples) informed the model(s)? How, when, and where was the data collected?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What steps were taken to identify and address ****potential biases****\xa0and limitations of the model(s)?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What materials, mechanisms, and/or approaches are used to provide ****transparency****about the model‚Äôs development, performance, and limitation(s)?\n', '\n', '$QUOTETOBEREPLACED$ Software Specifics[[d]](#cmnt4)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What hardware platforms are used?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What software platforms are used? ¬ß If applicable, what ****hosting environments****\xa0are used (e.g., hospital networks, cloud infrastructures) and for what ****functions****\xa0(e.g., processing, storage)?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Does the device use ****Off-The-Shelf (OTS) software****?  \n', '    \n', '\n', '- If a device uses OTS software, FDA may request additional information in premarket submissions. For more information, please refer to the guidance document [‚ÄúGuidance for Off-The-Shelf Software Use in Medical Devices.‚Äù](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/shelf-software-use-medical-devices&sa=D&source=editors&ust=1717021441090656&usg=AOvVaw1LK24hPcuxmYBSRVCWXI9C)  \n', '      \n', '    ![](HTML%20import/Attachments/image160.png)  \n', '    \n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What is the final release version (i.e., version intended to be released to end users)? If this version is different from the documentation‚Äôs version, explain the differences. ¬∑\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Software Inputs and Outputs\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What are the inputs and their format? Examples: signals, images (specify ****modality****), measurements (specify units), reports, questionnaires, other device data/results.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Who or what ****provides the inputs?****\xa0Examples: patients, caregivers, healthcare professionals, technicians, sensors/attachments, signal acquisition systems, in vitro diagnostic devices, other medical devices, other non-medical products or software.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What are the ****outputs and their format****? Examples: diagnostic information, treatment information, control signals for device hardware, images (specify modality), measurements (specify units), alarms, alerts, or reports.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Who or what ****receives the outputs?****\xa0Examples: patients, caregivers, healthcare professionals, technicians, health records, device hardware, other medical devices, interoperable systems.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Does the software impact or****replace any action(s) otherwise performed manually****\xa0by a health care professional, patient, caregiver, or other operator? What are the ****clinical workflow steps****\xa0and assumptions (from beginning to end state)? Examples: automates steps, triages patients, provides a definite diagnosis or suggests likely diagnosis for further confirmation by physician, performs or recommends specific treatment, identifies a region of interest for further review.\n', '\n', '$QUOTETOBEREPLACED$ While this guidance identifies the documentation sponsors should include in premarket submissions, this guidance is not meant to provide recommendations regarding how device software should be developed, verified, and validated. This guidance does not recommend the use of any ****specific software life cycle model****or development methodology (such as waterfall model or other variations thereof, spiral model, Agile model, etc.). Sponsors should establish a software life cycle model that is ****appropriate for their product and organization****, and meets the applicable regulatory requirements. The software life cycle model that is selected should ****cover the software throughout its total product life cycle****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Regardless of the software lifecycle model being utilized, sponsors should ensure that the establishment of their************design history file****\xa0(DHF)[[e]](#cmnt5)\xa0documentation is synchronized with their software development, verification, and validation efforts. ****DHF documentation****\xa0that is created retrospectively or following a prolonged period of time after actual software development, verification, and validation efforts could raise concerns regarding whether a developer has adequate control of their design process. For recommendations on device software development, verification, and validation, please consult software-related FDA-recognized voluntary consensus standards and other software-related FDA guidance documents referenced in this guidance (e.g., [‚ÄúGeneral Principles of Software Validation‚Äù](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/general-principles-software-validation&sa=D&source=editors&ust=1717021441091937&usg=AOvVaw0dBkagjnXzP8Lu_oaprbhU)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The risk management file should be provided as part of the premarket submission and include the following documentation. FDA recommends sponsors refer to an FDA-recognized version of [ISO 14971](https://www.google.com/url?q=https://www.iso.org/standard/72704.html&sa=D&source=editors&ust=1717021441092169&usg=AOvVaw3LljYdoRI_KGuX9luCAXbk)\xa0for additional information on the development and application of a risk management file.\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image122.png)\n', '\n', '$QUOTETOBEREPLACED$ ****Software Verification and Software Validation****\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Software verification involves evaluating the consistency, completeness, and correctness of the software and its supporting documentation, as it is being developed, and provides support for a subsequent conclusion that software is validated. ****Software testing****\xa0is one of several verification activities intended to confirm that the software development output meets its input requirements. Other verification activities include ****source code evaluations****\xa0(e.g., code inspections and walkthroughs), document inspections, design reviews, technical evaluations (e.g., software architecture, software detailed design, etc.) and****traceability****analyses (e.g., software requirements specification to software design specification (and vice versa), source code to software design specification (and vice versa), and test cases to source code and to software design specification). For example, the input and output of the design phase are known as Software Requirements Specification (SRS) and Software Design Specification (SDS), respectively. In this case, software verification would involve confirming by objective evidence (e.g., reviews, traceability analysis) that the software design as documented in the SDS (i.e., output)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The recommended documentation for a premarket submission depends on the ****device‚Äôs risk to a patient****, a user of a device, or others in the environment of use. FDA intends to take a risk-based approach to help determine the device‚Äôs Documentation Level, which is either****Basic****\xa0or ****Enhanced****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image44.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image118.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image130.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image216.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image143.png)  \n', '[ANSI/AAMI/IEC 62304 Medical Device Software - Software Life Cycle Processes](https://www.google.com/url?q=https://www.iso.org/standard/38421.html&sa=D&source=editors&ust=1717021441093183&usg=AOvVaw3eeOrjG1Nnf4VdXoqsY506)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image56.png)  \n', '![](HTML%20import/Attachments/image158.png)\n', '\n', '$QUOTETOBEREPLACED$ Unit, integration, and system level tests\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image170.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image115.png)Additionally, the Agency recommends considering the utilization of a defect classification system, or taxonomy, for each anomaly, such as [ANSI/AAMI SW91‚Äôs Classification of defects in health software](https://www.google.com/url?q=https://webstore.ansi.org/standards/aami/ansiaamisw912018&sa=D&source=editors&ust=1717021441093655&usg=AOvVaw165S4Mfh5gHlRa7u8ie3Zh). Regardless of the defect classification system used, the sponsor should evaluate the impact of an unresolved anomaly on the device‚Äôs safety and effectiveness based on the software‚Äôs intended use.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image179.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '#### ANSI/AAMI/IEC 62304: Medical Device Software - Software Life Cycle Processes\n', '\n', '![](HTML%20import/Attachments/image66.png)  \n', '[https://www.sdcsystems.com/tools/intland-software/codebeamer/alm-medical-device-development/](https://www.google.com/url?q=https://www.sdcsystems.com/tools/intland-software/codebeamer/alm-medical-device-development/&sa=D&source=editors&ust=1717021441094095&usg=AOvVaw2mIko3wB_L9mlS_e1jwkMU)\xa0\n', '\n', '![](HTML%20import/Attachments/image91.png)  \n', '[https://qbdgroup.com/en/industries/medical-devices/medical-device-software/](https://www.google.com/url?q=https://qbdgroup.com/en/industries/medical-devices/medical-device-software/&sa=D&source=editors&ust=1717021441094300&usg=AOvVaw0u3irwhs9H8DGnhD4g9qE6)\xa0\n', '\n', '[2018](https://www.google.com/url?q=https://sunstonepilot.com/2018/09/fda-software-guidances-and-the-iec-62304-software-standard/&sa=D&source=editors&ust=1717021441094469&usg=AOvVaw26hquLQV-LGEUfK0uOY-cJ): ‚ÄúFDA Software Guidances and the IEC 62304 Software Standard‚Äù\n', '\n', '$QUOTETOBEREPLACED$ My recommendation is to**==**==base your software development procedures on the IEC 62304 Standard==**==**, which is easier to understand, and then include any additional adjustments needed to meet all the FDA requirements.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The IEC 62304 medical device software standard (‚ÄúMedical device software‚ÄîSoftware life cycle processes‚Äù) is comprised of five processes in five chapters (5-9):\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****5 ‚Äì Software Development Process****\xa0= this is the main process that SW groups are focused on and includes all the key aspects of development from planning and requirements to testing and release\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****6 ‚Äì Software Maintenance Process****\xa0= this is an abridged form of the main software development process and is intended to quickly release patches for SW bugs and security risks\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****7 ‚Äì Software Risk Management Process****\xa0= risk assessment of SW failures as well as management of SW safety features which serve as risk controls for HW failures, for use error, and for other system failures\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****8 ‚Äì Software Configuration Management Process****= source code control system/ development environment and how to manage builds and releases\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****9 ‚Äì Software Problem Resolution Process****= bug tracking system and how your organization evaluates bugs and related activities to resolve issues\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The diagram below shows 4 of these 5 processes (numbered 5-9, but missing 6) and their relationship to overall system validation. Note that the 62304 standard****does not cover system validation or other system development activities****‚Äîit only covers up to ‚ÄúSW System Testing.‚Äù **==**==FDA SW Guidances have a much broader scope==**==**, including system validation and development of non-product software.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image218.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The Software Development Process (#5) consists of 8 key activities:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '1. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW Development ****Planning****‚Äì defining the scope of the SW development project\n', '2. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW ****Requirements****\xa0Analysis ‚Äì decomposing system/product requirements into software requirements within the context of the system architecture design (identifying the system functions that are to be implemented in software)\n', '3. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW ****Architectural Design****‚Äì high level design of the software, including partitioning/segregation of high-risk software, as appropriate\n', '4. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW ****Detailed Design****\xa0‚Äì defining the SW units and their interfaces, including state diagrams, data structures, and risk controls (the software engineer‚Äôs view of how the SW will function)\n', '5. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW ****Unit Implementation & Verification****\xa0‚Äì the core of SW development; coding and testing\n', '6. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW ****Integration & Integration Testing****\xa0‚Äì merge software units and demonstrate that multiple software components work properly together and with the system hardware\n', '7. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW System Testing ‚Äìverification of software against the SW requirements in a system environment\n', '8. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ SW Release ‚Äì deploying a controlled, verified version of SW\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ One of the challenges in understanding the 62304 standard is that it has its own language. For example, here are some terms from it that often confuse newcomers:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Anomaly****\xa0= software bug\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****SOUP****\xa0= Software Of Unknown Provenance; basically Off-the-Shelf (OTS) software but can also include legacy software that was not documented\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Software Item****\xa0= a software component or module (a part of a complete ‚Äúsoftware system‚Äù)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Software Unit****\xa0= the smallest software item\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Configuration Item****= a software item that can be identified and tracked in the build system (e.g., a SW library from a 3rd party that is tracked by its own version number)\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Problem Resolution****\xa0= bug tracking and evaluating bugs and documenting the resolution of bugs\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****General Principles of Software Validation (GPSV)****However, there are some particular points that stand out in the guidance:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ One of the most important points: ‚Äúsoftware testing by itself is not sufficient to establish confidence that the software is fit for its intended use.‚Äù In other words, **==**==detailed software test reports alone are not sufficient to claim that medical device software is safe and effective==**==**.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ‚ÄúBecause of its complexity, the development process for software should be even more tightly controlled than for hardware, in order to prevent problems that cannot be easily detected later in the development process.‚Äù Translation: you will ****need additional procedures and documentation for software development****\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The importance of risk analysis throughout development and particular practices for safety-critical software, such as defining risk controls in the software requirements\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Typical software documentation****So what documents does your SW team need to produce? \xa0The answer, ****unfortunately, is rarely a simple list****. The required documents, document names, and approaches all vary depending on the company, its quality system, and its products. But they all seek to answer these essential questions:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What are our goals for this SW development project?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ How are we organizing the project for success?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What does the SW need to do?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ How can the SW hurt someone?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ How have we designed the SW?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What is the test evidence that the SW does what it needs to do?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What are the remaining bugs and are any of them a safety risk?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What SW was tested?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ What changes were made between tests?\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ How do we make sure the right SW is installed in the product?  \n', '    \n', '\n', '$QUOTETOBEREPLACED$ (For example, the Software Requirements Specification document answers question #3)\n', '\n', '$QUOTETOBEREPLACED$ Now, how much documentation is enough? How detailed do these documents need to be?\n', '\n', '[RETINA-AI Health (2021](https://www.google.com/url?q=https://medium.com/retina-ai-health-inc/iec-62304-medical-device-software-lifecycle-processes-2b7967577c3f&sa=D&source=editors&ust=1717021441097581&usg=AOvVaw3qHo1gzluYizj7H76vTPsv)): ‚ÄùIEC 62304: Medical Device Software LifeCycle Processes‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image187.png)\n', '\n', '$QUOTETOBEREPLACED$ [https://medium.com/retina-ai-health-inc/iec-62304-medical-device-software-lifecycle-processes-2b7967577c3f](https://www.google.com/url?q=https://medium.com/retina-ai-health-inc/iec-62304-medical-device-software-lifecycle-processes-2b7967577c3f&sa=D&source=editors&ust=1717021441097921&usg=AOvVaw3yje6eYPVo9g9E_f8TMJrK)\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In IEC 62304, the process specifications are based on the the medical device software‚Äôs Safety Class: A, B, or C.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Class A: No injury or damage to health possible\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Class B: Injury possible, but not serious\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Class C: Death or serious injury possible\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image188.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****3.29: SOUP (Software of Unknown Provenance)****: ‚ÄúSoftware item that is already developed and generally available and that has not been developed for the purpose of being incorporated into the medical device (also known as ‚Äúoff-the-shelf software) or software item previously developed for which adequate records of the development processes are not available‚Äù\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Clause 4: General Requirements****specifies the need for a Quality Management System, Risk Management, Software Safety Classification, and handling of Legacy Software.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [Quality Management System](https://www.google.com/url?q=https://www.iso.org/standard/59752.html&sa=D&source=editors&ust=1717021441098664&usg=AOvVaw1bHaLBb0V6zMWhLPczqIh1)[: ISO 13485](https://www.google.com/url?q=https://www.iso.org/standard/59752.html&sa=D&source=editors&ust=1717021441098806&usg=AOvVaw0mDBsD9WpuJP2cDUMvgHiL)\xa0is the international standard for quality management system for medical device manufacturers. Compliance with other national regulation for QMS are allowed. For example, in the U.S., the Food and drug Administration (FDA) currently utilizes [21 CFR 820](https://www.google.com/url?q=https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/CFRSearch.cfm?CFRPart%3D820&sa=D&source=editors&ust=1717021441098967&usg=AOvVaw0_62urgqLIgYv-2lVdkxsa). However, there are imminent plan to transition to ISO 13485.\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Risk Management:****IEC 62304 requires manufacturer to be in compliance with the standard for risk management [ISO 14971:2019](https://www.google.com/url?q=https://www.iso.org/standard/72704.html&sa=D&source=editors&ust=1717021441099184&usg=AOvVaw328OyKjCyqipwl5z-KptH4).\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ****Legacy Software:****\xa0[IEC 62304 Sub-clause 4.4](https://www.google.com/url?q=https://silo.tips/download/2015-all-rights-reserved-3&sa=D&source=editors&ust=1717021441099413&usg=AOvVaw28Il0ufdUdnl9lqb4OKEAT)\xa0outlines steps manufacturer must take if choosing to incorporate legacy software into the medical device. These steps include risk management activities, gap analysis, gap closure, and rationale for use of legacy software.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Clause 5: Software Development Process****\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Clause 6: Software Maintenance Process:****This clause specifies the need for a software maintenance plan and software maintenance processes. This includes details on problem reporting, feedback evaluation, problem resolution process, change request analysis and approval, communication with users and regulators, risk-management of maintenance processes, and software re-release after maintenance activities.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Clause 7: Software Risk Management Process****\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '![](HTML%20import/Attachments/image209.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Clause 8: Software Configuration Management Process****\xa0This clause mandates documentation and implementation of configuration items, their change control, traceability, and verification. Including change verification, traceability, and overall configuration status accounting.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Clause 9: Software Problem Resolution Process****\xa0This clause specifies need for a process for problem resolution. It includes identification of the problem, reporting, problem investigation and analysis, resolution, change control, communication with affected parties, problem resolution, verification of problem resolution, and documentation.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[2021](https://www.google.com/url?q=https://www.pharmalex.com/thought-leadership/blogs/development-and-lifecycle-management-of-software-as-a-medical-device/&sa=D&source=editors&ust=1717021441100321&usg=AOvVaw1hHFvGQJvLs_gByvCJLYxY): ‚ÄúDevelopment and Lifecycle Management of Software as a Medical Device‚Äù\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image83.png)\n', '\n', '$QUOTETOBEREPLACED$ AIntegral to the life cycle management of a SaMD product is establishing a quality management system (QMS) design. Internationally, there are standards and regulations that provide a framework for implementing a QMS based on best practices, such as ISO 13485 and the [IMDRF SaMD application of the QMS draft guidance](https://www.google.com/url?q=http://www.imdrf.org/consultations/cons-samd-aqms-150326.asp&sa=D&source=editors&ust=1717021441100630&usg=AOvVaw1onsab_IV6-MY1jM_TaEPh).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Design Verification and Validation Process****Design verification involves unit testing, integration testing and can be conducted in ****an iterative process****. \u200bOnce all the software requirements have been implemented and verified, a ****design freeze is approved allowing a release candidate****to be ready for design validation during the design transfer phase. \u200bThe design validation **==**==may then involve user acceptance testing, usability validation and clinical validation==**==**. At the completion of the design verification and validation process, the final software is approved for release as a stable build to the corresponding production platform or commercial use environment and any changes should be managed through software version and change control procedures.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image61.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Usability engineering in development****SaMD manufacturers also should adopt u****sability engineering processes****, based on international standards (such as IEC 62366-1), early in development to ensure their product achieves reasonable usability and to minimize user errors and associated user risks. Usability engineering begins during the design phase with defining the preliminary user interface and user experience (UI/UX) requirements. This allows manufacturers to identify potential hazards, such as user errors and foreseen misuse.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image26.png)\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ [The HFE Approach for MD Design and Validation.](https://www.google.com/url?q=https://www.researchgate.net/publication/337888151_Impact_of_Design_on_Medical_Device_Safety&sa=D&source=editors&ust=1717021441101310&usg=AOvVaw08C2kkjJkc4XHQSc9-2wlf)\xa0The Necessary Procedures are Highlighted with a Blue Frame, While the Optional Processes, Which Depend on the Device or Results of the Use Validation Study, are Highlighted with Pink and Yellow Frames.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Post-marketing surveillance considerations****Once the software is produced and released, regulators expect manufacturers to **==**==collect and analyze post-marketing data for the life of the device==**==**. Due to the flexible nature of software, it is possible to incorporate mechanisms within the software to collect that data for regular monitoring and review.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ There are four key post-marketing activities that SaMD manufacturers must follow. These include:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Issue management, covering processes for adverse event monitoring, complaints and record processing, problem resolution processing.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Information security or cyber security, covering processes for monitoring vulnerabilities and threats and reducing the risk of attacks.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Software maintenance, applying standard software processes for managing user requirement changes and enhancements, managing third party software changes, managing configuration changes, for example platform or OS changes.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Quality assurance, either built into the software or defining processes to gather customer feedback. Specifically, building into the design functions the ability to gather quality metrics such as quality of input or process data.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '##### Traditional SW development vs Medical SW development\n', '\n', '[2021](https://www.google.com/url?q=https://sunstonepilot.com/2021/08/documentation-for-medical-device-software/&sa=D&source=editors&ust=1717021441102141&usg=AOvVaw0-WDcfrbiAcs-sJoc7CuMh): ‚ÄúDocumentation for Medical Device Software‚Äù\n', '\n', '$QUOTETOBEREPLACED$ There is a ****basic mismatch****\xa0between modern software development methods and medical device regulatory compliance documentation. Anyone familiar with agile methods for software development knows that ****agile emphasizes working software over documentation****\xa0and that eliminating unnecessary documentation helps agile teams be more productive and flexible. Right?\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ But in the highly regulated world of medical devices, there is a lot of necessary documentation. Therefore the ****goal****\xa0for agile teams developing medical software is ****not to eliminate documentation****\xa0but **==**==to be as efficient as possible in generating and updating the software documentation==**==**. Another way to think about this is that the definition of done for a software team is not just finished software, it‚Äôs also delivering completed software documentation.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image205.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image164.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image182.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ That‚Äôs a long list of documents and every time the team makes a change to the software they need to update some or all of the software documentation. \xa0Think about the impact of that on your software team‚Äì**==**==it can easily take longer to update all the documentation than to update the software!==**==**\xa0 What to do?\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ This is where **==**==automatic generation of documentation==**==**\xa0from software tools makes a huge difference. \xa0First consider the documents that are most frequently affected by changes to the software: requirements, design, test, and trace documents. \xa0Then look at the information already stored and managed in the team‚Äôs development tools and develop ways to extract that information into the formal compliance documentation. For example, e****xporting a set of test cases from a test management tool****\xa0and turning them into a formal software test protocol document, signed off in Doc Control.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In my experience, once a software team has gone through the laborious process of creating all the documentation by hand, they can be very resourceful**********==**==in figuring out ways to automatically generate document content==**==**. \xa0Investing time up front on this kind of automation will save time on every subsequent software release.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image40.png)\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image75.png)  \n', '**Pers. comm.**Florian Scherer, [http://cleary.ai/](https://www.google.com/url?q=http://cleary.ai/&sa=D&source=editors&ust=1717021441103394&usg=AOvVaw1ZWLw4DQBoWboWmu9bgVsk)\xa0  \n', '\n', '#### Medical DevOps\n', '\n', 'See [‚ÄúMLOps Tools Research‚Äù](https://www.google.com/url?q=https://docs.google.com/document/d/13fpVkEBEUc74Ywj-p525s9Z0urUMob7OI_-rpjMC_y4/edit?usp%3Dsharing&sa=D&source=editors&ust=1717021441103677&usg=AOvVaw2YsZt5Ejnj9sRhC6RJUpOu)\n', '\n', '[Laukkarinen et al. (2017)](https://www.google.com/url?q=https://doi.org/10.1109/ICSE-NIER.2017.20&sa=D&source=editors&ust=1717021441103855&usg=AOvVaw2Uok3AsvpJDzMaDeQu_7U1): ‚ÄúDevOps in Regulated Software Development: Case Medical Devices‚Äù | [Laukkarinen et al. (2018)](https://www.google.com/url?q=https://doi.org/10.1016/j.infsof.2018.01.011&sa=D&source=editors&ust=1717021441103965&usg=AOvVaw165udywgIXWz9nfO4abk4a): ‚ÄúRegulated software meets DevOps‚Äù \xa0[Cited by 63](https://www.google.com/url?q=https://scholar.google.co.uk/scholar?cites%3D5123810216483637640%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441104108&usg=AOvVaw3RS-a4y33KVvKrS3DwviY7)\n', '\n', '$QUOTETOBEREPLACED$ This paper discusses the****fit of DevOps for regulated medical device software development****. We examine two related standards, IEC 62304 and IEC 82304-1, for obstacles and benefits of using DevOps for medical device software development. We found **==**==these standards to set obstacles for continuous delivery and integration (CI/CD)==**==**. Respectively, development tools can help fulfilling the requirements of traceability and documentation of these standards.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image51.png)\n', '\n', '$QUOTETOBEREPLACED$ An illustration of the traceability requirements of IEC 63204 life-cycle between Requirement B and software (SW) Item 2. The sub-processes and their items are omitted for presentation clarity.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image110.png)\n', '\n', '$QUOTETOBEREPLACED$ An example of hierarchical use of tools. The shaded boxes indicate actions that the tools could help perform through automation during the workflow. For example, creating a software item would link it to a requirement, create a stub file, version control it, and open the preferred editor for writing the code. The workflow steps are reduced and simplified for presentation clarity.\n', '\n', '[McDermott et al. (2022)](https://www.google.com/url?q=https://doi.org/10.3390/su142114650&sa=D&source=editors&ust=1717021441104709&usg=AOvVaw1BqnRNCzHNTrlnNefd8wcV): ‚ÄúThe Impact of Industry 4.0 on the Medical Device Regulatory Product Life Cycle Compliance‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Regulatory compliance is how manufacturers comply with the different regulatory requirements to ensure their products, processes, and services deliver a safe and effective product, meet customer requirements and expectations and meet the country-specific regulatory requirements [12]. Digital transformation through the use of digital technology **==**==builds regulatory intelligence and automation==**==**, ensuring data is collected, stored, and maintained globally; it will support complex regulatory strategies ensuring the most up-to-date regulatory requirements are available and met, resulting in a ****faster turnaround time****\xa0for activities such as registrations, enabling a more effective and efficient and compliant RA function that is aligned with the rest of the organisation [23].\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Regulatory 4.0****, or the digitalisation of regulatory affairs, is not a term that has been used, unlike ****Quality 4.0****, which has been recognised through the publication of multiple research articles [5,24,25] which would suggest that the Quality (QA) function is further on their Industry 4.0 or digital transformation journey than its partnering function RA. Like Industry 4.0 and Quality 4.0, the same components can be used to support Regulatory 4.0. The RA function, as suggested in the [‚Äú](https://www.google.com/url?q=https://www.veeva.com/medtech/resources/modernizing-regulatory-affairs-veeva-medtech-regulatory-benchmark-study/&sa=D&source=editors&ust=1717021441105207&usg=AOvVaw1oyqN782jOuOHaHS_pA9-o)[Veeva MedTech 2021 Regulatory Pulse Benchmark Report‚Äù](https://www.google.com/url?q=https://www.veeva.com/medtech/resources/modernizing-regulatory-affairs-veeva-medtech-regulatory-benchmark-study/&sa=D&source=editors&ust=1717021441105415&usg=AOvVaw2RQ0-jUX4vci1cr4KkBWN5), where nearly one hundred organisations globally completed surveys, suggests just that. The RA function is not as far on as from QA and lags on its Industry 4.0 journey. However, the report also suggests that the MedTech Industry is taking much-needed steps toward digitalising regulatory affairs through digital technologies.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The ****digitalisation of regulatory affairs****or Regulatory 4.0 can be achieved through digital technologies, such as the Internet of Things (IoT), cloud computing, and wireless communication that support tools such as ****Regulatory information management systems (RIMs)****\xa0[[Arden et al. 2021](https://www.google.com/url?q=https://doi.org/10.1016/j.ijpharm.2021.120554&sa=D&source=editors&ust=1717021441105786&usg=AOvVaw2IptL0Zc6-jWxyQJGOu7tM)]. RIMs provide secure access to real-time regulatory data and visibility across regions globally, including Latin America (LATAM), Asia-Pacific (APAC) and Europe, the Middle East, and Africa (EMEA), supporting industry in achieving regulatory compliance throughout a products life cycle [[Nick et al. 2021](https://www.google.com/url?q=https://doi.org/10.1016/j.promfg.2021.07.007&sa=D&source=editors&ust=1717021441105934&usg=AOvVaw38OfKeCpl0Ttsnr5cTryRn)]. In addition, ****RIMs support streamlined regulatory processes resulting in quicker submission times and registrations****, leading to **==**==speedier market access==**==**, unification and connectivity across an organisation leading to global alignment and compliance. Figure 1 below shows the elements that constitute a Regulatory Information Management System.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image88.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image22.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image39.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image190.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image207.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image169.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Q10. Are you planning on implementing any Regulatory Intelligence tools or RIMs?****\xa0****If so, why do you need to do this, and what benefits can be achieved from this implementation? What might the potential benefits be from implementing such a system within the organisation?****\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ This question was aimed specifically at the Quality & Regulatory Affairs function, to which all interviewees answered ‚ÄúYes‚Äù. Company X is currently in the planning stages of identifying suitable RIMs that can deliver what the organisation needs. This **==**==RIM requirement is an automated system that will support the RA function==**==**, ensuring that products meet the many global regulatory requirements, support the registration process and control of shipments, ensuring only products that are registered and meet the regulatory requirements can ship. The ever-changing regulatory frameworks drive the need for RIMs throughout the world where Company X sells products and supports compliance. As discussed with One interviewee, the RIMs, like the ECM program, will be the foundation for digital transformation within the RA group. Once implemented, the ****RIMs will be used to control shipments****, ensuring only a product that is approved ships and also to monitor changes to regulatory requirements so that changes can be assessed in real-time and action when required taken to maintain market access. As discussed with One interviewee, the first part of the project will be to identify the system, and like project XXX, a business case must be made to obtain the required buy-in and financial support. Table 11 below are the comments from interviewees on the implementation and benefits of having RIMs.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image8.png)\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Martina et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1002/smr.2570&sa=D&source=editors&ust=1717021441107051&usg=AOvVaw3uhKgOwMhBdugPa5A3eMAx): ‚ÄúSoftware medical device maintenance: DevOps based approach for problem and modification management‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Software problem resolution and change control processes are crucial for the performance, safety, and regulatory clearance of a medical device. ****Software changes are frequent throughout the whole life cycle of a product****; therefore, iterative analysis and risk assessment are necessary to determine the impact of changes on the whole system. ****IEC standard 62304****\xa0clarifies software medical device life cycle processes including problem and modification analysis and requirements. The aim of this work is to describe a **==**==cost-effective and fully customizable solution for software medical devices problem and modification management==**==**\xa0implemented in our group. Key features of the problem and modification management related to the software life cycle have been identified and taken into account.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ A ****digital commercial platform****\xa0for software development and maintenance has been identified and used to implement an architecture satisfying the standard. The architecture solution****(SWMA, software maintenance architecture)****has been successfully developed and a description of how it addresses IEC 62304 standard requirements both in terms of problem resolution and in terms of change control has been provided. The presented system can be useful for manufacturers/groups to establish software maintenance plans that include activities and tasks related to software problem resolution and change control processes. The approach can be adopted for analyzing and resolving problems arising before and after the release of a medical device.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Recently, the development of medical device software (MDSW), as defined by the Guidance on Qualification and Classification of Software in Regulation (EU) 2017/745 ‚Äì ****MDR****,[1](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0001&sa=D&source=editors&ust=1717021441107731&usg=AOvVaw1EIJ7j7sym3K90TozyKMtk)\xa0in force from May 2021 postponed by 1 year due to the coronavirus pandemic,[4](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0004&sa=D&source=editors&ust=1717021441107889&usg=AOvVaw2eko5_2jXzQAhfold8jEZY)\xa0regulates the medical device sector in the EU countries replacing the previous Directive 93/42/EEC[5](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0005&sa=D&source=editors&ust=1717021441108019&usg=AOvVaw1rwoieKvnXWrgu3jOaovX2)\xa0and EU MDD (Medical Device Directive) 2007/47/EC.[6](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0006&sa=D&source=editors&ust=1717021441108138&usg=AOvVaw3avceLUEn2iOBmUKw6FkGh)\xa0One of the changes introduced by the new regulation concerns the software as a medical device sector. In particular, ****rule 11 makes the certification process clearer****\xa0by classifying most of the medical software starting from ****class IIa up to III****.[8](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0008&sa=D&source=editors&ust=1717021441108379&usg=AOvVaw1AQsGxB6rjds5c17UItFKD)\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ IEC 62304 explores the issue of problem resolution by specifying that for each problem encountered in the software life cycle, processes must be activated to make decisions, take correct actions, assign tasks, and compile related documentation. To ****manage this complex network of regulatory requirements and processes****, **==**==new approaches can be useful, such as DevOps==**==**\xa0where development and operations are integrated activities to rapidly manage tasks, ensure quality and safety, control feedback, and reduce development time and costs thanks to digital tools and work-flows (Laukkarinen et al. 2017).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ DORA 2019 State of DevOps report[14](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0014&sa=D&source=editors&ust=1717021441108765&usg=AOvVaw1ifnwnYT_KSK2pZTt4cFD6)\xa0shows that teams using DevOps tools and practices to build, test, and deliver software are able to release deliverables more frequently (====208 times more frequently and====**==**==106 times faster==**==**====than low-performing teams====), with higher quality and stability.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ Digital platforms for managing software development and maintenance, besides safety and security, need to take into consideration other users' needs, ranging from planning of tasks to tracking of data processes to provide a heuristic management within the software life cycle; thus, fundamental requirements to be met are  \n", '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ high customization\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ possibility of integrating with other platforms\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ cost-effective\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Based on the three points above, our customized digital solution was implemented by****using Jira****([https://www.atlassian.com/software/jira](https://www.google.com/url?q=https://www.atlassian.com/software/jira&sa=D&source=editors&ust=1717021441109253&usg=AOvVaw15EtEzci29avuNgWRno5qn)\xa0), a commercial software platform developed by Atlassian. 2020 ****DevOps Trends Survey****\xa0among 500 developers and IT decision makers reports that most of the respondents said DevOps****had a direct impact on business metric****s but****encountered barriers in their DevOps implementation.****\xa0In this context, Jira software can be considered a useful tool for manufacturers to support the implementation of DevOps approach in their company.[20](https://www.google.com/url?q=https://onlinelibrary.wiley.com/doi/full/10.1002/smr.2570%23smr2570-bib-0020&sa=D&source=editors&ust=1717021441109480&usg=AOvVaw1xSf2KfW3NAvlqE9qFBEXr)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Documentation control and problem and modification management integration****Documentation control is a **==**==crucial point for the whole life cycle of a medical device==**==**\xa0including development, maintenance, post-market surveillance, and control of records in order to ensure quality and safety. Furthermore, documentation management is a valuable control tool to ensure continuous improvement and risk minimization as fundamental aspects of the medical device design and deployment.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ Jira can connect with ****Confluence****,‚Ä† a commercial software platform developed by Atlassian Corporation Plc (Sydney, Australia) used by our group for ****documentation control****. A scheme for Jira and Confluence integration system is reported in Figure 1. Our group can rely on a structured quality management system, which is relevant to design and develop medical software. ****Quality management system manages documentation and records****\xa0related to the key company's activities through a customized architecture based on Confluence, supporting features such as implementation, versioning, approval, secure access of documentation, and compliance with standards throughout the software life cycle.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image4.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Confluence‚ÄìJira integration****\xa0in our system ****simplifies****the management of the software development and maintenance processes because the ****two applications work together from planning to execution****of the activities with organized workflows and task tracking by integration of the documentation management.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Inputs to the software problem resolution process****\n', '\n', '$QUOTETOBEREPLACED$ Sources of software problem reports may include\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ anomalies detected during software development, internal testing, external testing or by the final user;\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ software feedback evaluation; and\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ non-conformity reports and/or customer complaints, as summarized in Figure 3.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image154.png)  \n', 'Figure 3. Inputs and outputs to software problem report.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Problems detected from different sources and affecting the product shall be documented as ‚Äúbug‚Äù issues in Jira (Figure 4), according to the internal risk management procedure:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image77.png)\n', '\n', '$QUOTETOBEREPLACED$ Figure 4 Example of bug issue in Jira managing problem.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Bug issues****\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image50.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ Once the bug has been reported, internally or externally to the organization, ****a bug issue is created****\xa0(status OPEN), and tasks and sub-tasks are assigned and performed within the team (status IN PROGRESS). When the software is implemented according to the bug issue, the status changes in RESOLVED. ****A series of tests are run to verify if the bug is fixed****. If yes, the RESOLVED status is complete; however, crucial tasks related to the bug issue are needed before closing it, for example, ****the creation of documentation****. Furthermore,**********==**==an automatic mechanism has been implemented to not close the bug issue until all tasks are completed==**==**. If the tests fail, the bug issue's status changes to REOPENED for implementation (IN PROGRESS), then RESOLVED, and finally CLOSED.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image197.png)\n', '\n', '$QUOTETOBEREPLACED$ Flow chart of a Jira bug issue.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image119.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image152.png)\n', '\n', '$QUOTETOBEREPLACED$ ****Change list of issues.****This in an example of how it is possible to add the JIRA issue macro in a Confluence page in order to ****have a list of issues that is populated automatically.****\xa0Once you have added the macro, you can customize how the list of issues appears on the page,including how much information to display, how many issues, and so on. It is possible to configure this view through an advanced search that allows to ****build structured queries using the JIRA Query Language (JQL)****to search for issues and to specify criteria that cannot be defined in thequick or basic searches.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Software change implementation for the bug resolution****\xa0The software changes needed to solve the bug are implemented by the product design team. The assignee will be the person in charge for the software implementation. Once the ****change is implemented****, it undergoes **==**==a dedicated testing phase==**==**. For verifying the correct implementation, **==**==an ad hoc test can be created and executed==**==**; alternatively, it is possible to ****execute an existing test****\xa0from those available (the test execution shall be linked to the Jira issue).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image162.png)  \n', '**IEC 62304**\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image172.png)\n', '\n', '### Software-as-a-Medical Device (SaMD)\n', '\n', '[FDA (2021)](https://www.google.com/url?q=https://www.fda.gov/media/145022/download?attachment&sa=D&source=editors&ust=1717021441112231&usg=AOvVaw1gelsIQxBbXIZvL-H3OkXv): ‚ÄúArtificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) Action Plan ‚Äú\n', '\n', '[FDA starts 2023 with a flurry of guidance documents](https://www.google.com/url?q=https://www.pharmalex.com/thought-leadership/blogs/fda-starts-2023-with-a-flurry-of-guidance-documents/&sa=D&source=editors&ust=1717021441112500&usg=AOvVaw0y2xi2OipGfID2OeIQtjyw)\n', '\n', '[FDA (April 2023)](https://www.google.com/url?q=https://www.fda.gov/regulatory-information/search-fda-guidance-documents/marketing-submission-recommendations-predetermined-change-control-plan-artificial&sa=D&source=editors&ust=1717021441112748&usg=AOvVaw0wB014BJ8DFjq4mJwCyRUA): ‚ÄúMarketing Submission Recommendations for a Predetermined Change Control Plan for Artificial Intelligence/Machine Learning (AI/ML)-Enabled Device Software Functions‚Äù [FDA-2022-D-2628](https://www.google.com/url?q=https://www.regulations.gov/docket/FDA-2022-D-2628&sa=D&source=editors&ust=1717021441112877&usg=AOvVaw2Ec8emH5wPKERsMDrlmK2o)\n', '\n', '[GOV.UK (July 2023)](https://www.google.com/url?q=https://www.gov.uk/government/publications/software-and-artificial-intelligence-ai-as-a-medical-device/software-and-artificial-intelligence-ai-as-a-medical-device&sa=D&source=editors&ust=1717021441113151&usg=AOvVaw1EBk9qckDk6906MB4CsELz): ‚ÄúSoftware and Artificial Intelligence (AI) as a Medical Device‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Medical Device Regulators Forum (IMDRF‚Äôs) Software as a Medical Device (SaMD): Clinical Evaluation[53](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR53&sa=D&source=editors&ust=1717021441113383&usg=AOvVaw1M9RrtXOK8B81T83s1PWLj)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ FDA‚Äôs Guiding Principles for Good Machine Learning Practice (GMLP)[48](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR48&sa=D&source=editors&ust=1717021441113593&usg=AOvVaw1dMjfYEUALzBOZZ-lCxoKH)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', 'The term [Software as a Medical Device](https://www.google.com/url?q=http://www.imdrf.org/docs/imdrf/final/technical/imdrf-tech-131209-samd-key-definitions-140901.pdf&sa=D&source=editors&ust=1717021441113817&usg=AOvVaw0Wnwj-g_3Isxzp-yUsotzQ)\xa0\xa0is defined by the [International Medical Device Regulators Forum (IMDRF)](https://www.google.com/url?q=https://www.fda.gov/medical-devices/cdrh-international-affairs/international-medical-device-regulators-forum-imdrf&sa=D&source=editors&ust=1717021441113983&usg=AOvVaw2GSb9Y6QCEQL4_NCqVH-r_)\xa0as "****software intended to be used for one or more medical purposes that perform these purposes without being part of a hardware medical device."****\xa0The [International Medical Device Regulators Forum (IMDRF)](https://www.google.com/url?q=https://www.fda.gov/medical-devices/cdrh-international-affairs/international-medical-device-regulators-forum-imdrf&sa=D&source=editors&ust=1717021441114184&usg=AOvVaw20-irEzHjSK5-klVLqe0ww)\xa0 is a voluntary group of medical device regulators from around the world who have come together to reach harmonization on medical device regulation. IMDRF develops internationally agreed upon documents related to a wide variety of topics affecting medical devices. In 2013, IMDRF formed the Software as a Medical Device Working Group (WG) to develop guidance supporting innovation and timely access to safe and effective Software as a Medical Device globally. Chaired by the FDA, the Software as a Medical Device WG agreed upon the [key definitions](https://www.google.com/url?q=http://www.imdrf.org/docs/imdrf/final/technical/imdrf-tech-131209-samd-key-definitions-140901.pdf&sa=D&source=editors&ust=1717021441114371&usg=AOvVaw0ZbTIhD9nTA-mJ-bzlP0P-)\xa0for Software as a Medical Device, [framework for risk categorization](https://www.google.com/url?q=http://www.imdrf.org/docs/imdrf/final/technical/imdrf-tech-140918-samd-framework-risk-categorization-141013.pdf&sa=D&source=editors&ust=1717021441114541&usg=AOvVaw0Gx7o5qVLZt4x9Azt_bse5)\xa0for Software as a Medical Device, the [Quality Management System](https://www.google.com/url?q=http://www.imdrf.org/docs/imdrf/final/technical/imdrf-tech-151002-samd-qms.pdf&sa=D&source=editors&ust=1717021441114685&usg=AOvVaw0hUXm0lwpVxtzSyf7sgvnP)\xa0\xa0for Software as a Medical Device, and the [clinical evaluation](https://www.google.com/url?q=https://www.fda.gov/media/100714/download&sa=D&source=editors&ust=1717021441114812&usg=AOvVaw2OVeySgIikL65Q3aMGBVSD)\xa0of Software as a Medical Device.\n', '\n', '[Your Clinical Decision Support Software: Is It a Medical Device?](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/your-clinical-decision-support-software-it-medical-device&sa=D&source=editors&ust=1717021441115037&usg=AOvVaw3-foHRrE-M0Rtcas8SYNPz)\n', '\n', '[Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices&sa=D&source=editors&ust=1717021441115250&usg=AOvVaw3Ypbp_DrdyCJJqJ9ak1a_N)\n', '\n', '[Artificial Intelligence and Machine Learning in Software as a Medical Device](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-device&sa=D&source=editors&ust=1717021441115439&usg=AOvVaw0ju6VYwNQFw3nj1IGXUZGP)\n', '\n', '[Good Machine Learning Practice for Medical Device Development: Guiding Principles](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/good-machine-learning-practice-medical-device-development-guiding-principles&sa=D&source=editors&ust=1717021441115643&usg=AOvVaw2raRIqUkWC4oMCtgz91x-_)\n', '\n', '[What are examples of Software as a Medical Device?](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/what-are-examples-software-medical-device&sa=D&source=editors&ust=1717021441115829&usg=AOvVaw0MdCPBMjqVaX64jzLo5rjL)\n', '\n', '[Global Approach to Software as a Medical Device](https://www.google.com/url?q=https://www.fda.gov/medical-devices/software-medical-device-samd/global-approach-software-medical-device&sa=D&source=editors&ust=1717021441116029&usg=AOvVaw3LyzzurzfzdMwoADynk1ju)\n', '\n', '[Stat (2023)](https://www.google.com/url?q=https://www.statnews.com/2023/10/16/fda-johnson-johnson-abiomed-warning-letter/&sa=D&source=editors&ust=1717021441116236&usg=AOvVaw2WiXh2VoARCP6rS6VwtF-p): ‚ÄúFDA‚Äôs warning to J&J‚Äôs Abiomed signals a crackdown on digital health tools‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The Food and Drug Administration is following through ****on its promise to regulate more health software tools****, starting with a public reprimand of Johnson & Johnson‚Äôs heart pump company, Abiomed.\n', '\n', '[Schick et al. (Jan 2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00992-8&sa=D&source=editors&ust=1717021441116602&usg=AOvVaw2w_Tv-ejzq1tPiAmACz7LT): ‚ÄúTransparency of artificial intelligence/machine learning-enabled medical devices‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The United States Food and Drug Administration (FDA) is reviewing an increasing number of applications for AI/ML devices, with the number receiving FDA marketing authorization nearing seven hundred as of October 2023[3](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR3&sa=D&source=editors&ust=1717021441116882&usg=AOvVaw3DdfKsQutxyf3ISrvePf70). AI/ML devices have unique considerations during their development and use, including those for usability, equity of access[4](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR4&sa=D&source=editors&ust=1717021441117012&usg=AOvVaw2qho3_Iapdq3Kk82bskRmw), management of performance bias[5](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR5&sa=D&source=editors&ust=1717021441117131&usg=AOvVaw2v6Ah45HLk_aZTyZk3OyrN), the potential for continuous learning, and stakeholder (manufacturer, patient, caregiver, healthcare provider, etc.) accountability[6](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR6&sa=D&source=editors&ust=1717021441117257&usg=AOvVaw1k1xWnBb3f4u7LRy6vP93_). These considerations impact not only the responsible development and use of AI/ML devices but also the regulation of such devices[7](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR7&sa=D&source=editors&ust=1717021441117372&usg=AOvVaw0vdiGtr8f4ljIpT7wmIeC6). FDA‚Äôs Center for Devices and Radiological Health (CDRH) recognizes these unique considerations and released an action plan for AI/ML devices in January 2021[8](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR8&sa=D&source=editors&ust=1717021441117497&usg=AOvVaw20-f9fcRI6kYXGAo4MdM9z). Among its numerous aims, this action plan highlights CDRH‚Äôs commitment to promoting transparency of AI/ML devices by fostering a patient-centered approach, while also collaborating with stakeholders on regulatory science efforts.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ To advance efforts to promote the transparency of AI/ML devices further, CDRH hosted a virtual public workshop entitled ‚ÄúTransparency of Artificial Intelligence/Machine Learning-enabled Medical Devices‚Äù in October 2021[9](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR9&sa=D&source=editors&ust=1717021441117719&usg=AOvVaw15NckZIH9Eib7Qu7DQ_qnN). Speakers, panelists, and attendees from many stakeholder groups, including patients, healthcare providers, researchers, industry members, regulators, and payors, participated. This well-attended workshop focused on identifying ways to achieve transparency for users (patient, caregiver, healthcare provider, etc.) of AI/ML devices, such as information-sharing mechanisms, and ways in which improved transparency might enhance the safety and effectiveness of these devices. This manuscript presents the takeaways from the workshop discussions on the meaning and role of transparency for stakeholders, as well as ways to promote transparency of all AI/ML-enabled software that meets the definition of a device[10](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00992-8%23ref-CR10&sa=D&source=editors&ust=1717021441117863&usg=AOvVaw28FgRgUZpTLLMVcjp6QV-A).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image99.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '#### RIMs etc\n', '\n', '[McDermott et al. (2022)](https://www.google.com/url?q=https://doi.org/10.3390/su142114650&sa=D&source=editors&ust=1717021441118218&usg=AOvVaw2FguaBRDOqN6z-_GmPCC3h): ‚ÄúThe Impact of Industry 4.0 on the Medical Device Regulatory Product Life Cycle Compliance‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ?\n', '\n', '### QA\n', '\n', '[Mahmood et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1093/bjrai/ubae003&sa=D&source=editors&ust=1717021441118536&usg=AOvVaw01sElE8nUIgPNoTOPpp689): ‚ÄúArtificial intelligence in medicine: mitigating risks and maximizing benefits via quality assurance, quality control, and acceptance testing‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The adoption of artificial intelligence (AI) tools in medicine poses challenges to existing clinical workflows. This commentary discusses the necessity of context-specific quality assurance (QA), emphasizing the need for robust QA measures with quality control (QC) procedures that encompass (1) acceptance testing (AT) before clinical use, (2) continuous QC monitoring, and (3) adequate user training. The discussion also covers essential components of AT and QA, illustrated with real-world examples. We also highlight what we see as the shared responsibility of manufacturers or vendors, regulators, healthcare systems, medical physicists, and clinicians to enact appropriate testing and oversight to ensure a safe and equitable transformation of medicine through AI.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image70.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ====Flowchart illustrating the interconnected processes of quality assurance (QA), acceptance testing (AT), and quality control (QC) for AI tools in medical settings. The figure delineates the key steps emphasizing the cyclical nature of these processes for continuous improvement and patient safety. Some information that may be necessary for AT or the overall QA program must be obtained and reviewed before purchasing the AI tool. At installation of any AI tool, the necessary information must be provided to the team performing AT and ongoing QC procedures.====\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image32.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image102.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image199.png)\n', '\n', '### Unique device identification\n', '\n', '[Elisabetta Bianchini et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1016/j.jbi.2019.103150&sa=D&source=editors&ust=1717021441119362&usg=AOvVaw1tWFHF6VnIhrfnHV_75-sl): ‚ÄúUnique device identification and traceability for medical software: A major challenge for manufacturers in an ever-evolving marketplace‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Highlights:****\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ UDI has been introduced with the new European Regulations for medical devices.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ The impact of UDI on software development is of particular interest.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Labeling, privacy, assignment criteria, and standards should be considered.\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ These aspects can be managed to effectively pursue the medical device traceability.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Similarly to what already established and implemented in the United States, the concept of the ****Unique Device Identification (UDI)****\xa0system has been introduced with the European Regulations for medical devices MDR (EU) 2017/745 and in-vitro diagnostic medical devices IVDR (EU) 2017/746 and it is on the way to become a worldwide standard. The aim of this work was to provide a possible approach for the implementation of UDI and traceability in Europe for standalone software medical devices ====according to lifecycle and quality system standards====.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image52.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The approach is based on an ****unambiguous labelling system****\xa0aimed to provide secure distribution and traceability of medical devices [1]. More specifically, the **==**==UDI is an alphanumerical code that can univocally identify product-related information==**==**, such as the manufacturer, model, lot, serial number, and expiration date. In addition, the system will also include ****a public database (****[EUDAMED](https://www.google.com/url?q=https://ec.europa.eu/tools/eudamed/&sa=D&source=editors&ust=1717021441120162&usg=AOvVaw3RdcuOHX2gT27YnyYLMqBI)****)****\xa0that should report UDI code and the above-mentioned data in order to allow a fast identification of a specific medical device and related features. The introduction of this platform can greatly ****improve post market surveillance and patients‚Äô safety****\xa0by easily and accurately identifying a product.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ While the current European medical device regulations, Medical Device Directive (MDD) 93/42/EEC [[3]](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23b0015&sa=D&source=editors&ust=1717021441120497&usg=AOvVaw2bBg9g9iR_bL2e7NX4YJRG), ****left manufacturers the freedom****\xa0in applying the means to assure the safety and efficacy of their medical devices, the **==**==European Commission came to their rescue and provided a series of guidance documents called MEDDEVs==**==**\xa0[[8]](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23b0040&sa=D&source=editors&ust=1717021441120808&usg=AOvVaw0wPkc7Jk82DuvY681hzm3H), to assist stakeholders in their implementation.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Of particular interest for software medical device, we mention: the guidance on ****medical device classification, MEDDEV 2.4/1 rev.9****, and the guidance on the ****qualification and classification of standalone software, MEDDEV 2.6/1****. The latter helps the manufacturer decide whether the software, based on its intended use (diagnostic or [treatment](https://www.google.com/url?q=https://www.sciencedirect.com/topics/medicine-and-dentistry/therapeutic-procedure&sa=D&source=editors&ust=1717021441121194&usg=AOvVaw3cYQWxqNn-Hx7RDXEUEAR6)\xa0purposes), is to be considered a medical device or an in-vitro diagnostic device. It is ****worth mentioning that, while a certain type of device may not be considered a medical device in the EU, it may qualify as one in other regions of the world (for instance in the U.S.)****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ With the aim of adequately identifying medical devices, improve post-market surveillance and ensure patient safety, 21 CFR ‚Äì Part 830 referring to ‚ÄúUnique Device Identification‚Äù requires that all medical devices have ****UDI numbers affixed on their packaging and/or directly marked on the actual device****. The UDI must be in both ****plain text****(human-readable interpretation/HRI) and encoded in the form of ****Automatic Identification****and Data Capture (AIDC) technology, such as a barcode or Data Matrix or Radio-Frequency Identification (RFID). The labeler or their appointed representative must then enter all the information necessary to ****identify the device in the Global Unique Device Identification Database (GUDID)****, a portal with public access to the UDI-related information.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image13.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****EUDAMED****, the European Databank on Medical Devices (referred to in Clause 27 of the new Regulation) is a ****secure, web-based portal****, whose purpose is the exchange of information between national competent authorities and the European Commission, thus ****enforcing market surveillance and transparency****. The European Commission strongly believes that the best way to ensure the effective traceability of medical devices in the EU is through an UDI system harmonized across Europe, thus the need for an Electronic system on UDI as integral part of EUDAMED (referred to in Clause 24a of the new Regulation).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In order to contribute to patient safety, the device and its UDI have to be registered in the EUDAMED database and the UDI must be placed on the label, thus facilitating vigilance and market surveillance.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In addition, the company [Quality Management System](https://www.google.com/url?q=https://www.sciencedirect.com/topics/computer-science/quality-management-system&sa=D&source=editors&ust=1717021441122736&usg=AOvVaw3FQPvHVEO0FVQdW8Mg1aLR)\xa0must include the verification of the UDI attribution and, as far as the Technical File and conformity assessment are concerned, the labeling must be adapted for UDI coding.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Privacy aspects****\n', '\n', '$QUOTETOBEREPLACED$ Issues like data security, protection, hacking and privacy have become worldwide pressing matters, and have gained center stage especially for software medical devices. Manufacturers of software medical device are bound to comply with clause **4.2.5 - "Control of records" requirements of EN ISO 13485:2016 (Quality Management System)**\xa0since they deal with confidential health information. Therefore, their Organization is obliged to define and implement methods that safeguard relevant information contained in their records in accordance with regulatory requirements.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In compliance with the [Health Insurance Portability and Accountability Act (HIPAA)](https://www.google.com/url?q=https://www.cdc.gov/phlp/publications/topic/hipaa.html&sa=D&source=editors&ust=1717021441123179&usg=AOvVaw03u2L5pTOBtiuGofk67UaV)\xa0of 1996, the U.S. law governing privacy and security key features, patients must be given clear written explanations of how their health information is used, kept, and disclosed. Compared to the U.S. system, the ****EU situation is even more complex since the General Data Protection Regulation (GDPR)****\xa0came into force.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The main regulation of the European Union is the General Data Protection Regulation, GDPR [12] which ****restricts processing the European citizens‚Äô data (therefore their personal health records) outside the EU****. The EU General Data Protection Regulation replaces the Data Protection Directive 95/46/EC and was designed to harmonize data privacy laws across Europe.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Three labeling scenarios were hypothesized:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '1. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Software delivered by hardware medium.\n', '2. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Software delivered by web.\n', '3. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ Cloud-based software.\n', '\n', '$QUOTETOBEREPLACED$ Another issue worth noting when developing medical software is the fact that the device is intrinsically associated with the operating system of the computer where it runs. The ****operating system might be considered a SOUP (Software Of Unknown Provenience)****\xa0within the architecture of the device and, as a consequence, its changes and updates might end up influencing the device itself. From this point of view, ****the whole system (i.e. software installed on the operating system) is dynamic****\xa0and the tracking and recording of its changes might be extremely valuable from the traceability and post-market surveillance standpoint.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ A potential solution for addressing this issue might be the implementation of **==**==a detailed dynamic and automatic serial number (SN)==**==**\xa0that could be associated with the UDI-PI. The serial number (SN) of the product could be automatically generated during the installation process and ****automatically updated by the software****. A possibility is that, in a risk-based thinking, this more complex approach might be implemented only in case of high-risk class software (B, C) as defined by IEC 62304.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ For instance, the serial number could consist in ****an alphanumeric sequence automatically generated through a HASH algorithm****\xa0(Fig. 2). This sequence is unique, non-reversible and it depends on the information used as an input of the HASH algorithm. The following information could be used to generate a unique serial number:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ a software VERSION ID, an identifier of the software version, provided by the software manufacturer;\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ an identifier of the operating system of the machine (several software frameworks can provide a string/number that identify the operating system on which the software runs);\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ a MACHINE ID, an identifier of the computer hardware (several software frameworks can provide a string/number that uniquely identify a hardware configuration);\n', '- $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ the license key identification number (if available) etc.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image71.png)\n', '\n', '$QUOTETOBEREPLACED$ Example of SN generation through a HASH algorithm.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ However, **==**==a relevant issue remains open for discussion==**==**: the subsequent automatic changes of the SN should be ****immediately reported to the manufacturer in order to update the customers database****\xa0accordingly with the SN and the customer‚Äôs unique information (such as VERSION ID, operating system version, MACHINE ID, etc.). ****Each time the software runs, the******==**==connection with the company server==**==******is able to allow changes tracking automatically,****\xa0but in the event of ****off-line****\xa0user machine or server unavailability, a ****security mechanism should be designed and implemented****. By way of example, the manufacturer could not to allow the use of the software until the SN update is communicated to the company server. A more practical solution might be the adoption of a case-by-case classification and risk-based management.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Particular attention in terms of production should be placed on these ****two software-specific technical standards****. According to ****IEC 62304 and IEC 82304****, the software ‚Äúlifecycle‚Äù covers all activities from the concept phase to disposal, that includes decommissioning of the last instance of the product. Based on these two software-specific technical standards, UDI-related steps have to be identified for the entire software ‚Äúlifecycle‚Äù (outlined in [Fig. 3](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0015&sa=D&source=editors&ust=1717021441124985&usg=AOvVaw0HqTscVCnuBFK5iyV0kt_m)) which includes ****(a) the concept phase and the development****\xa0process, (b) the****maintenance****process and, lastly, (c) the ****post-market****\xa0management, and software disposal. These aspects are summarized and shown in [Fig. 3a](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0020&sa=D&source=editors&ust=1717021441125288&usg=AOvVaw1FqM8cor0SL1yB68neXVEp), [Fig. 3b](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0025&sa=D&source=editors&ust=1717021441125425&usg=AOvVaw1PLmy_hgys1V43VOe3YekG), [Fig. 3c](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0030&sa=D&source=editors&ust=1717021441125567&usg=AOvVaw1jp6YpGnMnoCov05-BA7ag)\xa0that depict the way the UDI design, implementation and modifications should be considered respectively during the [software design](https://www.google.com/url?q=https://www.sciencedirect.com/topics/computer-science/software-design&sa=D&source=editors&ust=1717021441125696&usg=AOvVaw2IS4mtcXVT_0wKYUjtEIhK)\xa0and development ([Fig. 3a](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0020&sa=D&source=editors&ust=1717021441125866&usg=AOvVaw18L0sxJxImgcSuuOsdjkwh)), maintenance ([Fig. 3b](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0025&sa=D&source=editors&ust=1717021441126013&usg=AOvVaw01lb-lfWCkSUkv_EnGv-z0)) and post-market processes ([Fig. 3c](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S1532046419300681%23f0030&sa=D&source=editors&ust=1717021441126137&usg=AOvVaw2u6D63CIH5mbnBWtpvCKJs)).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image123.png)  \n', 'Fig 3. Flowchart of the software life cycle main processes according to IEC 62304 and IEC 82304.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image17.png)Fig. 3a. How UDI implementation and modification interact with the ****design and development phases****\xa0of medical device software according to IEC 62304 and IEC 82304.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image1.png)Fig. 3b. How UDI implementation and modification interact with the ****maintenance process****\xa0of medical device software according to IEC 62304 and IEC 82304.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image16.png)\n', '\n', '$QUOTETOBEREPLACED$ Fig. 3c. How UDI implementation and modification interact with the ****post-market and disposal processes****\xa0of medical device software according to IEC 62304 and IEC 82304.Fig. 3c. How UDI implementation and modification interact with the post-market and disposal processes of medical device software according to IEC 62304 and IEC 82304.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### ‚ÄúAI RTCs‚Äù (Randomized controlled trial)\n', '\n', '[Alessandro Hammond et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s42256-023-00614-8&sa=D&source=editors&ust=1717021441127063&usg=AOvVaw2tLYNWOL51j4DQPU_FJ-_3): ‚ÄúAn extension to the FDA approval process is needed to achieve AI equity‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ‚Ä¶ recent study found that artificial intelligence (AI) deep learning models can****identify the race of a patient purely based on chest images****\xa0from X-rays (area under the receiver operating characteristics curve (AUC): 0.91‚Äì0.99), CT machines (AUC: 0.87‚Äì0.96) and mammograms (AUC: 0.81)3. The risk inherent in such imaging devices is that AI models can conceivably ****leverage race as a feature in informing decisions****through algorithms that use medical images as input, thereby perpetuating or exacerbating existing racial disparities. Particularly for medical imaging, this risk is ****compounded****by the fact that ****human experts cannot identify racial identity from medical images****, which means that human oversight of AI models is of limited use in mitigating this problem. This issue creates an enormous risk for all model deployments in medical imaging: if ****an AI model relies on its ability to detect racial identity****\xa0to make medical decisions but in doing so produces ****race-specific errors****\xa0that clinical radiologists ‚Äî who ****do not typically have access to racial demographic information****\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image135.png)\n', '\n', '[Drazen and Haug (2024)](https://www.google.com/url?q=https://doi.org/10.1056/AIe2400146&sa=D&source=editors&ust=1717021441127667&usg=AOvVaw2DQgeeiW_kR1YOBOhb3aT2): Trials of AI Interventions Must Be Preregistered\n', '\n', '$QUOTETOBEREPLACED$ Artificial intelligence (AI) must meet the same bar for clinical evidence as other clinical interventions. Trials that start enrolling patients after January 1, 2025 and that use an AI intervention as part of an approach to answering a clinical question will need to be registered in a trial database that meets the World Health Organization (WHO) International Clinical Trials Registry Platform specification or contributes data to this WHO platform if the final work is to be considered for publication in NEJM AI.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ As Isaac Kohane wrote earlier this year: ‚ÄúRandomized controlled trials with LLMs will not be easy. The breadth of such models‚Äô capabilities and unknowns about what data they have already ‚Äòseen‚Äô make their evaluation of narrowly defined tasks somewhat artificial and not entirely reflective of their usage by clinicians or patients. Ensuring that pluripotent AI programs are ‚Äòclinical grade‚Äô and safe will require a multifaceted, collaborative approach among clinicians, patient advocacy groups, and many stakeholders.‚Äù[1](https://www.google.com/url?q=https://ai.nejm.org/doi/full/10.1056/AIe2400146?query%3Dai_wu%26cid%3DDM2335618_Non_Subscriber%26bid%3D-2076061052%23core-r1&sa=D&source=editors&ust=1717021441128004&usg=AOvVaw06Lecr2IFm7f2DgHr46d04)\xa0Transparency will be the principal tool needed to win the trust of our readers, regardless of the form this evaluation takes. Proper prior registration of these trials will add to this transparency.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ There has been uncertainty in the medical AI community about what constitutes a clinical trial that requires registration. For example, different approaches to an AI-driven clinical decision support module in an electronic health record may be trialed to see which is most effective in providing the clinician with a clinically actionable plan. Is such an exercise a quality improvement endeavor or a clinical trial? This is an important distinction because the former may not be viewed as requiring trial registration, whereas the latter would require registration. We realize that drawing a bright line between these two approaches is impossible. Still, to avoid ambiguity, NEJM AI has made the editorial decision that any trial in which human data are gathered prospectively to determine the utility of an intervention requires trial registration even if the local institutional review board or ethics committee determines that the exercise is for quality improvement and that individual patient consent is not needed.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### HIPAA Compliance\n', '\n', '# Model Evaluation and Deployment\n', '\n', '[Sebastian Raschka (2020)](https://www.google.com/url?q=https://arxiv.org/pdf/1811.12808.pdf&sa=D&source=editors&ust=1717021441128583&usg=AOvVaw0o4jovXYStDC0QRfKyQ1-L): ‚ÄúModel Evaluation, Model Selection, and Algorithm Selection in Machine Learning‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image87.png)\n', '\n', 'Researcher variability ([https://twitter.com/SteveStuWill/status/1712943403091267897](https://www.google.com/url?q=https://twitter.com/SteveStuWill/status/1712943403091267897&sa=D&source=editors&ust=1717021441128895&usg=AOvVaw02yR-SadBdF0sdW2jnFDzA)):  \n', '[Breznau et al. (2023, PNAS)](https://www.google.com/url?q=https://twitter.com/SteveStuWill/status/1712943403091267897&sa=D&source=editors&ust=1717021441129053&usg=AOvVaw06HbaRDPjpbfPiw1gvA4AE): ‚ÄúObserving Many Researchers Using the Same Data and Hypothesis Reveals a Hidden Universe of Uncertainty‚Äù\n', '\n', '## ![](HTML%20import/Attachments/image101.png)\n', '\n', '[FG-AI4H DEL7.4](https://www.google.com/url?q=https://www.itu.int/dms_pub/itu-t/opb/fg/T-FG-AI4H-2023-.3-PDF-E.pdf&sa=D&source=editors&ust=1717021441129352&usg=AOvVaw2osqtIpErTc426eSMUtlwD): ‚ÄúClinical evaluation of AI for health‚Äù\n', '\n', '## ![](HTML%20import/Attachments/image9.png)\n', '\n', '## ‚ÄúTask set-up‚Äù: Regression vs Classification\n', '\n', '[Amey Vrudhula et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1056/AIcs2300176&sa=D&source=editors&ust=1717021441129842&usg=AOvVaw1aos53bgIEno32P199vBth): ‚ÄúThe Impact of Task Set-up in Algorithm Design: Regression versus Classification‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Many medical diagnoses can be formulated either as classification tasks that predict whether output variables fall into a particular diagnostic group or **==**==as regression tasks that predict the underlying measurements of disease severity==**==**. AI models trained on classification tasks and those trained on regression tasks may be equally valid in describing a clinical condition, but **==**==their performances can be significantly different==**==**. To illustrate such differences, we used electrocardiogram (ECG) data from an academic medical center to train two deep-learning AI ECG models to identify individuals with **==**==severe cardiomyopathy==**==**. The classification and regression models achieved similar results for area under the curve across three sites. However, **==**==the regression model achieved significantly better positive predictive values at each site.==**==**\xa0Differences in problem formulation can result in significant differences in model performance; therefore, careful thought should be given to the design and training of AI algorithms.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '## Evaluating Medical DL Deployments\n', '\n', '[Thomas Eche et al. (2021)](https://www.google.com/url?q=https://doi.org/10.1148/ryai.2021210097&sa=D&source=editors&ust=1717021441130353&usg=AOvVaw2kNizghDKdI4QQvt-umBPV): ‚ÄúToward Generalizability in the Deployment of Artificial Intelligence in Radiology: Role of Computation Stress Testing to Overcome Underspecification‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Stress testing is a known tool in AI that can limit underspecification and, importantly, assure broad generalizability of AI models. However, the application of stress tests is new in radiologic applications. This report describes the concept of underspecification from a radiologist perspective, discusses stress testing as a specific strategy to overcome underspecification, and explains ****how stress tests could be designed in radiology****‚Äîby modifying medical images or stratifying testing datasets. In the upcoming years, stress tests should become in radiology the standard that crash tests have become in the automotive industry.\n', '\n', '[Zhang et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-022-00690-x&sa=D&source=editors&ust=1717021441130812&usg=AOvVaw2AhkN2MFsp-7oNpzBeNkVx): (Imperial College London, London, UK) ‚ÄúMoving towards vertically integrated artificial intelligence development‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image120.png)\n', '\n', '[Niemiec (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s42256-022-00602-4&sa=D&source=editors&ust=1717021441131152&usg=AOvVaw0nQoCxQOk-eCCrORf5cQpU): ‚ÄúA cautionary tale about the adoption of medical AI in Sweden‚Äù\n', '\n', '$QUOTETOBEREPLACED$ A recent case of a flawed medical AI system that was backed by public funding provides an opportunity to discuss the impact of government policies and regulation in AI.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Sweden, like several other countries, has ambitions to become a leader in the race to realize the potential of artificial intelligence (AI). However, caution is necessary in such attempts, as there are many potential legal, ethical and political issues to tackle, as demonstrated by a recent attempt to implement an AI system in one-third of primary public healthcare centres in Sweden. The****system received a European grant despite design flaws and incorrect details in the******==**==grant application==**==**. In addition, the procurement process suffered from several irregularities, which eventually led to **==**==criminal convictions==**==**. In what follows, I describe this particular case and use it to illustrate the need to ****scrutinize government funding and implementation of AI systems in society****, especially in healthcare.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Governments and the EU have important roles in the adoption of AI, not only as legislators but also as****main investors****, and as actors shaping public discourse. Unfortunately, it seems that at least some of their activities in these areas serve not patients and society more generally, but **==**==instead serve the interests of the AI industry==**==**. The recently proposed ****AI Act****\xa0has serious shortcomings, among others in enforcement mechanisms, and in fact, as concluded by Veale and Zuiderveen Borgesius, it ‚Äúmay contribute to deregulation more than it raises the regulatory bar‚Äù27. The EU‚Äôs funding for private for-profit companies also raises questions about the ****adequacy of grant review processes****\xa0and the fair use of public money. Excessively optimistic and deterministic depictions of AI in policies and national strategies contribute to a distorted view of it and, arguably, to the adoption of unreliable systems. This means, as the case of V√•rdexpressen demonstrates, that individual responsibility and appropriate levels of education among stakeholders in AI, especially medical doctors, are vital if we are to resist the hype and identify abuses in the implementation of medical AI systems.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', 'Validation as a Service (VaaS), federated learning [https://youtu.be/fe-Fo7I69Ts?t=6835](https://www.google.com/url?q=https://youtu.be/fe-Fo7I69Ts?t%3D6835&sa=D&source=editors&ust=1717021441131863&usg=AOvVaw0lMxnifmbkOqZ5r-pQKFHO)\xa0- [Toward safer ophthalmic artificial intelligence via distributed validation on real-world data](https://www.google.com/url?q=https://journals.lww.com/co-ophthalmology/fulltext/2023/09000/Toward_safer_ophthalmic_artificial_intelligence.18.aspx?context%3DLatestArticles&sa=D&source=editors&ust=1717021441132026&usg=AOvVaw2cWo16awavZHVfgbpjdNit)\xa0(Sanro Health)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image129.png)  \n', '![](HTML%20import/Attachments/image54.png)  \n', '![](HTML%20import/Attachments/image27.png)\n', '\n', '[Youssef et al. (2023)](https://www.google.com/url?q=https://arxiv.org/pdf/2305.03219.pdf&sa=D&source=editors&ust=1717021441132327&usg=AOvVaw15Bi39YJlp6TaAZ4RrmWvx): ‚ÄúAll models are local: time to replace external validation with recurring local validation‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ******ABSTRACT*******"External validation is often recommended to ensure the generalizability of ML models. However, it neither guarantees generalizability*******nor equates to a model‚Äôs clinical usefulness (the ultimate goal of any clinical decision-support tool)********. External validation is misaligned with current healthcare ML needs. First, patient data changes across time, geography, and facilities; these changes create significant volatility in the performance of a single fixed model (especially for deep learning models, which dominate clinical ML). Second, newer ML techniques, current market forces, and updated regulatory frameworks are enabling frequent updating and monitoring of individual deployed model instances. We********submit that*********==***==external validation is insufficient to establish ML models\' safety or utility==***==****. Proposals to "fix" the external validation paradigm do not go far enough. Continued reliance on it as the ultimate test is likely to lead us astray. We propose the*******MLOps-inspired paradigm of*********==***==recurring local validation==***==*********as an alternative********that ensures the validity of models while protecting against performance-disruptive data variability. This paradigm***relies on "site-specific" reliability tests before every deployment**, followed by regular and recurrent checks throughout the life cycle of the deployed algorithm. Initial and recurrent reliability tests protect against performance-disruptive distribution shifts, and concept drifts that jeopardize patient safety."*\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ******SNIPPETS FROM TEXT*******"Taken together, we suggest that a better use of the essence of external validation would be**"site-specific" validation***performed as a reliability test before every local deployment and********repeated on a recurring basis********. It builds on and expands the concept of temporal validation. Such local validation would be performed********(1)********before deployment at a particular facility, given the novelty of the unseen local dataset, and********(2********) repeated over time, given the potential for performance-disruptive********distribution shifts and concept drifts********.**\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ *"This "recurring local validation" paradigm is new to healthcare bu*******t standard practice in Machine Learning Operations (MLOps)********. MLOps is a discipline concerned with the at-scale production, deployment, monitoring, and maintenance of models. MLOps originates from a 2015 paper by Google [**[Sculley et al. 2015](https://www.google.com/url?q=https://papers.neurips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf&sa=D&source=editors&ust=1717021441133184&usg=AOvVaw1Ua31bwjgVUXJGXAR7vyNp)**].*****==***==Continuous performance monitoring==***==*********and model updating********are critical for ML implementation through MLOps. [**[Granlund et al. 2021](https://www.google.com/url?q=https://link.springer.com/article/10.1007/s42979-021-00726-1&sa=D&source=editors&ust=1717021441133362&usg=AOvVaw0ct090u3dwhe_DiUJ30mjz)].‚Äù  \n', '  \n', '‚ÄúAccording to this logic [[Riley et al. 2016](https://www.google.com/url?q=https://www.bmj.com/content/353/bmj.i3140&sa=D&source=editors&ust=1717021441133481&usg=AOvVaw3cdOkelx5LjO4U5oHDeZDz)**,**[Bluemke et al. 2020](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/31891322/&sa=D&source=editors&ust=1717021441133589&usg=AOvVaw0IUbOj852iWaOEyiPlfxG8)**,**[Yu et al. 2022](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/35652114/&sa=D&source=editors&ust=1717021441133690&usg=AOvVaw3j-lFVVN_O8LcMC5LanbLe)**,**[van de Sande et al. 2022](https://www.google.com/url?q=https://www.sciencedirect.com/science/article/pii/S003960602200215X%23!&sa=D&source=editors&ust=1717021441133817&usg=AOvVaw2q81fyAWl-d0We3GAqVFdN)**,**[Singh et al. 2022](https://www.google.com/url?q=https://journals.plos.org/digitalhealth/article?id%3D10.1371/journal.pdig.0000023&sa=D&source=editors&ust=1717021441133948&usg=AOvVaw1DJtiH2a0T0-KRCh-UPIsC)**]., if a model passes an external validation test on one or a few datasets, it is generalizable, safe, and reliable. However, external validation does not guarantee generalizability [**[Futoma et al. 2020](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/32864600/&sa=D&source=editors&ust=1717021441134062&usg=AOvVaw2q25oh8-E0_5IFBR79Q9ca)**]. Neither does it equate to********model usefulness********, which should be the true goal of any clinical decision-support tool. Taken together,***==*==we question whether external validation should be a==*==****==***==gold standard==***==****==*==paradigm for evaluating healthcare ML algorithms==*==*.‚Äù  \n', '  \n', '‚ÄúExternal validation studies usually rely on global performance statistics *==*==(e.g., AUROC, AUPRC) that==*==****==***==do not capture the practical value of the clinical decision support (CDS)==***==****==*==tool==*==***[**[Pencina et al. 2020](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/32320568/&sa=D&source=editors&ust=1717021441134341&usg=AOvVaw2X2__U4T7FPNmOe17Mvbrq)**]. Clinical utility and safety are measured by metrics beyond the replicability of a narrow performance statistic across settings.*****==***==Clinically useful models recommend decisions that improve outcomes or reduce cost==***==*****[**[Shah et al. 2019](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/31393527/&sa=D&source=editors&ust=1717021441134485&usg=AOvVaw11z6yz2Z1FjlyEjWyJfGUB)**,**[Emanuel and Wachter 2019](https://www.google.com/url?q=https://jamanetwork.com/journals/jama/fullarticle/2734581&sa=D&source=editors&ust=1717021441134603&usg=AOvVaw3LFlap2W471O4et9AWev0W)**,**[Berwick et al. 2008](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/18474969/&sa=D&source=editors&ust=1717021441134709&usg=AOvVaw03SPiLZ51bscqEKjgyddPk)**,**[Frakt 2016](https://www.google.com/url?q=https://jamanetwork.com/journals/jama/fullarticle/2552195&sa=D&source=editors&ust=1717021441134819&usg=AOvVaw2FRbtOuR-Ky2duYjlJhTRi)**,**[Porter 2010](https://www.google.com/url?q=https://www.nejm.org/doi/full/10.1056/nejmp1011024&sa=D&source=editors&ust=1717021441134923&usg=AOvVaw0IgMDbKJdGoK0J7L_X_upD)**, **[Ganguli et al. 2020](https://www.google.com/url?q=https://www.semanticscholar.org/paper/Machine-Learning-and-the-Pursuit-of-High-Value-Care-Ganguli-Ganguli/4033463002445eecb591a5bb26936e64795332fa&sa=D&source=editors&ust=1717021441135085&usg=AOvVaw3oveJEg8JMTXsYgqBGFADd)**,**[Grant et al. 2018](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/29741602/&sa=D&source=editors&ust=1717021441135206&usg=AOvVaw1pEwTs_SKmtGfgvOxo_ROp)**,**[Vergouwe et al. 2002](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/12012295/&sa=D&source=editors&ust=1717021441135317&usg=AOvVaw0Y_6huaIwTZOjMVjYgE6BW)**,**[Baker and Gerdin 2017](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/28935477/&sa=D&source=editors&ust=1717021441135421&usg=AOvVaw2zoPxWmA8Yeej8l96NKX3W)**,**[Holmberg and Vickers 2013](https://www.google.com/url?q=https://journals.plos.org/plosmedicine/article?id%3D10.1371/journal.pmed.1001491&sa=D&source=editors&ust=1717021441135554&usg=AOvVaw2Uo5lVByszUjmh07DuNkvD)**,**[Triantafyllidis and Tsanas 2019](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/30950797/&sa=D&source=editors&ust=1717021441135672&usg=AOvVaw1MYMnzasS4-lNw02-BB1PS)**]. Fair models achieve parity in the statistical outcome/model recommendation across various population groups [**[Verghese et al. 2018](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/29261830/&sa=D&source=editors&ust=1717021441135798&usg=AOvVaw0PJQi0wZJStGUFEO6SZFBw)**,**[Rajkomar et al. 2019](https://www.google.com/url?q=https://pubmed.ncbi.nlm.nih.gov/30943338/&sa=D&source=editors&ust=1717021441135910&usg=AOvVaw3jNneaDcUq7_yf9mA1l4yw)**,**[Corbett-Davies et al. 2018](https://www.google.com/url?q=https://arxiv.org/abs/1808.00023&sa=D&source=editors&ust=1717021441136013&usg=AOvVaw3SEEdhqGIQ66tVkRT0KEwQ)**]. Simply put, the metrics that are critical for safety and clinical utility rely on site-specific, guideline-based, translation of the ML algorithm into clinical recommendations [**[Foryciarz et al. 2022](https://www.google.com/url?q=https://informatics.bmj.com/content/29/1/e100460&sa=D&source=editors&ust=1717021441136167&usg=AOvVaw3uUzbMd02me3oIUAFTmiWM)*]. These are hard to adequately capture in a generic external validation."*\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ *"External validation is*******particularly problematic with Deep Learning (DL)********models, given their********sensitivity to distribution shifts********and data variability. The current state-of-the-art DL solutions tend to overfit the training distribution and often fail to generalize on out-of-distribution test data [**[Goyal et al. 2022](https://www.google.com/url?q=https://arxiv.org/abs/2011.15091&sa=D&source=editors&ust=1717021441136516&usg=AOvVaw00u6-ATaSl1T24cxUGsEgi)**,**[Zhang et al. 2021](https://www.google.com/url?q=https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Deep_Stable_Learning_for_Out-of-Distribution_Generalization_CVPR_2021_paper.pdf&sa=D&source=editors&ust=1717021441136682&usg=AOvVaw1nMzHsdb8yBgTgdRCQrMHW)**,**[Robey et al. 2021](https://www.google.com/url?q=https://arxiv.org/abs/2102.11436&sa=D&source=editors&ust=1717021441136784&usg=AOvVaw1N5SRohQnb31N-_qwaBe1s)*]. "*\n', '\n', '[Collins et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1136/bmj-2023-074819&sa=D&source=editors&ust=1717021441136966&usg=AOvVaw0w4S4vqVIj3AtbtY-IvGh-): ‚ÄúEvaluation of clinical prediction models (part 1): from development to external validation‚Äù\n', '\n', '[Riley et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1136/bmj-2023-074820&sa=D&source=editors&ust=1717021441137287&usg=AOvVaw3iSdyivJa065WVLl0gKUsX): ‚ÄúEvaluation of clinical prediction models (part 2): how to undertake an external validation study‚Äù\n', '\n', '[Riley et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1136/bmj-2023-074821&sa=D&source=editors&ust=1717021441137487&usg=AOvVaw1o01ulx0f_WKHulQWpIt78): ‚ÄúEvaluation of clinical prediction models (part 3): calculating the sample size required for an external validation study‚Äù\n', '\n', '[Chekroud et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1126/science.adg8538&sa=D&source=editors&ust=1717021441137790&usg=AOvVaw342Rs72yI7ESkARduOwdJH): ‚ÄúIllusory generalizability of clinical prediction models‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image174.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image28.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ A central promise of artificial intelligence (AI) in healthcare is that large datasets can be mined to predict and identify the best course of care for future patients. Unfortunately, we do not know how these models would perform on new patients because they are rarely tested prospectively on truly independent patient samples. Chekroud et al. showed that machine learning models routinely achieve perfect performance in one dataset even when that dataset is a large international multisite clinical trial (see the Perspective by [Petzschner 2024](https://www.google.com/url?q=https://doi.org/10.1126/science.adm9218&sa=D&source=editors&ust=1717021441138272&usg=AOvVaw3K1OnLS6FIoSGSj4P8Ve5n): ‚ÄúPractical challenges for precision medicine‚Äù). However, when that ****exact model was tested in truly independent clinical trials****, **==**==performance fell to chance levels==**==**. Even when building what should be a more robust model by aggregating across a group of similar multisite trials, **==**==subsequent predictive performance remained poor==**==**. ‚ÄîPeter Stern\n', '\n', '### ‚ÄúClinical noise‚Äù\n', '\n', '[Mohamed Abdalla and Benjamin Fine (2023)](https://www.google.com/url?q=https://doi.org/10.1148/ryai.220056&sa=D&source=editors&ust=1717021441138663&usg=AOvVaw2fhgSF_U_-A96I38yYI14j): ‚ÄúHurdles to Artificial Intelligence Deployment: Noise in Schemas and ‚ÄúGold‚Äù Labels‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Despite frequent reports of imaging artificial intelligence (AI) that parallels human performance,****clinicians often question the safety and robustness of AI products in practice****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ This work explores ****two under-reported sources of noise****\xa0which negatively affect imaging AI: (a) **==**==variation in labeling schema definitions==**==**\xa0and (b) **==**==noise in the labeling process==**==**. First, the overlap between the schemas of two publicly available datasets and a third-party vendor are compared, showing there is low agreement (< 50%) between them. The authors also highlight the problem of****label inconsistency****, where ****different annotation schemas are selected for the same clinical prediction task****; this results in inconsistent use of medical ontologies through intermingling or duplicate observations and diseases. Second, the individual radiologist annotations for the CheXpert test set are used to quantify noise in the labeling process. The analysis demonstrated that label noise varies by class, as agreement was high for pneumothorax and medical devices (percent agreement > 90%). Among low agreement classes (pneumonia, consolidation), the **labels assigned as "ground truth" were unreliable**, suggesting that the result of majority voting is highly dependent on which group of radiologists are assigned to annotation. ****Noise in labeling schemas and gold label annotations are pervasive in medical imaging classification and impact downstream clinical deployment****. Possible solutions (eg, changes to task design, annotation methods and model training) and their potential to improve trust in clinical AI are discussed.\n', '\n', '[Aneeta Sylolypavan et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00773-3&sa=D&source=editors&ust=1717021441139380&usg=AOvVaw2xUjqIW6wLxTeBi1rp5nDg): ‚ÄúThe impact of inconsistent human annotations on AI driven clinical decision making‚Äù\n', '\n', '$QUOTETOBEREPLACED$ In supervised learning model development, domain experts are often used to provide the class labels (annotations).****Annotation inconsistencies****\xa0commonly occur when even highly experienced clinical experts annotate the same phenomenon (e.g., medical image, diagnostics, or prognostic status), ****due to inherent expert bias****, judgments, and slips, among other factors. While their existence is relatively well-known, the ****implications of such inconsistencies are largely understudied in real-world settings****, when supervised learning is applied on such ‚Äònoisy‚Äô labelled data. To shed light on these issues, we conducted extensive experiments and analyses on three real-world Intensive Care Unit (ICU) datasets. Specifically, individual models were built from a common dataset, annotated independently by****11 Glasgow Queen Elizabeth University Hospital ICU consultants****, and model performance estimates were compared through internal validation.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The results suggest that: (a) there**may not always be a "super expert"**\xa0in acute clinical settings (using internal and external validation model performances as a proxy); and (b) standard consensus seeking (such as **==**==majority vote) consistently leads to suboptimal models==**==**. Further analysis, however, suggests that assessing annotation learnability and using only ‚Äòlearnable‚Äô annotated datasets for determining consensus achieves optimal models in most cases.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image193.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The left component (with three boxes) illustrates the model derivation including dataset, models and internal validation methods. The top component with two green boxes denotes the external validation dataset selection and preparation. The middle component (circled by a dashed line) shows the external validation experiments. The right component (with four pink boxes) describes the external validation experiment details including inconsistent measurements, consensus seeking methods and decision making considering changing patterns.\n', '\n', '### Fairness\n', '\n', '[Yongshuo Zong, Yongxin Yang, Timothy Hospedales (2022)](https://www.google.com/url?q=https://arxiv.org/abs/2210.01725&sa=D&source=editors&ust=1717021441140195&usg=AOvVaw23DAcG6YN7SrHSuqB0bhr8): ([https://github.com/ys-zong/MEDFAIR](https://www.google.com/url?q=https://github.com/ys-zong/MEDFAIR&sa=D&source=editors&ust=1717021441140324&usg=AOvVaw2AJMacdzCm4uI9uoiVvwAg)) ‚ÄúMEDFAIR: Benchmarking Fairness for Medical Imaging‚Äù\n', '\n', '$QUOTETOBEREPLACED$ A multitude of work has shown that machine learning-based medical diagnosis systems can be ****biased against certain subgroups of people****. This has motivated a growing number of ****bias mitigation algorithms****that aim to address fairness issues in machine learning. However, it is difficult to compare their effectiveness in medical imaging for two reasons. First, there is ****little consensus on the criteria to assess fairness****. Second, existing bias mitigation algorithms are developed under different settings, e.g., datasets, model selection strategies, backbones, and fairness metrics, making a direct comparison and evaluation based on existing results impossible. In this work, ****we introduce MEDFAIR****, a framework to benchmark the fairness of machine learning models for medical imaging. MEDFAIR covers ****eleven algorithms from various categories****, nine datasets from different imaging modalities, and three model selection criteria. Through extensive experiments, we find that the **==**==under-studied issue of model selection criterion can have a significant impact on fairness outcomes==**==**; while in contrast, ****state-of-the-art bias mitigation algorithms do not significantly improve fairness****\xa0outcomes over empirical risk minimization (ERM) in both in-distribution and out-of-distribution settings. We evaluate fairness from various perspectives and make recommendations for different medical application scenarios that ****require different ethical principles****. Our framework provides a reproducible and easy-to-use entry point for the development and evaluation of future bias mitigation algorithms in deep learning\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image150.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image142.png)\n', '\n', '$QUOTETOBEREPLACED$ ****Are the evaluations enough for now?****\xa0Although we have tried our best to include a diverse set of algorithms and datasets in our benchmark, it is certainly not exhaustive. There are methods to promote fairness from other perspectives, e.g., **==**==self-supervised learning may be more robust==**==******(****[Liu et al., 2021](https://www.google.com/url?q=https://arxiv.org/abs/2110.05025&sa=D&source=editors&ust=1717021441141095&usg=AOvVaw1WbmVj2qOKFz__6aTzy3qS)****;****[Azizi et al., 2022](https://www.google.com/url?q=https://arxiv.org/abs/2205.09723?context%3Dcs.LG&sa=D&source=editors&ust=1717021441141220&usg=AOvVaw28LO3QWsqzWfLg7eo5GyJT)****)****. Also, datasets from other medical data modalities (e.g., cardiology, digital pathology) should be added. Beyond image classification, other important tasks in medical imaging, such as segmentation, regression, and detection, are underexplored. We will keep our codebase alive and actively incorporate more algorithms, datasets, and even other tasks in the future.\n', '\n', '[Liu et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00918-4&sa=D&source=editors&ust=1717021441141485&usg=AOvVaw38KVObJaZaKDtaaJEN0JCQ): ‚ÄúA translational perspective towards clinical AI fairness‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Various fairness measurements have been developed to detect differences between subgroups as evidence of bias, and bias mitigation methods are designed to reduce the differences detected. This perspective of fairness, however, is **==**==misaligned with some key considerations in clinical contexts==**==**. The set of sensitive variables used in healthcare applications must be carefully examined for relevance and justified by clear clinical motivations. In addition, clinical AI fairness should closely investigate **==**==the ethical implications of fairness measurements==**==**\xa0(e.g., potential conflicts between ****group- and individual-level fairness****) to select suitable and objective metrics.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Two types of fairness metrics****\xa0are discussed most often: group-based and individual-based[17](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR17&sa=D&source=editors&ust=1717021441141885&usg=AOvVaw2j05XhQrsnJqwlP-Lutxnn),[18](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR18&sa=D&source=editors&ust=1717021441142023&usg=AOvVaw3GSychAbFCAH_lvlaLaz7B),[26](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR26&sa=D&source=editors&ust=1717021441142150&usg=AOvVaw2c8CRMauWZ3P0AcIjLu6J2). ****Group****-based metrics measure the consistency of model performance (e.g., using the confusion matrix or ****calibration****) across subgroups defined by sensitive variables, and a fair model is expected to behave similarly among subgroups. Some widely used****individual-****based metrics include ****fairness through awareness****[27](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR27&sa=D&source=editors&ust=1717021441142409&usg=AOvVaw2pmUDv7aJpA09E7ZWiPo-t)\xa0which assumes that observations with similar conditions should have similar predictions, and ****counterfactual fairness****[28](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR28&sa=D&source=editors&ust=1717021441142611&usg=AOvVaw2XvuJM8mifCkI33XOJt9db)\xa0expecting that changing a sensitive variable should not alter the predicted outcome for an individual.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image78.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Generally defining AI fairness as ‚Äúequality‚Äù is not necessarily reasonable in clinical settings, as**==**==differences may have clinical justifications and do not indicate biases==**==**. Instead, **"equity" would be an appropriate objective of clinical AI fairness**. Moreover, clinical feedback is essential to developing fair and well-performing AI models, and efforts should be made to ****actively involve clinicians in the process****. The adaptation of AI fairness towards healthcare is not self-evident due to misalignments between technical developments and clinical considerations. Multidisciplinary collaboration between AI researchers, clinicians, and ethicists is necessary to bridge the gap and translate AI fairness into real-life benefits.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ However, due to the ****knowledge gap amongst AI researchers and clinicians****, AI fairness studies ****tend to focus on abstractive conceptualization or technical developments****. While these aspects are highly important, it is ****unclear how they can be applied to healthcare****. This paper provides an overview of the misalignments of current AI fairness research with practical clinical concerns and the obstacles to AI fairness adaptation, which is visually summarised in Fig. [1](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23Fig1&sa=D&source=editors&ust=1717021441143275&usg=AOvVaw3c_RQGhwhzVf-dGo3GWcYD).\n', '\n', '$QUOTETOBEREPLACED$  \n', '![](HTML%20import/Attachments/image155.png)Fig. 1 Left panel: the framework of AI fairness from the technical perspective; right panel: the corresponding concerns from the clinical perspective, which are not yet (fully) addressed by current methodological developments.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Race/ethnicity****\xa0is particularly challenging to handle in the pursuit of ‚Äúequity‚Äù, as it can be associated with systemic bias that affects clinical practice, or genuine biological and/or sociological differences among subpopulations[48](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR48&sa=D&source=editors&ust=1717021441143703&usg=AOvVaw1BjUtpKDT6I53_VS1k_-MS).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Secondly, different types of fairness metrics correspond to varying fairness definitions, which may in some cases conflict in perspectives and ethical principles:****group-based fairness****may be more relevant to the ****perspective of hospital leadership****or ****public health policy-making****on the basis of population ethics, whereas****individual-based metrics are closer to the perspective of patient-level decision-making guided by clinical ethics****[32](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR32&sa=D&source=editors&ust=1717021441144038&usg=AOvVaw0B-M7798MAqp8ncNEVqn9x). Such differences in ethical assumptions and clinical perspectives should be accounted for and justified when applying fairness metrics in healthcare applications, and failing to account for either individual- or group-based fairness seems unethical[33](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR33&sa=D&source=editors&ust=1717021441144169&usg=AOvVaw2oaaJDCAxV28KhMpL9_s54).\n', '\n', '$QUOTETOBEREPLACED$ The choice of fairness metrics is****further complicated by the large number of metrics available****\xa0that may produce inconsistent results[26](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR26&sa=D&source=editors&ust=1717021441144388&usg=AOvVaw25KrnG28upGstK5Um8FiIt). Though there have been several review papers discussing the relationships and differences between these metrics, they ****do not provide practical guidelines****regarding the selection of fairness metrics to address specific clinical needs[34](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR34&sa=D&source=editors&ust=1717021441144556&usg=AOvVaw2Ju4wVRwWPeAcN7i2FUhoQ). Due to the trade-offs between the metrics, it is mathematically impossible to optimize all metrics simultaneously, except in highly restrictive cases[26](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR26&sa=D&source=editors&ust=1717021441144678&usg=AOvVaw1eVp3_nxc1pVScHSkYNwxo),[33](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR33&sa=D&source=editors&ust=1717021441144791&usg=AOvVaw0-OizD1kTqrHfs7iofdm-N),[35](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR35&sa=D&source=editors&ust=1717021441144940&usg=AOvVaw0F-72uqBhG-sTPyv8pZsDa).\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image43.png)\n', '\n', '$QUOTETOBEREPLACED$ \xa0To align the objectives of AI developers and clinicians, it is necessary to establish a two-way communication between the two parties to facilitate an iterative model building process that aligns technical rationale with clinical concerns. For example, fairness metrics applied (or developed) ****by AI developers should be clinically contextualized****\xa0to accurately quantify fairness in clinical settings. Such communication requires some functional **==**==understanding of AI modeling for clinicians==**==**[59](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR59&sa=D&source=editors&ust=1717021441145278&usg=AOvVaw0Of1VGNehTv2M93D4CS8pl)====and====**==**==clinical context grasping for AI developers==**==**[56](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR56&sa=D&source=editors&ust=1717021441145419&usg=AOvVaw3lGpfLAc99ueSN5ArmPaki). ****Explainable AI****\xa0can contribute to such communication since it provides clinicians with the capability of interpreting models[60](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR60&sa=D&source=editors&ust=1717021441145577&usg=AOvVaw1aDfE4e9UPmXoI_HRSOIZF)\xa0and giving feedback to the AI developers[61](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00918-4%23ref-CR61&sa=D&source=editors&ust=1717021441145696&usg=AOvVaw1I0pO7ajvvxxUvU4SrSC6F). Having a better understanding of the model‚Äôs decision-making process could enable clinicians to help improve the model‚Äôs accuracy, and clinicians would also guide the algorithms in a more equitable direction.\n', '\n', '[Abr√†moff et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00913-9&sa=D&source=editors&ust=1717021441145960&usg=AOvVaw2_H797t_0-Jq8drU1X9NuC): ‚ÄúConsiderations for addressing bias in artificial intelligence for health equity‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Health equity****\xa0is a primary goal of healthcare stakeholders: patients and their advocacy groups, clinicians, other providers and their professional societies, bioethicists, payors and value based care organizations, regulatory agencies, legislators, and creators of artificial intelligence/machine learning (AI/ML)-enabled medical devices. Lack of equitable access to diagnosis and treatment****may be improved through new digital health technologies****, especially AI/ML, but these may also exacerbate disparities, depending on how bias is addressed. We propose an expanded **==**==Total Product Lifecycle (TPLC)==**==**====framework for healthcare AI/ML====, describing the sources and impacts of undesirable bias in AI/ML systems in each phase, how these can be analyzed using appropriate metrics, and how they can be potentially mitigated. The goal of these ‚ÄúConsiderations‚Äù is to educate stakeholders on how potential AI/ML bias may impact healthcare outcomes and how to identify and mitigate inequities; to initiate a discussion between stakeholders on these issues, in order to ensure health equity along the expanded AI/ML TPLC framework, and ultimately, better health outcomes for all.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ These ethical and other concerns with AI in healthcare have been shown by a number of research studies[27](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR27&sa=D&source=editors&ust=1717021441146415&usg=AOvVaw30_7FzYl4lWKsfphFTVyr4),[28](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR28&sa=D&source=editors&ust=1717021441146540&usg=AOvVaw0dfW9aWA-iuMNGDoEUYNvQ),[29](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR29&sa=D&source=editors&ust=1717021441146728&usg=AOvVaw265NT9irDMev9RGH3QGvyp). Abramoff et al. proposed ****ethical frameworks****for AI[27](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR27&sa=D&source=editors&ust=1717021441147003&usg=AOvVaw2qc9C6g4CI6ydYYqwzQQFI),[28](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR28&sa=D&source=editors&ust=1717021441147136&usg=AOvVaw2Yx_-ZNJyD5NFdulJ8FW_a),[29](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR29&sa=D&source=editors&ust=1717021441147266&usg=AOvVaw1u_Vvi19I137ETEhfSna7f),[30](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR30&sa=D&source=editors&ust=1717021441147387&usg=AOvVaw1-EEqAB1pvQPxS5s-JSVar),[31](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR31&sa=D&source=editors&ust=1717021441147520&usg=AOvVaw3kJowJBJvCqgeYJnwfS1qO)\xa0to help proactively address the issue of undesirable algorithmic bias as well as other concerns with AI. More recently, the ****Foundational Considerations on Algorithmic Interpretation (FPOAI)****workgroup of the ****Collaborative Community on Ophthalmic Imaging****published their ‚ÄúFoundational Considerations‚Äù[32](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR32&sa=D&source=editors&ust=1717021441147766&usg=AOvVaw1aNtTpofn9HEXM3YIo-4My)\xa0on AI as a start to developing **metrics for ethics**, including metrics for ‚ÄúEquity‚Äù[33](https://www.google.com/url?q=https://www.nature.com/articles/s41746-023-00913-9%23ref-CR33&sa=D&source=editors&ust=1717021441147978&usg=AOvVaw3Xq89lm2CDNUCZXkoZMoCS), in order to be able to evaluate how specific AI systems adhere to various bioethical principles.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image157.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image214.png)  \n', 'Total Product LifeCycle (TPLC) equity expanded framework with examples for each phase.\n', '\n', '[Lara et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1007/978-3-031-45249-9_13&sa=D&source=editors&ust=1717021441148557&usg=AOvVaw2iowE_hL-gSW_JbUXyAocu): ‚ÄúTowards Unraveling Calibration Biases in Medical Image Analysis‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Most research on healthcare algorithmic fairness to date has focused on the assessment of biases****in terms of classical discrimination metrics such as AUC and accuracy****.**********==**==Potential biases in terms of model calibration==**==**, however, have only recently begun to be evaluated. This is especially important when working with clinical decision support systems, as ****predictive uncertainty****\xa0is key to optimally evaluate and combine multiple sources of information. Here we study discrimination and calibration biases in models trained for automatic detection of malignant dermatological conditions from skin lesions images. Importantly, we ****show how several typically employed calibration metrics are systematically biased****with **==**==respect to sample sizes,==**==**\xa0and how this ****can lead to erroneous conclusions****if not taken into consideration. This is of particular relevance to fairness studies, where data imbalance results in drastic sample size differences between demographic sub-groups, which could act as confounders.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image192.png)\n', '\n', '$QUOTETOBEREPLACED$ ****Effect of sample sizes on calibration metric fairness audits.****Significant differences on (A) show the impact of sample size in most of the metrics when comparing the original light-skinned test set and a sub-sampled version, matching the number of samples in the dark-skinned test set. When metrics are computed with equal sample sizes, they do not exhibit such differences (B).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The boxplots for the calibrated scenario (top row in Fig. 3B), reveal a clear trend where ****ECE, MCE and AdaECE are biased with respect to the sampling ratio (i.e. test set size)****, supported by the significant differences found between the value of these metrics computed on 100% and 10% of the data (Wilcoxon Signed Rank test at a 0.05 level).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ We note however that differences become ****less pronounced as de-calibration becomes more prominent****(middle and bottom rows in Fig. 3B). Comparing the scales on the y-axis we note that the finite size effect component in the metrics is eventually dominated by the miscalibration component itself. On the other hand, it can be observed that sample size does not seem to have a major effect on the PSRs.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image59.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Calibration metrics calculated over the runs with different sampling ratios of the original test sets.****Results of the numerical experiments on real data (A) show the trend on ECE, MCE and AdaECE values with respect to the sampling proportion. The results of the synthetic experiments (B) are arranged according to the different de-calibration scenarios: perfectly calibrated (Œ± \xa0= Œ≤ \xa0=1) in the top row, slightly out of calibration (Œ± \xa0= Œ≤ \xa0= 1.5) in the middle row and highly miscalibrated (Œ± \xa0= Œ≤ \xa0= 5) in the bottom row.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image125.png)\n', '\n', '### Without labels\n', '\n', '[Sims et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1101/2023.02.23.529809&sa=D&source=editors&ust=1717021441149823&usg=AOvVaw0dL_oblg5H72qnOhbaNd5F): ‚ÄúSEG: Segmentation Evaluation in absence of Ground truth labels‚Äù\n', '\n', '[Kiyasseh et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41467-024-46000-9&sa=D&source=editors&ust=1717021441150074&usg=AOvVaw1qGSbNrE0NM7lmm63zWB97): ([https://github.com/flatironhealth/SUDO](https://www.google.com/url?q=https://github.com/flatironhealth/SUDO&sa=D&source=editors&ust=1717021441150184&usg=AOvVaw0k02dJ9nVoLL31hAqpqq0q)) ‚ÄúA framework for evaluating clinical artificial intelligence systems without ground-truth annotations‚Äù\n', '\n', '$QUOTETOBEREPLACED$ A clinical artificial intelligence (AI) system is often validated on data withheld during its development. This provides an estimate of its performance upon future deployment on data in the wild; those currently unseen but are expected to be encountered in a clinical setting. However, **==**==estimating performance on data in the wild is complicated by distribution shift==**==**\xa0between data in the wild and withheld data and **==**==the absence of ground-truth annotations==**==**. Here, we introduce SUDO, a framework for evaluating AI systems on data in the wild. Through experiments on AI systems developed for dermatology images, histopathology patches, and clinical notes, we show that **==**==SUDO can identify unreliable predictions==**==**, inform the selection of models, and allow for the previously out-of-reach assessment of algorithmic bias for data in the wild without ground-truth annotations. These capabilities can contribute to the deployment of trustworthy and ethical AI systems in medicine.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image191.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ To address this need, previous work ====assumes highly-confident predictions are reliable====[5](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR5&sa=D&source=editors&ust=1717021441150697&usg=AOvVaw2RymXGaruPrzaBDXEGg7QM),[6](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR6&sa=D&source=editors&ust=1717021441150824&usg=AOvVaw10Wn-gGMmlLWYki00I0Q4f), even though AI systems are **==**==known to generate highly-confident incorrect predictions==**==**[7](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR7&sa=D&source=editors&ust=1717021441150968&usg=AOvVaw1XWdrGgdZYzAKT-RTg5y9P). Recognising these limitations, others have demonstrated the value of modifying AI-based confidence scores through explicit calibration methods such as ****Platt scaling****[8](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR8&sa=D&source=editors&ust=1717021441151117&usg=AOvVaw3h538XoW4-JcCU0paX4H7-),[9](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR9&sa=D&source=editors&ust=1717021441151246&usg=AOvVaw0Ypse9hKkPLTaiVeFNd-Kx)\xa0or through ****ensemble models****[10](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR10&sa=D&source=editors&ust=1717021441151379&usg=AOvVaw0oCNJosLrLTlcKoqvEw5bc). Such calibration methods, however, can be ineffective when deployed on data in the wild that exhibit distribution shift[11](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR11&sa=D&source=editors&ust=1717021441151501&usg=AOvVaw22blwcv7oC79j9NBGLNBg9). Regardless, ****quantifying the effectiveness of calibration methods would still require ground-truth labels****, a missing element of data in the wild. Another line of research focuses ****on estimating the overall performance of models with unlabelled data****[12](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR12&sa=D&source=editors&ust=1717021441151657&usg=AOvVaw2LPt9cc7VkuIgyytPcCtJq),[13](https://www.google.com/url?q=https://www.nature.com/articles/s41467-024-46000-9%23ref-CR13&sa=D&source=editors&ust=1717021441151764&usg=AOvVaw3ZnyJgNrrfOYxa103y6rNq). However, it tends to be model-centric, overlooking the data-centric decisions (e.g., identifying unreliable predictions) that would need to be made upon deployment of these models, and makes the oft fallible assumption that the held-out set of data is representative of data in the wild, and therefore erroneously extends findings in the former setting to those in the latter.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In this study, we propose **==**==pseudo-label discrepancy (SUDO),==**==**\xa0a framework for evaluating AI systems deployed on data in the wild. Through experiments on three clinical datasets (dermatology images, histopathology patches, and clinical notes), we show that SUDO can be a reliable proxy for model performance and thus be used to identify unreliable AI predictions. This**********==**==finding holds even with overconfident models.==**==**========We also show that SUDO informs the selection of models upon their deployment on data in the wild. By implementing SUDO across patient groups, we demonstrate that it also allows for the previously out-of-reach assessment of algorithmic bias for data without ground-truth labels.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image180.png)\n', '\n', '$QUOTETOBEREPLACED$ ****a****An AI system is often deployed on data in the wild, which can vary significantly from those in the held-out set (distribution shift), and which can also lack ground-truth labels. ****b****\xa0SUDO is a 5-step framework that circumvents the challenges posed by data in the wild. First, deploy an AI system on data in the wild to obtain probability values. Second, discretize those values into quantiles. Third, sample data points from each quantile and pseudo-label (temporarily label) them with a possible class (SUDO Class 0). Sample data points with ground-truth labels from the opposite class to form a classification task. Fourth, train a classifier to distinguish between these data points. Repeat the process with a different pseudo-label (SUDO Class 1). Finally, evaluate and compare the performance of the classifiers on the same held-out set of data with ground-truth labels, deriving the pseudo-label discrepancy. This discrepancy and the relative classifier performance indicate whether the sampled data points are more likely to belong to one class than another.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image81.png)\n', '\n', '### Stats for measures\n', '\n', '[Rainio et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41598-024-56706-x&sa=D&source=editors&ust=1717021441152547&usg=AOvVaw0qTU_z1nbDJg69WNJBNHvP): ‚ÄúEvaluation metrics and statistical tests for machine learning‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Research on different machine learning (ML) has become incredibly popular during the past few decades. However, for some researchers not familiar with statistics, it **==**==might be difficult to understand how to evaluate the performance of ML models and compare them with each other.==**==**\xa0Here, we introduce the most common evaluation metrics used for the typical supervised ML tasks including binary, multi-class, and multi-label classification, regression, image segmentation, object detection, and information retrieval. We explain **==**==how to choose a suitable statistical test for comparing models==**==**, how to obtain enough values of the metric for testing, and how to perform the test and interpret its results. We also present a few practical examples about comparing convolutional neural networks used to classify X-rays with different lung infections and detect cancer tumors in positron emission tomography images.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image29.png)  \n', '\n', '$QUOTETOBEREPLACED$ The possible tasks for a model, their evaluation metrics, the values of the evaluation metric that must be computed for each model before statistical testing, the potential questions a statistical test could answer in the situation, and the suitable test.\n', '\n', '### Cross-validation\n', '\n', '[How to get from evaluation to final model](https://www.google.com/url?q=https://mindfulmodeler.substack.com/p/how-to-get-from-evaluation-to-final&sa=D&source=editors&ust=1717021441153119&usg=AOvVaw13ffB1CoRz5MQM48jalqbl)\n', '\n', '$QUOTETOBEREPLACED$ Let‚Äôs say that you get 84% accuracy, which is estimated by averaging the performance over the 5 folds. 84% is good enough to deploy the model. But the pragmatic question is: What exactly do you deploy now?\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****The Ensemble Approach: The 5 models from cross-validation are already your final model.****\xa0To predict a new data point, simply take the predictions from the five models and average them. This approach is consistent with saying that the evaluation was specific to these five models. Problems with this approach: Makes deployment more difficult as you now have to deploy an ensemble. It‚Äôs also unclear whether the accuracy is still 84% after averaging the predictions for new data, but I would expect the ensemble performance to be equal to or better than for a single model.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ [Sebastian M√ºller](https://www.google.com/url?q=https://substack.com/profile/143697125-sebastian-muller&sa=D&source=editors&ust=1717021441153540&usg=AOvVaw1aEUFHvjMw5kDxYihveXrP)\xa0[Sebastian‚Äôs Substack](https://www.google.com/url?q=https://snimu.substack.com/?utm_source%3Dsubstack%26utm_medium%3Dweb%26utm_content%3Dcomment_metadata&sa=D&source=editors&ust=1717021441153683&usg=AOvVaw1NZrmTDSVsbqZw9dWOVmyo)\xa0[Mar 19](https://www.google.com/url?q=https://mindfulmodeler.substack.com/p/how-to-get-from-evaluation-to-final/comment/51978033&sa=D&source=editors&ust=1717021441153822&usg=AOvVaw1HrzIHvLOYdrv7uMOQtuOd)\n', '\n', '$QUOTETOBEREPLACED$ In Neural Networks, weight averaging the five models can sometimes work pretty well as an alternative to ensembling (especially if you use techniques like git rebasing).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### AUROC vs ?\n', '\n', '‚ÄùThe AUROC, better understood as the concordance probability between predicted and observed values, has no problem with highly imbalanced data other than having a higher standard error than when the outcomes are balanced and the total sample size stays the same. The problem with AUROC is that like other measures you mentioned it is not sensitive enough for comparing two models. For that one should use the gold standard (log-likelihood) or sensitive measures discussed here.‚Äù - [https://stats.stackexchange.com/a/571824](https://www.google.com/url?q=https://stats.stackexchange.com/a/571824&sa=D&source=editors&ust=1717021441154250&usg=AOvVaw3t_4W-Tneb5_AX0AwlK-El)\xa0\n', '\n', 'Nice visualization on AUROC spread:\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image138.png)\n', '\n', '$QUOTETOBEREPLACED$ [Lasko et al. (2024)](https://www.google.com/url?q=https://arxiv.org/pdf/2402.05802.pdf&sa=D&source=editors&ust=1717021441154620&usg=AOvVaw1Hf4HX2q154fk1PodRL_xV)\n', '\n', '[Andr√© M. Carrington et al. (2022)](https://www.google.com/url?q=https://arxiv.org/pdf/2103.11357.pdf&sa=D&source=editors&ust=1717021441154806&usg=AOvVaw3hEZHcdG0gQ4maWg29x7Bb): ‚ÄúDeep ROC Analysis and AUC as Balanced Average Accuracy to Improve Model Selection, Understanding and Interpretation‚Äù\n', '\n', '[Anne A H de Hond et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1016/S2589-7500(22)00188-1&sa=D&source=editors&ust=1717021441154983&usg=AOvVaw16J2fg3q1DwrkJsVOsnb7j): ‚ÄúInterpreting area under the receiver operating characteristic curve‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Clinicians often ask biostatisticians to provide a judgement on the quality of a prediction model. The prediction quality can be assessed with different performance criteria, with discriminative ability being a main issue: how well can we separate high-risk from low-risk patients? Discriminative ability is typically quantified by the area under the receiver operating characteristic curve (AUC) when we consider prediction of a binary event.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image111.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Literature from the past 5 years proposes labels ranging from unhelpful to very helpful for specific AUC values.[3](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib3&sa=D&source=editors&ust=1717021441155414&usg=AOvVaw10eCA5hl0PORv3WwKP4nik)\xa0These labels associate AUC values to the actions that happen after deploying the prediction model. These actions typically include informing patients of their individual risk and support decision making. To reliably inform patients and physicians, we note t****hat it is not discrimination****, but **==**==calibration of risk predictions that is essential.==**==**[4](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib4&sa=D&source=editors&ust=1717021441155625&usg=AOvVaw2cUgbepbBszQYzYRn1IYD9)\xa0Hence, a helpful model with an AUC of more than 0¬∑8 can be misleading if predictions are not well calibrated. For claims on making better decisions, **==**==dedicated measures beyond the AUC are needed==**==**. One such measure is ****net benefit.****[5](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib5&sa=D&source=editors&ust=1717021441155812&usg=AOvVaw3ZahgYlCf5ypXoWc67FTIk)\xa0Net benefit is calculated as:\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image113.png)\n', '\n', '$QUOTETOBEREPLACED$ where ******p**********t is the decision threshold****[0,1] above which a patient is positive. The true (false) positives are the number of patients with a risk prediction higher than the decision threshold that are truly positive (negative). Net benefit considers the ****clinical context,****\xa0including the treatment decision for which the model is used and the ****relative importance of true-positive versus false-positive classifications****. The clinical context determines what can be considered a reasonable decision threshold, not statistical criteria.[6](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib6&sa=D&source=editors&ust=1717021441156171&usg=AOvVaw3YuKdhmf-VESd3mri8gt_Y)\xa0To evaluate the value of a model for decision making, a range of reasonable decision thresholds might be examined graphically in a decision curve.\n', '\n', '$QUOTETOBEREPLACED$ The curve goes ****beyond AUC as a summary measure****\xa0of model quality because it allows comparison of the net benefit of a model with reference strategies (****treat everyone or treat no one****). When, at a given decision threshold, a model has higher net benefit than such default strategies, decision making based on the model is useful.**********==**==If net benefit is lower than that of a default strategy, the model is harmful==**==**====.====\xa0This interpretation is lacking for performance measures related to discrimination or calibration. Net benefit could therefore serve as ****an initial assessment of clinical usefulness****, before proceeding with more time-intensive and costly evaluation steps, such as a ****health-economics evaluation****\xa0or ****clinical trial for effects on patient or clinical outcomes****.\n', '\n', '$QUOTETOBEREPLACED$ Empirical research shows that models with higher AUC values are more often clinically useful.[7](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib7&sa=D&source=editors&ust=1717021441156668&usg=AOvVaw03m7AxBUgv3D8QizSgfUH3)\xa0When transporting a model from one setting to another, some ****miscalibration is typically observed, which reduces net benefit****.[8](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib8&sa=D&source=editors&ust=1717021441156842&usg=AOvVaw2WPqwnaDMJTpsKchHSRgw9)\xa0The lower the AUC, the more easily such miscalibration could make models harmful, depending on the type and extent of miscalibration, the decision threshold, and event rate (appendix pp 2‚Äì4). For the real-world 4C Mortality Score validation example, we assume that the event rate is 17%, and the AUC is 0¬∑79. We show that quite some miscalibration can be tolerated for the model to remain helpful for decision making across a reasonable range of decision thresholds (appendix p 2), so a high AUC might compensate for poor calibration to some extent.\n', '\n', '$QUOTETOBEREPLACED$ In conclusion, ****labelling systems for AUC are arbitrary****. ****High discriminatory ability is not sufficient to claim positive potential effect****\xa0of deploying a prediction model in clinical practice. The predominant purpose of AUC values might be to compare the discriminative ability of different models. If needed, the model with the best AUC can be updated to fix any observed miscalibration.[9](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib9&sa=D&source=editors&ust=1717021441157118&usg=AOvVaw0JOhRk3FTynoCVr-nZcugC)\xa0The implication is that we should report AUC values without using AUC labels and that ****we should look beyond AUC values****\xa0when reporting model performance,[10](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23bib10&sa=D&source=editors&ust=1717021441157297&usg=AOvVaw3564m-qsiiQekfAhgpsK-d)\xa0including measures for ****calibration****\xa0and ****net benefit****.[4](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23&sa=D&source=editors&ust=1717021441157496&usg=AOvVaw3zWaysKFuFCoY6iTkXqsWz), \xa0[5](https://www.google.com/url?q=https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00188-1/fulltext?dgcid%3Draven_jbs_aip_email%23&sa=D&source=editors&ust=1717021441157632&usg=AOvVaw2UQPswUT-jziGJbuUwLGpc)\n', '\n', '[Neto et al. (2024, Sage Bionetworks)](https://www.google.com/url?q=https://doi.org/10.1186/s12911-023-02382-2&sa=D&source=editors&ust=1717021441157793&usg=AOvVaw079C4-iYtr5TsHf0ZVDN2r): ([https://github.com/Sage-Bionetworks/tp_AUC](https://www.google.com/url?q=https://github.com/Sage-Bionetworks/tp_AUC&sa=D&source=editors&ust=1717021441157957&usg=AOvVaw1Xh2Jz2-RYWlsvpBQXw_o0)\xa0/ [https://github.com/echaibub/pROC_based_tpAUC](https://www.google.com/url?q=https://github.com/echaibub/pROC_based_tpAUC&sa=D&source=editors&ust=1717021441158074&usg=AOvVaw1HKIMXFdNHVkBzTldfbTSU))\xa0A novel estimator for the two-way partial AUC\n', '\n', '$QUOTETOBEREPLACED$ The ****two-way partial AUC****\xa0[[16](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR16&sa=D&source=editors&ust=1717021441158362&usg=AOvVaw0pBIcKkfvCqnwqZX-RNKwY), \xa0[Cited by 37](https://www.google.com/url?q=https://scholar.google.com/scholar?cites%3D12575374804545615655%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441158521&usg=AOvVaw1tNP5H2foP-yGGdwfEtjma)\xa0[Yang et al. 2019](https://www.google.com/url?q=https://doi.org/10.1177/0962280217718866&sa=D&source=editors&ust=1717021441158635&usg=AOvVaw02CoboGt00QTTXwASem_QN)] has been recently proposed as a way to directly quantify partial area under the ROC curve with **==**==simultaneous restrictions on the sensitivity and specificity ranges of diagnostic tests or classifiers==**==**. \xa0Previous approaches in the literature [[17](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR17&sa=D&source=editors&ust=1717021441158871&usg=AOvVaw2tLS2c0bbbyABS6qo_hCIQ),[18](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR18&sa=D&source=editors&ust=1717021441159003&usg=AOvVaw35O6oSib6hyhOhmrVzL_xu),[19](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR19&sa=D&source=editors&ust=1717021441159126&usg=AOvVaw3ooMDD8lKwLVQhu8SacwwA),[20](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR20&sa=D&source=editors&ust=1717021441159255&usg=AOvVaw2kUH-LVgRJFUNyHxRxdQag),[21](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR21&sa=D&source=editors&ust=1717021441159380&usg=AOvVaw2-6zNq6207KyNQ9nJgGjnP)] focused on quantifying partial area under the ROC (pAUC) by directly restricting the FPR range, but only indirectly controlling for the TPR. However, as illustrated in [[16](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR16&sa=D&source=editors&ust=1717021441159522&usg=AOvVaw19JJjBHiu9hqjZXgP6H-XS)], this indirect approach can be problematic making diagnostic test comparisons less efficient and, in some circumstances, leading to incorrect conclusions (see the illustrative examples presented in [[16](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR16&sa=D&source=editors&ust=1717021441159662&usg=AOvVaw02ralWBj3g60iHOZ-48M21)] for further details).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The metric, as originally implemented in the [tpAUC R package](https://www.google.com/url?q=https://cran.r-project.org/package%3DtpAUC&sa=D&source=editors&ust=1717021441159873&usg=AOvVaw02E_frrg-7sDrCYHd2uItK), is estimated using a nonparametric estimator based on a trimmed Mann-Whitney U-statistic, which becomes computationally expensive in large sample sizes. This is problematic since the statistical methodology for comparing estimates generated from alternative diagnostic tests/classifiers relies on bootstrapping resampling and requires repeated computations of the estimator on a large number of bootstrap samples.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The proposed estimator provides an improvement for the computation of two-way partial AUC, and allows the comparison of diagnostic tests/machine learning classifiers in large datasets where repeated computations of the original estimator on bootstrap samples become too expensive to compute.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image14.png)\xa0 ![](HTML%20import/Attachments/image12.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image95.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image106.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image136.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image184.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The receiver operation characteristic curve (ROC) [[8](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR8&sa=D&source=editors&ust=1717021441160553&usg=AOvVaw3jj-bxdaWCSRk0Z9O-_P32)] plots the false positive rate (FPR) against the the true positive rate (TPR) across all possible threshold levels and is a widely used technique for visualizing the trade-offs between FPR and TPR at any threshold level of interest in both diagnostic testing based on continuous scales [[9](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR9&sa=D&source=editors&ust=1717021441160717&usg=AOvVaw0kAGH6pKhDeW8ycc3OFNOD),[10](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR10&sa=D&source=editors&ust=1717021441160848&usg=AOvVaw0LLziU7vn6SNvBCBqU0XPV),[11](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR11&sa=D&source=editors&ust=1717021441160976&usg=AOvVaw2B08_ptBHxdA32sjOlgavz),[12](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR12&sa=D&source=editors&ust=1717021441161102&usg=AOvVaw0Fs3GUlhyBTGNQ0mLII1KH),[13](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR13&sa=D&source=editors&ust=1717021441161234&usg=AOvVaw3EgHBL8Hz5sChvWuwSFYMY)] and machine learning evaluations [[8](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR8&sa=D&source=editors&ust=1717021441161363&usg=AOvVaw3XsdqYEMkRHNuu914Lps_Z)]. The **==**==area under the ROC curve (AUC) is the most widely used criterium to summarize the information==**==**\xa0provided by the ROC curve across all thresholds.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ For every diagnostic test/classifier there is a ****cost-benefit analysis****\xa0necessary for **==**==evaluating the costs of false positives versus false negatives==**==**. These costs can sometimes be measured economically as in unnecessary medical care costs for false positives, but also translate to societal and individual costs such as psychological strain due to false positive diagnosis or the ethical concerns due to the direct harm caused by a false negative diagnosis (which might lead to poor prognosis or even the death of the individual). As a consequence, in many applications, it is **==**==important to simultaneously maintain a low FPR and high TPR==**==**, and regulatory or policy making bodies may have pre-defined criteria for the allowable TPR and FPR in various scenarios based on the healthcare economics of false positive and false negative outcomes.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ For example, the World Health Organization (WHO) has set minimal requirements for community-based tuberculosis screening **==**==at sensitivity (TPR) above 90% and specificity (1-FPR) above 70%==**==**\xa0[[14](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR14&sa=D&source=editors&ust=1717021441161836&usg=AOvVaw27jVtWhO10otlqdLJezUkn)]. For SARS-CoV-2 diagnostics, the WHO requirements for antigen-detecting rapid diagnostic tests are sensitivity above 80% and specificity above 97% [[15](https://www.google.com/url?q=https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-023-02382-2%23ref-CR15&sa=D&source=editors&ust=1717021441161995&usg=AOvVaw2Jk1t2oxd40U8eyaTJSzve)]. Thus, in evaluating diagnostic tests/classifiers, we **==**==may only be interested in comparing their performances within the regulatory guideline bounds==**==**.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ When clear guidelines exist, there is an advantage to compare different classifiers in a limited region of the ROC space instead of over the entire range.\n', '\n', '[Mojtaba Hassanzad & Karimollah Hajian-Tilaki (2024)](https://www.google.com/url?q=https://doi.org/10.1186/s12874-024-02198-2&sa=D&source=editors&ust=1717021441162285&usg=AOvVaw3EF9-nAY66RhvvJNyvwIdW): Methods of determining optimal cut-point of diagnostic biomarkers with application of clinical data in ROC analysis: an update review\n', '\n', '$QUOTETOBEREPLACED$ Our results in the clinical data suggested that for CRP and MDA, the calculated cut-points of the Youden index, Euclidean index, Product and Union index methods were consistent in predicting IBD patients, while for ESR, only the Euclidean and Product methods yielded similar estimates. However, the diagnostic odds ratio (DOR) method provided more extreme values for the optimal cut-point for all biomarkers analyzed.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Overall, the four methods including the ****Youden index, Euclidean index, Product, and IU can produce quite similar optimal cut-points for binormal pairs****\xa0with the same variance. The cut-point determined with the Youden index may not agree with the other three methods in the case of****skewed distributions****\xa0while DOR does not produce valid informative cut-points. Therefore, ****more extensive Monte Carlo simulation studies are needed to investigate the conditions of test result distributions****\xa0that may lead to inconsistent findings in clinical diagnostics.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Roberts et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s42256-024-00817-7&sa=D&source=editors&ust=1717021441162738&usg=AOvVaw0Oq7PjmHVPsTYCSaRZaN6f): The curious case of the test set AUROC [https://doi.org/10.24433/CO.1960655.v1](https://www.google.com/url?q=https://doi.org/10.24433/CO.1960655.v1&sa=D&source=editors&ust=1717021441162846&usg=AOvVaw3RXl_40TYvpDgOZs8R_Ol9)\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ In particular, among the many potential performance metrics, the ML community****stubbornly continues to use****(i) the AUROC for a validation and test cohort (distinct from training data) or (ii) the sensitivity and specificity of the test data at an optimal threshold determined from the validation receiver operating characteristic (ROC) curve.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ However, we argue that considering scores derived from the test ROC curve alone gives only a narrow insight into how a model performs and its ability to generalize. In earlier work, researchers have discussed the overall advantages and disadvantages of the AUROC[1](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR1&sa=D&source=editors&ust=1717021441163169&usg=AOvVaw1RT8HmmZMXXKAfo8vCTS6P),[2](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR2&sa=D&source=editors&ust=1717021441163297&usg=AOvVaw0Nt-kVYh6WXp8b0A4beB9u), its misuse in model validation[3](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR3&sa=D&source=editors&ust=1717021441163410&usg=AOvVaw08FVYeJgIbY2KMNed4b2U1),[4](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR4&sa=D&source=editors&ust=1717021441163624&usg=AOvVaw06vxpf1rT4B44MWg1whxZw)\xa0and its failure to measure real-world generalization performance[5](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7?utm_source%3Dnatmachintell_etoc%26utm_medium%3Demail%26utm_campaign%3Dtoc_42256_6_4%26utm_content%3D20240425%23ref-CR5&sa=D&source=editors&ust=1717021441163806&usg=AOvVaw2b6DDVYx_Osd6Qv6rIXFvW),[6](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7?utm_source%3Dnatmachintell_etoc%26utm_medium%3Demail%26utm_campaign%3Dtoc_42256_6_4%26utm_content%3D20240425%23ref-CR6&sa=D&source=editors&ust=1717021441163958&usg=AOvVaw3SvsMfJkub7o8GYKeBIQO2),[7](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR7&sa=D&source=editors&ust=1717021441164107&usg=AOvVaw0ueqEpU1b-Q6PwDy2Sbov0)\xa0and have proposed dropping it altogether in favor of other scoring systems[8](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR8&sa=D&source=editors&ust=1717021441164247&usg=AOvVaw1ID6O5iEcR2e1ZbLI5PIBe). We don‚Äôt seek to discuss the individual shortcomings of the AUROC (such as equal treatment of all threshold values and extrapolation required for ‚Äòdegenerate‚Äô distributions)[1](https://www.google.com/url?q=https://www.nature.com/articles/s42256-024-00817-7%23ref-CR1&sa=D&source=editors&ust=1717021441164388&usg=AOvVaw1L_nOeCRMYLTGEhRMmI5Q0)\xa0or to disregard it, as the AUROC is a staple for ML researchers. However, we do seek to highlight, in particular, its shortcomings for evaluating a model‚Äôs generalizability and motivate the community to provide solutions, some examples of which we present.![](HTML%20import/Attachments/image89.png)  \n', 'For two-example validation (left) and test (right) set model output distributions, we show that for two different model output distributions, the ROC curves and AUROC are identical. Colouring the ROC by the associated thresholds highlights the underlying differences.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image163.png)\n', '\n', '$QUOTETOBEREPLACED$ a,b, Curves showing the profile of the ****relative AUROC and how it changes for bias and noise perturbation at level œÉ in the example validation (a) and test (b) cohorts****. \xa0is given for the bias and noise perturbations.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### Clinical evaluation\n', '\n', 'blog by [Jason Brownlee](https://www.google.com/url?q=https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/&sa=D&source=editors&ust=1717021441164982&usg=AOvVaw0cKzyO0CiAwIaytzOIc_Lo):\n', '\n', '$QUOTETOBEREPLACED$ ‚ÄúROC Curves and ROC AUC can be optimistic on severely imbalanced classification problems with few samples of the minority class.‚Äù -\n', '\n', '[J√∏rgen Hilden (1991)](https://www.google.com/url?q=https://doi.org/10.1177/0272989x9101100204&sa=D&source=editors&ust=1717021441165193&usg=AOvVaw0g3fZKjPjQsGmp6Yhs_iwi)\xa0The area under the ROC curve and its competitors [Cited by 216](https://www.google.com/url?q=https://scholar.google.co.uk/scholar?cites%3D14074448485034981982%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441165336&usg=AOvVaw1o2wLJEmB5Y0vgkXJ0LOqz)\n', '\n', '$QUOTETOBEREPLACED$ *"The area under the receiver operating characteristic (ROC) curve is a popular measure of the power of a (two-disease) diagnostic test, but it is shown here to be an inconsistent criterion: tests of indistinguishable clinical impacts may have different areas"*\n', '\n', '[Davis and Goadrich (2006)](https://www.google.com/url?q=https://doi.org/10.1145/1143844.1143874&sa=D&source=editors&ust=1717021441165555&usg=AOvVaw00_3WDsQFNaY5TOBP01v0R)\xa0The relationship between Precision-Recall and ROC curves: [Cited by 5798](https://www.google.com/url?q=https://scholar.google.ca/scholar?cites%3D10708180947310062390%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441165686&usg=AOvVaw0sJQ-ZPqzPYNiXhlq4Qz0b)\n', '\n', '$QUOTETOBEREPLACED$ *"However, when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more informative picture of an algorithm‚Äôs performance."*\n', '\n', '[Saito and Rehmsmeier (2015)](https://www.google.com/url?q=https://doi.org/10.1371/journal.pone.0118432&sa=D&source=editors&ust=1717021441165878&usg=AOvVaw1eT6LTpb0aTNuA6VAqreoW)\xa0The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets: [Cited by 2332](https://www.google.com/url?q=https://scholar.google.ca/scholar?cites%3D15154271232411513624%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441166006&usg=AOvVaw0N08fxr8etY9xDgG6JMQ5U)\n', '\n', '$QUOTETOBEREPLACED$ ‚ÄùWhile ROC plots are visually appealing and provide an overview of a classifier‚Äôs performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image204.png)\n', '\n', '$QUOTETOBEREPLACED$ Fig 5. PRC is changed but the other plots are unchanged between balanced and imbalanced data. Each panel contains two plots with balanced (left) and imbalanced (right) for (A) ROC, (B) CROC with exponential function: f(x) = (1 - exp(-Œ±x))/(1 - exp(-Œ±)) where Œ± = 7, (C) CC, and (D) PRC. Five curves represent five different performance levels: Random (Rand; red), Poor early retrieval (ER-; blue), Good early retrieval (ER+; green), Excellent (Excel; purple), and Perfect (Perf; orange).\n', '\n', '[Assel et al. (2017)](https://www.google.com/url?q=https://doi.org/10.1186/s41512-017-0020-3&sa=D&source=editors&ust=1717021441166351&usg=AOvVaw27-s0mXkVKhrCE13LDojmc): ‚ÄúThe Brier score does not evaluate the clinical utility of diagnostic tests or prediction models‚Äù \xa0[Cited by 84](https://www.google.com/url?q=https://scholar.google.co.uk/scholar?cites%3D15730841479033088835%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441166511&usg=AOvVaw0_7hfwuRja5ls7P0YdZVsZ)\n', '\n', '$QUOTETOBEREPLACED$ A variety of statistics have been proposed as tools to help investigators assess the value of diagnostic tests or prediction models. The Brier score has been recommended on the grounds that it is ****a proper scoring rule****that is affected by both discrimination and calibration. However, the Brier score is ****prevalence dependent****\xa0in such a way that the rank ordering of tests or models may inappropriately vary by prevalence.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ We explored ****four common clinical scenarios****:\n', '\n', '1. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ comparison of a highly accurate binary test with a continuous prediction model of moderate predictiveness;\n', '2. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ comparison of two binary tests where the importance of sensitivity versus specificity is inversely associated with prevalence;\n', '3. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ comparison of models and tests to default strategies of assuming that all or no patients are positive;\n', '4. $QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ and comparison of two models with miscalibration in opposite directions.\n', '\n', '$QUOTETOBEREPLACED$ In each case, we found that the ****Brier score gave an inappropriate rank ordering of the tests and models****. Conversely, **==**==net benefit==**==**, a decision-analytic measure,****gave results that always favored the preferable test or model****. **==**==Brier score does not evaluate clinical value of diagnostic tests or prediction models==**==**. We advocate, as an alternative, the use of decision-analytic measures such as **==**==net benefit==**==**.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Recent years have seen considerable methodologic criticism of these traditional metrics. This was driven, at least in part, by interest ****in molecular markers****. For instance, it has been argued out that **==**==AUC is insensitive==**==**, that it does not markedly increase when a new marker is added to a model unless the odds ratio for that marker is very high [2, 3]. In 2008, Pencina and colleagues introduced the net reclassification improvement (NRI) as an alternative metric to AUC [4]. The NRI measures the incremental prognostic impact of a new predictor when added to an existing prediction model for a binary outcome [5]. The metric became very widely used within a short period of time, a phenomenon attributed **==**==to the view that change in AUC will be small even for valuable markers==**==**\xa0[6]. The NRI has since been debunked; Kerr et al. provide a comprehensive evaluation of the disadvantages of NRI [7]. Hilden and Gerds demonstrated that miscalibration can improve NRI and so, critically, this results in the size of the test for NRI being much larger than nominal levels under the null [5]. Hilden and Gerds‚Äô commentary on their findings focuses on the concept of a **"proper scoring rule"**, that is, a ****metric that is maximized when correct probabilities are used****\xa0[5]. The authors mention the Brier score as an example of a proper scoring rule.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The **==**==Brier score is an improvement==**==**\xa0over other statistical performance measures, such as AUC, because it is ****influenced by both discrimination and calibration simultaneously,****\xa0with smaller values indicating superior model performance. The Brier score also estimates a well-defined parameter in the population, the mean squared distance between the observed and expected outcomes. The square root of the Brier score is thus the expected distance between the observed and predicted value on the probability scale.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Zepeng Huo et al. (2022)](https://www.google.com/url?q=https://arxiv.org/pdf/2207.11382.pdf&sa=D&source=editors&ust=1717021441167830&usg=AOvVaw1D9bLogTzAGz5H_fqnCblz): ‚ÄúDensity-Aware Personalized Training for Risk Prediction in Imbalanced Medical Data‚Äù\n', '\n', '$QUOTETOBEREPLACED$ "In addition to the traditional way of measuring probabilistic output of the medical models, i.e. area under the receiver operating curve (AUC-ROC), we argue that we need to incorporate the metrics that can represent the difficulties induced by imbalanced class densities.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image94.png)\n', '\n', '$QUOTETOBEREPLACED$ We compared the AUC-ROC plot and AUC-PRC plot of our model and the R-MLP baseline in Figure 2 and 3. As can be seen, the ****AUC-ROC****\xa0plots of the two models are similar, however, the AUC-PRC plot shows on the upper region of the curve the baseline is performing rather unstably but our model gives a more smooth curve. In [Saito and Rehmsmeier (2015)](https://www.google.com/url?q=https://doi.org/10.1371/journal.pone.0118432&sa=D&source=editors&ust=1717021441168145&usg=AOvVaw2TWEJayicF6xCjXwAv1xkv), this region is defined as early retrieval region, where is usually used to measure in information retrieval application for when results of interest account for a small portion of all the corpus [Hilden (1991)](https://www.google.com/url?q=https://doi.org/10.1177/0272989x9101100204&sa=D&source=editors&ust=1717021441168270&usg=AOvVaw0bszVSIJgBfVxdPqSQJEfL); [Truchon and Bayly (2007)](https://www.google.com/url?q=https://doi.org/10.1021/ci600426e&sa=D&source=editors&ust=1717021441168370&usg=AOvVaw2Jz_9pLqMnfyKXuSA4hVF5)\xa0(what is the model precision when recall rate is low). We can conclude our model has better performance on AUC-PRC is due to the better part on early retrieval where it can better handle the imbalance for the class of interest\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ First AUC-ROC only measures the true positives (TP) and false positive (FP) relationship, which can present an overly optimistic view of an algorithm‚Äôs performance if there is large skew in the class distribution [Davis and Goadrich (2006)](https://www.google.com/url?q=https://doi.org/10.1145/1143844.1143874&sa=D&source=editors&ust=1717021441168582&usg=AOvVaw0PfKqncY1KImsEFiMvNaJV), [Cited by 5798](https://www.google.com/url?q=https://scholar.google.ca/scholar?cites%3D10708180947310062390%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441168706&usg=AOvVaw1gf-rIOzQYVEaDKVPNelxi)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ On the other hand, area under ****precision-recall curve (AUC-PRC)****\xa0can provide a ****more reliable interpretation under imbalance****, due to the fact that they evaluate the fraction of true positives among positive predictions [Saito and Rehmsmeier (2015)](https://www.google.com/url?q=https://doi.org/10.1371/journal.pone.0118432&sa=D&source=editors&ust=1717021441168958&usg=AOvVaw0sX5NsXio1JZfGIxBHWpNa), [Cited by 2332](https://www.google.com/url?q=https://scholar.google.ca/scholar?cites%3D15154271232411513624%26as_sdt%3D2005%26sciodt%3D0,5%26hl%3Den&sa=D&source=editors&ust=1717021441169089&usg=AOvVaw2LGcUfeNhLSda4yry9uMTD), and the precision-recall relationship will change when the test set‚Äôs imbalance ratio changes, thus providing more sensitive evaluation [Davis and Goadrich (2006](https://www.google.com/url?q=https://doi.org/10.1145/1143844.1143874&sa=D&source=editors&ust=1717021441169291&usg=AOvVaw1PbbPeC-Imvnnyf8ym4Ehj)). Furthermore, in a medical model, the conventional way of measuring the model is through ****Brier score****\xa0Brier et al. (1950), which takes into consideration the calibration of the model. However, the Brier score is also susceptible to imbalance ratio [Fern√°ndez et al. (2018)](https://www.google.com/url?q=https://doi.org/10.1007/978-3-319-98074-4&sa=D&source=editors&ust=1717021441169453&usg=AOvVaw2Vhkd6GyEo-eA0HHK3vhso). We propose to use **==**==Brier Skill Score (BSS)==**==**[Fern√°ndez et al. (2018)](https://www.google.com/url?q=https://doi.org/10.1007/978-3-319-98074-4&sa=D&source=editors&ust=1717021441169588&usg=AOvVaw1tJxnYK4hv9HKsMiwjgE4i), where the model takes the calculated Brier score and compare it to a reference point, i.e. a scaled Brier score by its maximum score under a non-informative model [Steyerberg et al. (2010)](https://www.google.com/url?q=https://doi.org/10.1097/ede.0b013e3181c30fb2&sa=D&source=editors&ust=1717021441169749&usg=AOvVaw0soQmEaZBmu4klTHMNWb1P), to show the improvement:"\n', '\n', '[Faghani et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1148/ryai.220061&sa=D&source=editors&ust=1717021441169946&usg=AOvVaw0AuSzoqoneh6nCtYMn4pPZ): Mitigating Bias in Radiology Machine Learning: 3. Performance Metrics\n', '\n', '$QUOTETOBEREPLACED$ The increasing use of machine learning (ML) algorithms in clinical settings raises concerns about****bias in ML models****. Bias can arise at any step of ML creation, including data handling, model development, and performance evaluation. Potential biases in the ML model can be minimized by implementing these steps correctly. This report focuses on ****performance evaluation and discusses model fitness****\xa0as well as a set of performance evaluation toolboxes, namely performance metrics, **==**==performance interpretation maps, and uncertainty quantification==**==**. By discussing the strengths and limitations of each toolbox, our report highlights strategies and considerations to mitigate and detect biases during performance evaluations of radiology artificial intelligence models.\n', '\n', '[Ramon Diaz-Uriarte et al. (August 2022)](https://www.google.com/url?q=https://doi.org/10.1371/journal.pcbi.1010357&sa=D&source=editors&ust=1717021441170317&usg=AOvVaw0HG8rOdKu3zfik4IhHGN_E): ‚ÄúTen quick tips for biomarker discovery and validation analyses using machine learning‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Here, we provide a set of broadly applicable tips to ****address some of the most common pitfalls and limitations for biomarker signature development****, including supervised and unsupervised machine learning, feature selection and hypothesis testing approaches. In contrast to previous guidelines discussing detailed aspects of quality control, statistics or study reporting, we give a broader overview of the typical challenges and sort the quick tips to address them chronologically by the study phase (starting with study design, then covering consecutive phases of biomarker signature discovery and validation, see also the overview in Fig 1).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image80.png)\n', '\n', '$QUOTETOBEREPLACED$ Apart from **p**-value significance scores, **==**==confidence intervals and similar measures of uncertainty should be assessed [==**==**[76](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref076&sa=D&source=editors&ust=1717021441170813&usg=AOvVaw25mC_DzLCKNdhiQDBmxfy2)**==**==‚Äì==**==**[79](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref079&sa=D&source=editors&ust=1717021441170955&usg=AOvVaw0xbkyM3A-wW52CoTaYYl8y)**==**==]==**==**, taking into account the limitations of individual uncertainty measures [[80](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref080&sa=D&source=editors&ust=1717021441171112&usg=AOvVaw2539Ekx9qZHupA39SapkJ1)]. Finally, in addition to assessing individual machine learning algorithms, the integration of modeling approaches using ensemble learning (for both supervised and unsupervised problems) or consensus clustering (for unsupervised problems) may be explored to combine the benefits of different modeling methods [[81](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref081&sa=D&source=editors&ust=1717021441171272&usg=AOvVaw05CCXjqrTv5HzQaXOZFnE7),[82](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref082&sa=D&source=editors&ust=1717021441171405&usg=AOvVaw3tYHOpeU10iucVNCTl-bV0)].\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ There is a quickly growing literature on **==**==Explainable AI (XAI) techniques==**==**\xa0to interpret also very complex black-box models, such as neural networks. Examples include Shapley Additive Explanations [[143](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref143&sa=D&source=editors&ust=1717021441171656&usg=AOvVaw1lq5EzB8CfTljkfnyNqmH9)], LIME [[144](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref144&sa=D&source=editors&ust=1717021441171788&usg=AOvVaw2OZqA5CUD447EbfFNOtMq9)], Explainable Boosting Machines [[145](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref145&sa=D&source=editors&ust=1717021441171914&usg=AOvVaw26aDKItx9r31oEd2XXiQNH)], and symbolic meta-modeling [[146](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref146&sa=D&source=editors&ust=1717021441172042&usg=AOvVaw3FYT4ddo5ner-CI-AiXYov)]. A systematic review of those and further methods can be found in [[147](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref147&sa=D&source=editors&ust=1717021441172197&usg=AOvVaw00aCh9kYcBb7AG1h308UEy),[148](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref148&sa=D&source=editors&ust=1717021441172342&usg=AOvVaw3rstbWewAgcX-rHo7UrgGG)].\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ While these tips are not comprehensive, they are chosen to cover what we consider as the most frequent, significant, and practically relevant issues and risks in biomarker development. By pointing the reader to further relevant literature on the covered aspects of biomarker discovery and validation, we hope to provide an initial guideline and entry point into the more detailed technical and application-specific aspects of this field.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ For an overview of related existing guidelines and data and methods standardization efforts, we also recommend to study the **"Criteria for the use of omics-based predictors in clinical trials"**\xa0by the US National Cancer Institute [[153](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref153&sa=D&source=editors&ust=1717021441172705&usg=AOvVaw3_cjD0ba38dTgQcrXlfm_N)] with a focus on omics-derived biomarkers and the standard framework **"Assessing Credibility of Computational Modeling through Verification and Validation: Application to Medical Devices"**\xa0with a broad applicability beyond the specific framework focus on medical devices [[154](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref154&sa=D&source=editors&ust=1717021441172870&usg=AOvVaw3nPp_w1EYmVpkM79oohAlF)]. Furthermore, as a guidance on how to document and present biomarker results derived from machine learning approaches, we refer the reader to the TRIPOD Statement on **"Transparent reporting of a multivariable prediction model for individual prognosis or diagnosis"**\xa0[[155](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref155&sa=D&source=editors&ust=1717021441173036&usg=AOvVaw3qXejCis72a7Wt0w6FbJQ0)] and the more generic **"Standards for Reporting of Diagnostic Accuracy (STARD)"**\xa0[[12](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref012&sa=D&source=editors&ust=1717021441173216&usg=AOvVaw1lmRML3WipN-HyyLhTtt2D),[13](https://www.google.com/url?q=https://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1010357%23pcbi.1010357.ref013&sa=D&source=editors&ust=1717021441173417&usg=AOvVaw3_7nX7cGVJFYMXX_TiTy8n)]. In practice, project managers should also ensure that the required multidisciplinary expertise for all project phases is well represented in the project consortium, and that measures for effective cross-disciplinary communication throughout the project are set in place.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ As further steps in the future, community-driven standardization efforts, involving researchers, practitioners, and regulators in the field, are still needed to develop more comprehensive and detailed documentation and validation standards, minimum requirements, and study type-specific guidelines to further****improve the quality of biomarker stratification and prediction projects****.\n', '\n', '[Diana Mincu & Subhrajit Roy (2022)](https://www.google.com/url?q=https://doi.org/10.1038/s42256-022-00559-4&sa=D&source=editors&ust=1717021441173723&usg=AOvVaw1l7rAbdfpRPmerBDk2IId9): ‚ÄúDeveloping robust benchmarks for driving forward AI innovation in healthcare‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Machine learning technologies have seen increased application to the healthcare domain. The main drivers are openly available healthcare datasets, and a general interest from the community to use its powers for knowledge discovery and technological advancements in this more conservative field. However, with this additional volume comes a range of questions and concerns ‚Äî **==**==are the obtained results meaningful and conclusions accurate==**==**; how do we know we have improved state of the art; is the clinical problem well defined and ****does the model address it?****\xa0We reflect on key aspects in the end-to-end pipeline that we believe suffer the most in this space, and suggest some good practices to avoid reproducing these issues.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image206.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image21.png)\n', '\n', '[Zhou et al. (2023)](https://www.google.com/url?q=https://arxiv.org/abs/2305.13426&sa=D&source=editors&ust=1717021441174112&usg=AOvVaw0C0FPFAVSRn3cjoecKKkFq): ‚ÄúEvaluating Model Performance in Medical Datasets Over Time‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Machine learning (ML) models deployed in healthcare systems must face data drawn from ****continually evolving environments****. However, researchers proposing such models typically evaluate them in a time-agnostic manner, splitting datasets according to patients sampled randomly throughout the entire study time period. This work proposes the **==**==Evaluation on Medical Datasets Over Time (EMDOT) framework,==**==**\xa0which evaluates the performance of a model class across time. Inspired by the ****concept of backtesting****, EMDOT simulates possible training procedures that practitioners might have been able to execute at each point in time and ****evaluates the resulting models on all future time points****. Evaluating both linear and more complex models on six distinct medical data sources (tabular and imaging), we show how ****depending on the dataset, using all historical data may be ideal in many cases****, whereas using a****window of the most recent data could be advantageous in others****. In datasets where models suffer from **==**==sudden degradations in performance==**==**, we investigate **==**==plausible explanations for these shocks==**==**. We release the EMDOT package to help facilitate further works in deployment-oriented evaluation over time.![](HTML%20import/Attachments/image47.png)![](HTML%20import/Attachments/image168.png)\n', '\n', '[White et al. (2023)](https://www.google.com/url?q=https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-023-03048-6&sa=D&source=editors&ust=1717021441174706&usg=AOvVaw3CnHJ6qlY-FuRo2I0DIoiW): ‚ÄúEvidence of questionable research practices in clinical prediction models‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The AUC is often interpreted relative to thresholds, with ‚Äúgood‚Äù or ‚Äúexcellent‚Äù models defined at 0.7, 0.8 or 0.9. These thresholds may ==create targets that result in "hacking"==, where researchers are motivated to re-analyse their data until they achieve a ‚Äúgood‚Äù result. The distribution of ****306,888 AUC values****\xa0showed clear excesses above the thresholds of 0.7, 0.8 and 0.9 and shortfalls below the thresholds.  \n', '  \n', 'The ****AUCs for some models are over-inflated****, which risks exposing patients to sub-optimal clinical decision-making. Greater modelling transparency is needed, including published protocols, and data and code sharing.  \n', '  \n', '![](HTML%20import/Attachments/image109.png)  \n', 'Histogram of AUC mean values (top panel) and residuals from a smooth fit to the histogram (bottom panel). The dotted line in the top panel shows the smooth fit\n', '\n', '#### Decision Curve Analysis (DCA)\n', '\n', 'Not like Decision Curve Analysis (DCA) has become widely accepted standard either, e.g. when going beyond just addressing the class imbalance\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image175.png)\n', '\n', '$QUOTETOBEREPLACED$ [A Systematic Review of the Literature Demonstrates Some Errors in the Use of Decision Curve Analysis but Generally Correct Interpretation of Findings](https://www.google.com/url?q=https://doi.org/10.1177%252F0272989X19832881&sa=D&source=editors&ust=1717021441175448&usg=AOvVaw0KdC1fiFgFO-Dz2K0hC8E7)\xa0Paolo Capogrosso, Andrew J. Vickers Medical Decision Making (February 28, 2019)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '![](HTML%20import/Attachments/image126.png)\n', '\n', 'J√∏rgen Hilden. Evaluation of diagnostic tests: the schism. Soc Med Decis Making Newsletter. 2004;16:5‚Äì6. , [Vickers and Elkin (2006)](https://www.google.com/url?q=https://doi.org/10.1177/0272989X06295361&sa=D&source=editors&ust=1717021441175740&usg=AOvVaw2IJtjqIeVOAYEj6yF1SJTT)\n', '\n', '[](https://www.google.com/url?q=https://rspc.cafe/secure-media-uploads/original/2X/b/b81ff7702a0d4c73d5a1e5ef49d06de30e2ce9a7.jpeg&sa=D&source=editors&ust=1717021441175934&usg=AOvVaw3Kx9iCpHipo1G0BE9991hJ)\n', '\n', '![](HTML%20import/Attachments/image147.png)\n', '\n', '[The Brier score does not evaluate the clinical utility of diagnostic tests or prediction models (2017)](https://www.google.com/url?q=https://doi.org/10.1186/s41512-017-0020-3&sa=D&source=editors&ust=1717021441176247&usg=AOvVaw144IUx8pesx0jc7cdRJdH2)\n', '\n', '[How should we evaluate prediction tools? Comparison of three different tools for prediction of seminal vesicle invasion at radical prostatectomy as a test case (2012)](https://www.google.com/url?q=https://dx.doi.org/10.1016%252Fj.eururo.2012.04.022&sa=D&source=editors&ust=1717021441176433&usg=AOvVaw2MYJAdFe_K1JujmdA_5ehZ)\n', '\n', '[Luqing Zhao et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1093/postmj/qgae027&sa=D&source=editors&ust=1717021441176604&usg=AOvVaw1vNl2Que_eHRvz-Ns0cHg3): ‚ÄúUnderstanding decision curve analysis in clinical prediction model research‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Background****Many medical graduate students lack a thorough understanding of decision curve analysis (DCA), a valuable tool in clinical research for evaluating diagnostic models.\n', '\n', '$QUOTETOBEREPLACED$ ****Methods****This article elucidates the concept and process of DCA through the lens of clinical research practices, exemplified by its application in diagnosing liver cancer using serum alpha-fetoprotein levels and radiomics indices. It covers the calculation of probability thresholds, computation of net benefits for each threshold, construction of decision curves, and comparison of decision curves from different models to identify the one offering the highest net benefit.\n', '\n', '$QUOTETOBEREPLACED$ ****Results****The paper provides a detailed explanation of DCA, including the creation and comparison of decision curves, and discusses the relationship and differences between decision curves and receiver operating characteristic curves. It highlights the superiority of decision curves in supporting clinical decision-making processes.\n', '\n', '$QUOTETOBEREPLACED$ ****Conclusion****By clarifying the concept of DCA and highlighting its benefits in clinical decision making, this article has improved researchers‚Äô comprehension of how DCA is applied and interpreted, thereby enhancing the quality of research in the medical field.\n', '\n', '#### Optimizing AUC, reducing FPR, etc.\n', '\n', '[Mohammadi et al. (March 2023)](https://www.google.com/url?q=https://arxiv.org/pdf/2304.00049.pdf&sa=D&source=editors&ust=1717021441177101&usg=AOvVaw20XH3A475EtJSmrZC3DFDl): ‚ÄúRanking Regularization for Critical Rare Classes: Minimizing False Positives at a High True Positive Rate‚Äù\n', '\n', '$QUOTETOBEREPLACED$ In many real-world settings, the critical class is rare and a **==**==missed detection carries a disproportionately high cost.==**==**\xa0For example, tumors are rare and a false negative diagnosis could have severe consequences on treatment outcomes; fraudulent banking transactions are rare and an undetected occurrence could result in significant losses or legal penalties. In such contexts, systems are often ****operated at a high true positive rate, which may require tolerating high false positives****. In this paper, we present a novel approach to address the challenge of ****minimizing false positives****for systems that need to operate at a high true positive rate. We propose a **==**==ranking-based regularization (RankReg)==**==**approach that is****easy to implement****, and show empirically that it not only effectively reduces false positives, but also complements conventional imbalanced learning losses (long-tail learning).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image90.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image86.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image97.png)\n', '\n', '$QUOTETOBEREPLACED$ ****Deep AUC optimization.****\xa0Our work can be considered (and will be demonstrated in Section 4) as an optimizer for maximizing the AUC score, cf. [10,19,33,34]. Nonetheless, none of them are designed to favor low false positive rates given a high true positive rate requirement. The work most similarly motivated to ours is ALM [24], which recently advocated yielding higher score (i.e. probability) for critical positives than non-critical negatives, thus improving the AUC. ALM formulates the problem from a constrained optimization perspective and achieves strong empirical results.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ **[10] Wei Gao and Zhi-Hua Zhou. On the consistency of AUC pairwise optimization. In IJCAI, 2015. 2, 6**\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ **[19] Mingrui Liu, Zhuoning Yuan, Yiming Ying, and Tianbao Yang. Stochastic AUC maximization with deep neural networks. arXiv preprint arXiv:1908.10831, 2019. 2, 6**\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ **[24] Sara Sangalli, Ertunc Erdil, Andreas Hoetker, Olivio Donati, and Ender Konukoglu. Constrained optimization to train neural networks on critical and under-represented classes. In NeurIPS, 2021. 2, 3, 4, 5, 6, 7, 8, 9**\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ **[33] Yiming Ying, Longyin Wen, and Siwei Lyu. Stochastic online AUC maximization. In NeurIPS, 2016. 2, 6**\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ **[34] Zhuoning Yuan, Yan Yan, Milan Sonka, and Tianbao Yang. Large-scale robust deep AUC maximization: A new surrogate loss and empirical studies on medical image classification. In CVPR, 2021. 2, 6**\n', '\n', '#### Uncertainty Quantification\n', '\n', '[2024 CV Deep Learning Literature Diary](https://www.google.com/url?q=https://docs.google.com/document/d/1wwCXhAX-b8fs3qSd1lxHVsO6irK35i592lFgyW2iSGU/edit%23heading%3Dh.dppvh2p08lg&sa=D&source=editors&ust=1717021441178406&usg=AOvVaw1Jc8WgqZWik8HFECPVw5ZW)\n', '\n', '[Selective classification (‚Äúrejection option‚Äù)](https://www.google.com/url?q=https://docs.google.com/document/d/1wwCXhAX-b8fs3qSd1lxHVsO6irK35i592lFgyW2iSGU/edit%23heading%3Dh.cksp9gwaekoo&sa=D&source=editors&ust=1717021441178601&usg=AOvVaw1DwKNrLXBZmxUl7jy7_z0g)\n', '\n', '[Conformal prediction](https://www.google.com/url?q=https://docs.google.com/document/d/1wwCXhAX-b8fs3qSd1lxHVsO6irK35i592lFgyW2iSGU/edit%23heading%3Dh.mxaj69mtp1ei&sa=D&source=editors&ust=1717021441178780&usg=AOvVaw1RrjYndhNu0RnNXUl7FMSS)\n', '\n', '[Angelopoulos et al. (2024)](https://www.google.com/url?q=https://www.medrxiv.org/content/10.1101/2024.02.09.24302543v1.full.pdf&sa=D&source=editors&ust=1717021441179030&usg=AOvVaw107wlasscwOkewDyhGJmJf): ‚ÄúConformal Triage for Medical Imaging AI Deployment‚Äù\n', '\n', '$QUOTETOBEREPLACED$ We introduce the conformal triage algorithm, designed to **==**==categorize patients into low-risk, high-risk, and uncertain groups==**==**\xa0within a clinical deployment setting. This method leverages a combination of a black-box AI model and **==**==conformal prediction==**==**\xa0techniques to offer statistical guarantees of predictive power for each group. The high-risk group is guaranteed to have a high positive predictive value (PPV), while the low-risk group is assured a high negative predictive value (NPV). Prediction sets are never constructed; instead, ****conformal techniques directly assure high accuracy in both groups****,**==**==even in clinical environments different from those in which the AI model was originally trained==**==**, thereby ameliorating the challenges posed by ****distribution shifts****. Importantly, a representative data set of exams from the testing environment is required to ensure statistical validity.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image137.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image132.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image159.png)\n', '\n', '#### Transparency & Reporting\n', '\n', '[Fehr et al. (2024)](https://www.google.com/url?q=https://doi.org/10.3389/fdgth.2024.1267290&sa=D&source=editors&ust=1717021441179675&usg=AOvVaw188X85SRt4MCKUK0_z1WTM): A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare\n', '\n', '$QUOTETOBEREPLACED$ Trustworthy medical AI requires transparency about the development and testing of underlying algorithms to identify biases and communicate potential risks of harm. Abundant guidance exists on how to achieve transparency for medical AI products, but it is unclear whether publicly available information adequately informs about their risks. To assess this, we **==**==retrieved public documentation on the 14 available CE-certified AI-based radiology products==**==**\xa0of the II b risk category in the EU from vendor websites, scientific publications, and the European EUDAMED database. Using a self-designed survey, we reported on their development, validation, ethical considerations, and deployment caveats, according to trustworthy AI guidelines. We scored each question with either 0, 0.5, or 1, to rate if the required information was ‚Äúunavailable‚Äù, ‚Äúpartially available,‚Äù or ‚Äúfully available.‚Äù The ****transparency of each product was calculated****relative to all 55 questions. **==**==Transparency scores ranged from 6.4% to 60.9%, with a median of 29.1%==**==**. Major transparency gaps included missing documentation on training data, ethical considerations, and limitations for deployment. Ethical aspects like consent, safety monitoring, and GDPR-compliance were rarely documented. Furthermore, deployment caveats for different demographics and medical settings were scarce. In conclusion, public documentation of authorized medical AI products in Europe **==**==lacks sufficient public transparency to inform about safety and risks==**==**. We call on lawmakers and regulators to establish legally mandated requirements for public and substantive transparency to fulfill the promise of trustworthy AI for health.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image65.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image74.png)\n', '\n', '$QUOTETOBEREPLACED$ Degree of transparency from publicly available information of 14 CE-certified medical AI tools for radiology. The degree of transparency is grouped by model development, clinical validation results, and ethics. The percentage indicates the transparency of each category relative to the total amount of questions in each category (marked as ‚Äún=‚Äù).\n', '\n', '### ‚ÄòRegulatory Evaluation‚Äô\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image208.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ Do your AI/ML engineers have access to your Test Dataset? This may be a $100k+ mistake. Your Test Dataset is the set of data that is never shown to the ML training algorithm during training. It is used to estimate the ML model's performance after training.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ FDA understands that ****if you reuse the Test Dataset too many times****, you may be implicitly using it to train your model. At the same time, FDA realize Test Datasets can be very expensive to develop. They therefore DO allow you to reuse them‚Äîbut you need to do so carefully.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Many AI/ML startups are not being careful. Their AI/ML engineers have direct access to their test dataset. Often, anyone on the team can access this valuable data anytime. Furthermore, **==**==no records are kept of when or why they‚Äôre evaluating their model‚Äôs performance==**==**.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****FDA could ask about your test data reuse****. They could ask what procedures you had in place to prevent overfitting. Worst case, they may ask you to collect a new Test Dataset. For many AI/ML teams, this would be a $100k, $200k, or $500k problem.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ To avoid this problem, we suggest that our client‚Äôs follow FDA‚Äôs Guidance:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ "In the event that you would like the [FDA] to consider the reuse of any test data in your standalone evaluation, you should control the access of your staff to performance results for the test subpopulations and individual cases. It may therefore be necessary for you to==set up a "firewall" to ensure those outside of the regulatory assessment team (e.g., algorithm developers) are completely insulated from knowledge of the [test data].==\xa0You should maintain test data integrity throughout the lifecycle of the product. This is analogous to data integrity involving clinical trial data monitoring committees and the use of a ‚Äúfirewall‚Äù to insulate personnel responsible for proposing interim protocol changes from knowledge of interim comparative results."\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '## Measuring Generalization (Proxies, etc.)\n', '\n', '[Matthias Feurer](https://www.google.com/url?q=https://arxiv.org/abs/2212.04183&sa=D&source=editors&ust=1717021441181061&usg=AOvVaw1CjM0u2G28KlQyKxXZwMeS)\xa0[et al. (2022)](https://www.google.com/url?q=https://arxiv.org/abs/2212.04183&sa=D&source=editors&ust=1717021441181154&usg=AOvVaw0-8P5Fw7RgD5ningijGwOJ): Mind the Gap: Measuring Generalization Performance Across Multiple Objectives\n', '\n', '$QUOTETOBEREPLACED$ Modern machine learning models are often constructed taking into account multiple objectives, e.g., to minimize inference time while also maximizing accuracy. ****Multi-objective hyperparameter optimization (MHPO)****\xa0algorithms return such candidate models and the approximation of the ****Pareto front****is used to assess their performance. However, when estimating generalization performance of an approximation of a Pareto front found on a validation set by computing the performance of the individual models on the test set, models might no longer be Pareto-optimal. This makes it ****unclear how to measure performance****. To resolve this, we provide a novel evaluation protocol that allows measuring the generalization performance of MHPO methods and to study its capabilities for comparing two optimization experiments.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image173.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image48.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image45.png)\n', '\n', '[Zhang et al. (2022)](https://www.google.com/url?q=https://arxiv.org/abs/2212.00850&sa=D&source=editors&ust=1717021441181676&usg=AOvVaw3jy1et4NHFTq5uZ2WsNFIn): ‚ÄúWhen Neural Networks Fail to Generalize? A Model Sensitivity Perspective‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Domain generalization (DG) aims to train a model to perform well in unseen domains under different distributions. This paper considers a more realistic yet more challenging scenario,namely ****Single Domain Generalization (Single-DG),****\xa0where only a single source domain is available for training. To tackle this challenge, we first try to understand ****when neural networks fail to generalize?****We empirically ascertain a property of a model that correlates strongly with its generalization that we coin as "model sensitivity". Based on our analysis, we propose a novel strategy of Spectral Adversarial Data Augmentation (SADA) to ****generate augmented images targeted at the highly sensitive frequencies.****\xa0Models trained with these hard-to-learn samples can effectively suppress the sensitivity in the frequency space, which leads to improved generalization performance. Extensive experiments on multiple public datasets demonstrate the superiority of our approach, which surpasses the state-of-the-art single-DG methods.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image33.png)\n', '\n', '$QUOTETOBEREPLACED$ Spatial frequency power spectrum, Fourier\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Fu et al. (2023)](https://www.google.com/url?q=https://arxiv.org/pdf/2304.12579.pdf&sa=D&source=editors&ust=1717021441182159&usg=AOvVaw1cOb6LpUSEsbpg9qf9hw3a): ‚ÄúLearning Trajectories are Generalization Indicators‚Äù\n', '\n', '$QUOTETOBEREPLACED$ This paper aims to investigate the relation between learning trajectories of the Deep Neural Networks (DNNs) and their corresponding generalization capabilities when being optimized with gradient descent and stochastic gradient descent algorithms. In this paper, we construct ****Linear Approximation Function to model the trajectory information****\xa0and we propose ****a new generalization bound with richer trajectory information based on this modelling.****\xa0Our proposed generalization bound **==**==relies on the complexity of learning trajectory and the ratio between the bias and diversity of training set==**==**. Experimental results indicate that the proposed method effectively captures the generalization trend across various iterations, learning rates, and label noise levels across entire training process.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image133.png)\n', '\n', '[Corso et al. (2023, Stanford)](https://www.google.com/url?q=https://arxiv.org/pdf/2307.10586.pdf&sa=D&source=editors&ust=1717021441182558&usg=AOvVaw2WFid5k2ybu4SPdaO2jrrk): ‚ÄúA Holistic Assessment of the Reliability of Machine Learning Systems‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Underspecification****\xa0In accordance with prior work, we find that deep neural networks are underspecified (selecting for one metric does not constrain the others) across all reliability metrics we measure. We found ****almost no intrinsic correlation between any of the reliability metrics****\xa0when measured on over 500 models trained in diverse ways across three real-world datasets. This conclusion has several key implications. Firstly, it **==**==underscores the critical need for comprehensive evaluation methodologies==**==**\xa0in the development of machine learning algorithms, **==**==of which the HR score is a small step towards==**==**. Not only should individual reliability metrics be assessed and optimized, but understanding their interdependencies and the potential trade-offs is equally essential. Secondly, it highlights the ****importance of model selection****\xa0prior to deployment. Any reliability metric that is not measured and selected could take on a wide range of values, potentially hurting overall system performance. Lastly, the lack of connections between these metrics means there can be substantial value in developing techniques that improve one of these reliability metrics in isolation (like temperature scaling does for calibration). These bespoke methods could then be combined to ****construct high-reliability models****\xa0in a more modular fashion.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image23.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image196.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image146.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image49.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image134.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image103.png)\n', '\n', '$QUOTETOBEREPLACED$ Camelyon17, HR score = ****holistic reliability (HR) score****\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image104.png)\n', '\n', '## Continuous development of medical models\n', '\n', '[Monika Steidl et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1016/j.jss.2023.111615&sa=D&source=editors&ust=1717021441183472&usg=AOvVaw3gDfAf-WhCEa6bzoQ6FLAH): ‚ÄúThe pipeline for the continuous development of artificial intelligence models‚ÄîCurrent state of research and practice‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ****Highlights****\n', '\n', '$QUOTETOBEREPLACED$ ‚Ä¢ Terms for AI and DevOps, CI/CD, MLOps, continuous development lifecycle, CD4ML.\n', '\n', '$QUOTETOBEREPLACED$ ‚Ä¢ Trigger types for executing the continuous development of AI.\n', '\n', '$QUOTETOBEREPLACED$ ‚Ä¢ AI pipeline: data handling, model learning, software development, system operations.  \n', '‚Ä¢ Pipeline-specific challenges for continuous AI development.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image148.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image24.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image34.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Cardoso et al. (2024)](https://www.google.com/url?q=https://arxiv.org/pdf/2311.14570.pdf&sa=D&source=editors&ust=1717021441184093&usg=AOvVaw2FMlolVfAlOdxa7ZGg4MXY): ‚ÄúRAISE ‚Äì Radiology AI Safety, an End-to-end lifecycle approach‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The integration of AI into radiology introduces opportunities for improved clinical care provision and efficiency but it demands a meticulous approach to mitigate potential risks as with any other new technology. Beginning with ****rigorous pre-deployment evaluation and validation****, the focus should be on ensuring models meet the highest standards of safety, effectiveness and efficacy for their intended applications.**********==**==Input and output guardrails implemented during production usage==**==**\xa0act as an additional layer of protection, identifying and addressing individual failures as they occur.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ **==**==Continuous postdeployment monitoring==**==**\xa0allows for tracking population-level performance (data drift), fairness, and value delivery over time. Scheduling reviews of post-deployment model performance and educating radiologists about new algorithmic-driven findings is critical for AI to be effective in clinical practice. Recognizing that****no single AI solution can provide absolute assurance even when limited to its intended use, the synergistic application of quality assurance at multiple levels****- regulatory, clinical, technical, and ethical - is emphasized. Collaborative efforts between stakeholders spanning healthcare systems, industry, academia, and government are imperative to address the multifaceted challenges involved. ****Trust in AI is an earned privilege****, contingent on a broad set of goals, among them transparently demonstrating that the AI adheres to the same rigorous safety, effectiveness and efficacy standards as other established medical technologies. By doing so, developers can instil confidence among providers and patients alike, enabling the responsible scaling of AI and the realization of its potential benefits. The roadmap presented herein aims to expedite the achievement of deployable, reliable, and safe AI in radiology.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image131.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Regulators reviewing submissions may request additional information, such as prospective clinical studies, to substantiate the performance of the AI model; approval is often based on reasonable assurances of safety and effectiveness for the intended use. Many research groups, with the support of professional societies such as ACR and RSNA, have enhanced formal regulatory requirements by ****publishing guidance documents****\xa0such as STARD-AI [9], FUTURE-AI [10], MI-CLAIM [11] or MINIMAR [12], outlining principles and best practices for healthcare AI. These cover topics like ****appropriate clinical validation****\xa0and their evidence hierarchy, transparent reporting of capabilities and limitations, and trial protocol design considerations. While informal, these guidelines represent a consensus expert view and can serve as complements to formal regulations.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image203.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The software technology stack used to develop radiology AI models must be of high quality and meet certain standards for safety and efficacy, ideally **==**==building upon trusted open-source toolkits such as MONAI==**==**\xa0[20]. When AI medical device manufacturers package these AI models into a complete SaMD, they need to ensure, to the best of their ability, that their software is ****free from errors, bugs, and security vulnerabilities, and that it can handle large amounts of data****. While most quality assurance (QA) processes are implemented by the manufacturer itself, **==**==bugs and errors in AI models are often a function of the input data==**==**, and thus models need to be continuously QA tested at every site they are deployed to ensure that AI models are reliable and effective.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image213.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image194.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image19.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image141.png)\n', '\n', '## Deployment & User Studies\n', '\n', '[Zhang et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1038/s41551-022-00898-y&sa=D&source=editors&ust=1717021441185483&usg=AOvVaw1Zr1GzatgaDDORHhcz3bBT): ‚ÄúShifting machine learning for healthcare from development to deployment and from models to data‚Äù\n', '\n', '$QUOTETOBEREPLACED$ In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The past decade of research in ML in healthcare has focused on model development, and the next decade will be defined by model deployment into clinical settings[42](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23ref-CR42&sa=D&source=editors&ust=1717021441185835&usg=AOvVaw2q9poMTd2JyP98dju6QgOZ),[45](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23ref-CR45&sa=D&source=editors&ust=1717021441186005&usg=AOvVaw15-1D1REoRdR_rkBMdMBrr),[46](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23ref-CR46&sa=D&source=editors&ust=1717021441186198&usg=AOvVaw32ZTHB3rVOmy1PttDfX9Bp),[154](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23ref-CR154&sa=D&source=editors&ust=1717021441186358&usg=AOvVaw3kEKjnkL0vlFZ6D2qcnQM2),[155](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23ref-CR155&sa=D&source=editors&ust=1717021441186511&usg=AOvVaw2fMfPlo0qcEYjlQF013fjX). In this section, we discuss two data-centric obstacles in model deployment: how to efficiently deliver raw clinical data (Table [4](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23Tab4&sa=D&source=editors&ust=1717021441186638&usg=AOvVaw33uP_YWf20PT17YJGYkdT_)) to models, and how to monitor and correct for natural data shifts that deteriorate model performance.\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image60.png)\n', '\n', '$QUOTETOBEREPLACED$ Delivering data to models A main obstacle to model deployment is associated with how to efficiently ****transform raw, unstructured and heterogeneous clinical data into structured data****\xa0that can be inputted into ML models. During model development, pre-processed structured data are directly inputted into the model. However, during deployment, minimizing the delay between the acquisition of raw data and the delivery of structured inputs requires an adept data pipeline for collecting data from their source, and for ingesting, preparing and transforming the data (Fig. [4](https://www.google.com/url?q=https://www.nature.com/articles/s41551-022-00898-y%23Fig4&sa=D&source=editors&ust=1717021441186966&usg=AOvVaw1N2J42ui4_OxncXbcW05Ji)). An ideal system would need to be high-throughput, have low latency and be scalable to a large number of data sources. A lack of optimization can result in major sources of inefficiency and delayed predictions from the model. In what follows, we detail the challenges of building a pipeline for clinical data and give an overview of the key components of such a pipeline.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image198.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '### Ophthalmology\n', '\n', '[Devin Coldewey (2020, TechCrunch)](https://www.google.com/url?q=https://techcrunch.com/2020/04/27/google-medical-researchers-humbled-when-ai-screening-tool-falls-short-in-real-life-testing/&sa=D&source=editors&ust=1717021441187371&usg=AOvVaw2dkCsNZAOSuQFjoK0rvMUi): ‚ÄúGoogle medical researchers humbled when AI screening tool falls short in real-life testing‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image7.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ But the study authors ([Beede et al. 2020](https://www.google.com/url?q=https://doi.org/10.1145/3313831.3376718&sa=D&source=editors&ust=1717021441187677&usg=AOvVaw3zX38b1E4J-BRf1zkYKYDB)) seemed clear-eyed in their evaluation of this premature and partial application of their AI system. As they put it:\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ $QUOTETOBEREPLACED$ *"When introducing new technologies, planners, policy makers, and technology designers did not account for the dynamic and emergent nature of issues arising in complex healthcare programs. The authors argue that attending to people‚Äîtheir motivations, values, professional identities, and the current norms and routines that shape their work‚Äîis vital when planning deployments."*\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The paper is well worth reading both as a primer in how AI tools are meant to work in clinical environments and what obstacles are faced ‚Äî both by the technology and those meant to adopt it.\n', '\n', '## Validation ‚Äústandards‚Äù\n', '\n', '[Kwong et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1001/jamanetworkopen.2023.35377&sa=D&source=editors&ust=1717021441188074&usg=AOvVaw0Gpfuc1QApG514cQGIvWqq): ‚ÄúAPPRAISE-AI Tool for Quantitative Evaluation of AI Studies for Clinical Decision Support‚Äù\n', '\n', '$QUOTETOBEREPLACED$ In this quality improvement study, the APPRAISE-AI tool was developed to evaluate the methodological and reporting quality of 28 clinical AI studies using a quantitative approach. APPRAISE-AI demonstrated strong interrater and intrarater reliability and correlated well with other validated measures of study quality across a variety of AI studies. This project was conducted in compliance with the Standards for Quality Improvement Reporting Excellence ([SQUIRE](https://www.google.com/url?q=http://www.equator-network.org/reporting-guidelines/squire/&sa=D&source=editors&ust=1717021441188300&usg=AOvVaw3n_eXGvAh-k0g4pHx3Z9H5)) reporting guideline.[14](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r14&sa=D&source=editors&ust=1717021441188430&usg=AOvVaw2-Eh32ms-6medUXYKhgUpi)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Although much of the initial excitement for these novel AI solutions has been centered around their performance, there has been **==**==growing attention toward ensuring the reproducibility, safety, and fairness of these applications.==**==**[1](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r1&sa=D&source=editors&ust=1717021441188713&usg=AOvVaw1WQERPN-6lHPtsbfapsuqW)\xa0Indeed, recent work[2](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r2&sa=D&source=editors&ust=1717021441188856&usg=AOvVaw2XM0JDY7-w8o9MfwjBze-h)\xa0has highlighted several methodological concerns within the existing clinical AI literature, including ****poor adherence to conventional reporting guidelines****, inadequate sample size (ie, low number of events per variable),****no external validation****, limited assessment of ****calibration****, and bias.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ These concerns have prompted the development of ****several reporting guidelines****\xa0along the AI pathway, including MI-CLAIM, TRIPOD-AI, and STARD-AI for model development[3](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r3&sa=D&source=editors&ust=1717021441189263&usg=AOvVaw30cLUa-jRC2KaMHTKdQWjE)-[5](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r3&sa=D&source=editors&ust=1717021441189409&usg=AOvVaw0y5ymAMspmndetlwjRMuXA); DECIDE-AI for model evaluation[6](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r6&sa=D&source=editors&ust=1717021441189550&usg=AOvVaw12B9Wyz-ri8lrarYdRCdmp); and CONSORT-AI and SPIRIT-AI for clinical trials evaluation.[7](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r7&sa=D&source=editors&ust=1717021441189712&usg=AOvVaw23fyrRfWvWSa0ZWMnvzmLL),[8](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r8&sa=D&source=editors&ust=1717021441189849&usg=AOvVaw3DfjSVPXGpjFSpY1kYBvMS)\xa0Other reporting guidelines have also been adopted within various clinical domains, including cardiology (PRIME),[9](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r9&sa=D&source=editors&ust=1717021441189981&usg=AOvVaw3ZrS5ZVIfrv_8QP2o7f2tH)\xa0dentistry,[10](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r10&sa=D&source=editors&ust=1717021441190115&usg=AOvVaw1lFT97OLqQj4la7-KXUzmd)\xa0medical imaging (Radiomics Quality Score),[11](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r11&sa=D&source=editors&ust=1717021441190248&usg=AOvVaw2AhuYFoC9dDzIyQwvk26pm)\xa0****ophthalmology,****[12](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r12&sa=D&source=editors&ust=1717021441190418&usg=AOvVaw3vvJ_V1FjPxHnnS4oueGeX)********and urology (STREAM-URO).[13](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r13&sa=D&source=editors&ust=1717021441190618&usg=AOvVaw11SPFQEbomKbmWu0u6HT4z)\xa0These guidelines are valuable in ensuring transparency, reproducibility, and comparability in AI research by providing a list of minimum reporting items for AI studies. However, they nevertheless****do not provide a means of quantifying the overall quality of clinical AI research****, which necessitates evaluating methodological soundness, appropriateness to clinical targets, and more. This lack of a quantitative assessment tool makes it **==**==difficult to evaluate the robustness of AI models and their readiness for clinical use==**==**, particularly when comparing 2 models addressing the same clinical question.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Methods to address class imbalance were excluded because recent simulation studies have shown that ****imbalance correction may worsen model calibration****despite no clear improvement in discrimination.[17](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r17&sa=D&source=editors&ust=1717021441191059&usg=AOvVaw3kGbgEpQ5EKQp5ALgYL_AO)\xa0\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Although there is ****no universally accepted method for determining minimum sample size****\xa0for AI model development and validation,[19](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r19&sa=D&source=editors&ust=1717021441191358&usg=AOvVaw2gfHbmFHIn3xI9yXwysnPc)\xa0prior simulation studies have shown that **AI models may require "at least 10 events per variable"**[20](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r20&sa=D&source=editors&ust=1717021441191520&usg=AOvVaw2E9Wt72-kYFaDfepSMXpCK)\xa0to achieve stable performance (item 9).\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image185.png)\n', '\n', '$QUOTETOBEREPLACED$ Several ****limitations****\xa0merit discussion. Although the construct validity of the APPRAISE-AI tool was successfully demonstrated using a previously published systematic review of sepsis AI models,[26](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r26&sa=D&source=editors&ust=1717021441191860&usg=AOvVaw1uSvqbxZAEnsrdWHkRM9HG)\xa0a considerable proportion of those studies (36%) used the Medical Information Mart for Intensive Care database. As such, the ****variability of data quality domain scores may have been limited****. Therefore, use of the APPRAISE-AI tool in larger systematic reviews with more diverse data sets may yield a wider range of quality. Second, ****study citation rates****\xa0may not be a reliable measure of quality; however, we attempted to mitigate this limitation by excluding self-citations. Furthermore, APPRAISE-AI was well-correlated with other validated measures of study quality, such as QUADAS-2 and TRIPOD. Third,**********==**==this iteration of APPRAISE-AI is based on current best practices in AI==**==**.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ However, as AI methods continue to evolve at a rapid pace, this tool may need to be updated to reflect these advancements. For example, ****model explainability****\xa0remains a highly controversial topic ****among clinical and AI experts****, with no universally accepted method for providing robust explanations for individual-level predictions.[33](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r33&sa=D&source=editors&ust=1717021441192346&usg=AOvVaw0IoUtm_pCEqx2UNuFUV8WW)\xa0Similarly, there is ****no clear consensus on the best strategy to incorporate algorithmic fairness considerations****[34](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r34&sa=D&source=editors&ust=1717021441192545&usg=AOvVaw0nT7tg_H8kTJdNhXZipBOE),[35](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r35&sa=D&source=editors&ust=1717021441192676&usg=AOvVaw0D3aYg31mPudauFoRvA6IG); therefore, APPRAISE-AI does not assign scores to any particular approach. Instead, the emphasis is placed on conducting bias assessments (item 17) so that researchers can examine the efficacy of their fairness strategies, regardless of the approach used.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ It must be emphasized that APPRAISE-AI, like other reporting guidelines, **==**==cannot replace clinical and methodological expertise==**==**. For example, even if a study uses an objective, well-captured ground truth (ie, the highest assigned score for item 6, quality of ground truth), it may not be appropriate for the specific clinical problem. In addition, even the performance of a very high quality AI model may degrade over time or when applied to a foreign setting owing to ****dataset and concept drift.****[36](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r36&sa=D&source=editors&ust=1717021441193030&usg=AOvVaw1JWuFh2bKRkrsIOPT8npn6),[37](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r37&sa=D&source=editors&ust=1717021441193163&usg=AOvVaw0h-MMNwOHwInhD233vAv-L)\xa0This issue has been exemplified by the ****Epic Sepsis Model, which substantially underperformed on external validation****.[38](https://www.google.com/url?q=https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2809841%23zoi231016r38&sa=D&source=editors&ust=1717021441193341&usg=AOvVaw3lGKF23OJKYygy13Tdduo6)\xa0Another consideration is that APPRAISE-AI is not intended to evaluate feasibility and other ethical considerations that are essential to clinical implementation, such as ease of use, interoperability, and privacy concerns. Furthermore, APPRAISE-AI is ****primarily intended for AI research focused on clinical decision support****\xa0and may be less applicable for other types of studies, such as ****causal inference****.\n', '\n', '## Clinical Trials\n', '\n', '[Chen et al. (2024)](https://www.google.com/url?q=https://arxiv.org/pdf/2401.03482.pdf&sa=D&source=editors&ust=1717021441193755&usg=AOvVaw1THSgPDZSaEvLkk6xlNPzX): ‚ÄúUncertainty Quantification on Clinical Trial Outcome Prediction‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Quantification into clinical trial outcome predictions. Our main goal is to enhance the model‚Äôs ability to discern nuanced differences, thereby significantly improving its overall performance. We have adopted a [selective classification](https://www.google.com/url?q=https://docs.google.com/document/d/1wwCXhAX-b8fs3qSd1lxHVsO6irK35i592lFgyW2iSGU/edit%23heading%3Dh.cksp9gwaekoo&sa=D&source=editors&ust=1717021441194100&usg=AOvVaw0nrePOhaSz5XAWNLCWuobj)**==**==approach==**==**\xa0to fulfill our objective, integrating it seamlessly with the ****Hierarchical Interaction Network (HINT)****, which is at the forefront of clinical trial prediction modeling. Selective classification, encompassing a spectrum of methods for uncertainty quantification, empowers the model to withhold decision-making in the face of samples marked by ambiguity or low confidence, thereby amplifying the accuracy of predictions for the instances it chooses to classify. A series of comprehensive experiments demonstrate that incorporating selective classification into clinical trial predictions markedly enhances the model‚Äôs performance.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image55.png)\n', '\n', '[Fatemeh Haghighi et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.media.2024.103086&sa=D&source=editors&ust=1717021441194480&usg=AOvVaw1BpftTksqdAICnGwsAI5tG): ‚ÄúSelf-supervised learning for medical image analysis: Discriminative, restorative, or adversarial?‚Äù [https://github.com/JLiangLab/DiRA](https://www.google.com/url?q=https://github.com/JLiangLab/DiRA&sa=D&source=editors&ust=1717021441194599&usg=AOvVaw1IL99q2rY6BcxrteQ7w_FK)\xa0\n', '\n', '$QUOTETOBEREPLACED$ ****Discriminative, restorative, and adversarial learning****\xa0have proven beneficial for self-supervised learning schemes in computer vision and medical imaging. Existing efforts, however, fail to capitalize on the potentially synergistic effects these methods may offer in a ****ternary setup****, which, we envision can significantly benefit deep semantic representation learning. Towards this end, we developed ****DiRA****, the first framework that **==**==unites discriminative, restorative, and adversarial learning in a unified manner==**==**\xa0to collaboratively glean complementary visual information from unlabeled medical images for fine-grained semantic representation learning. Our extensive experiments demonstrate that DiRA: (1) encourages collaborative learning among three learning ingredients, **==**==resulting in more generalizable representation across organs, diseases, and modalities==**==**; (2) outperforms fully supervised ImageNet models and ****increases robustness******==**==in small data regimes==**==**, reducing annotation cost across multiple medical imaging applications; (3) learns fine-grained semantic representation, facilitating accurate lesion localization with only image-level annotation; (4) improves reusability of low/mid-level features; and (5) enhances restorative self-supervised approaches, revealing that DiRA is a general framework for united representation learning.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image121.png)\n', '\n', '## Feedback & Continuous Model Improvement\n', '\n', '[Barker et al. (2023)](https://www.google.com/url?q=https://arxiv.org/abs/2307.15475&sa=D&source=editors&ust=1717021441195162&usg=AOvVaw26QzeAy5mYqZQm0oxzxh-_): ‚ÄúFeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Even though machine learning (ML) pipelines affect an increasing array of stakeholders, there is**==**==little work on how input from stakeholders is recorded and incorporated==**==**. We propose FeedbackLogs, addenda to existing documentation of ML pipelines, to **==**==track the input of multiple stakeholders==**==**. Each log records important details about the feedback collection process, the feedback itself, and how the feedback is used to update the ML pipeline. In this paper, we introduce and formalise a process for collecting a ****FeedbackLog****. We also provide concrete use cases where FeedbackLogs can be employed as evidence for **==**==algorithmic auditing and as a tool to record updates based on stakeholder feedback==**==**.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Stakeholders, who interact with or are affected by machine learning (ML) models, should be involved in the model development process [2, 22, 27]. Their unique perspectives, however, ****may not be adequately accounted for by practitioners****, who are responsible for developing and deploying models (e.g., ML engineers, data scientists, UX researchers) [16]. We notice a gap in the existing literature around documenting how stakeholder input was collected and incorporated in the ML pipeline, which we define as a model‚Äôs end-to-end lifecycle, from data collection to model development to system deployment and ongoing usage.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image166.png)\n', '\n', '$QUOTETOBEREPLACED$ We propose a template-like design for FeedbackLogs with ****three distinct components****\xa0(shown in Figure 2): a starting point, one or more records, and a final summary.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image171.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ****Image Recognition: This FeedbackLog (Figure 4)****shows records that track non-technical, ecosystem updates as well as technical, model updates. In this case, ****two updates****\xa0(to the ****parameter space****and ****dataset****) needed to be used simultaneously since no individual update was sufficient to meet the metric requirements. However, we note that individual updates are still tracked. This FeedbackLog contains a final summary, as the updates per the second record satisfy specified metrics.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image58.png)\n', '\n', '## ‚ÄúInnovation models‚Äù\n', '\n', '[Norman et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1186/s13643-022-02106-z&sa=D&source=editors&ust=1717021441196329&usg=AOvVaw3N-xbMJiu9lKpAp2VRxXPE): ‚ÄúRapid evidence synthesis to enable innovation and adoption in health and social care‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The rapid identification and adoption of ****effective innovations****\xa0in healthcare is a known challenge. The strongest evidence base for innovations can be provided by ****evidence synthesis****, but this is frequently a lengthy process and even rapid versions of this can be time-consuming and complex. In the UK, the Accelerated Access Review and Academic Health Science Network (AHSN) have provided the impetus to develop a consistently rapid process to support the identification and adoption of high-value innovations in the English NHS.\n', '\n', '[Salisbury et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00922-8&sa=D&source=editors&ust=1717021441196736&usg=AOvVaw0hX0r_leoN7In3DCp_D0jy): ‚ÄúDigital Fellowships: Inspiring use of contemporary technologies in applied healthcare‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Here, we examine the ****role and impact of digital fellowships****\xa0in facilitating digital transformation in healthcare systems. Digital fellowships are structured educational programmes ****designed to equip healthcare professionals with advanced digital skills****. Focusing on UK-based initiatives like the ****Topol Digital Fellowship****\xa0and the ****Fellowship in Clinical AI****, we explore their efforts to prepare healthcare leaders for digital and AI adoption. Each fellowship programme provides participants with hands-on experience in digital healthcare projects and **==**==fosters interdisciplinary collaboration and post-fellowship support==**==**. We discuss how these fellowships contribute to staff retention by diversifying professional experiences and opportunities. We call for increased collaborations between universities, industry, and professional bodies to ****integrate lessons from digital fellowships into relevant curricula****, acknowledging that digital fellowships are just one piece of the puzzle in bridging the digital skills gap in the healthcare workforce.\n', '\n', '[Christopher Gyldenk√¶rne et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1016/j.ijhcs.2023.103162&sa=D&source=editors&ust=1717021441197188&usg=AOvVaw2aH8H5UH2LlyzxIf4JMzQT): ‚ÄúInnovation tactics for implementing an ML application in healthcare: A long and winding road‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Artificial intelligence techniques, including machine learning (ML), have shown remarkable test results over the past decade but struggled with the transfer to practical application. The present study applies action research to **==**==investigate this last stage of a project to implement an ML algorithm for predicting no-shows at a Danish hospital.==**==**\xa0We approach the implementation of the no-show algorithm as an innovation process and****identify 14 tactics****\xa0that were employed to provide the innovation necessary at the implementation stage. The tactics****span three analytic levels****\xa0‚Äì ****organization, project, and practice****\xa0‚Äì and alternate between efforts to train the algorithm and to establish trust in its predictions. These efforts are interdependent, highly sociotechnical, and hence****blur the boundary between technical development and organizational implementation****. They also show the intricacies involved in innovating during ML implementation. Despite sustained support at the organization level, the ****implementation of the no-show algorithm at the practice level remained unsettled****.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image96.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image11.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image67.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image69.png)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '## Business models and startups\n', '\n', '[AI Strategies That Offer a Sustainable Competitive Advantage: Principles You Should Follow](https://www.google.com/url?q=https://pixelscientia.lt.acemlna.com/Prod/link-tracker?redirectUrl%3DaHR0cHMlM0ElMkYlMkZ3d3cuc2hlbHB1ay5jb20lMkZwb3N0JTJGYWktc3RyYXRlZ2llcy10aGF0LW9mZmVyLWEtc3VzdGFpbmFibGUtY29tcGV0aXRpdmUtYWR2YW50YWdlLXByaW5jaXBsZXMteW91LXNob3VsZC1mb2xsb3clM0Z1dG1fc291cmNlJTNEQWN0aXZlQ2FtcGFpZ24lMjZ1dG1fbWVkaXVtJTNEZW1haWwlMjZ1dG1fY29udGVudCUzRE9uZSUyQlllYXIlMkJvZiUyQlBvZGNhc3RpbmclMjUyQyUyQkRpc3RyaWJ1dGlvbiUyQlNoaWZ0cyUyNTJDJTJCQmFja2dyb3VuZCUyQkJpYXMlMjUyQyUyQmFuZCUyQk1vcmUlMjZ1dG1fY2FtcGFpZ24lM0RDb21wdXRlciUyQlZpc2lvbiUyQkluc2lnaHRzJTJCNzA%3D%26sig%3D81sDqvjLhH6WjoiwpXyvwSVVzmvS2edSs6zhQVAcy1xJ%26iat%3D1698753421%26a%3D%257C%257C1001257108%257C%257C%26account%3Dpixelscientia%252Eactivehosted%252Ecom%26email%3D14iblJR8nD0m%252FafnJUTCQJOusOLUpYe3EeoNrtEwxfWdf9ZJbFPJcxc%253D%253AshKoF1%252BfYPfGHZ17sVUCEKvQvEbIATZ8%26s%3D909140abca5115d82e7335ba00b85437%26i%3D127A139A2A1601&sa=D&source=editors&ust=1717021441198316&usg=AOvVaw1pblcec3c8JY2lICjO_6F6)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image15.png)\n', '\n', '[Kulkov (2021)](https://www.google.com/url?q=http://dx.doi.org/10.1108/IJEBR-04-2021-0304&sa=D&source=editors&ust=1717021441198630&usg=AOvVaw2m-eqdlK7uelzU2r05iJv8): ‚ÄúNext-generation business models for artificial intelligence start-ups in the healthcare industry‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image46.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image156.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image186.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image108.png)\n', '\n', '### Founding team and advisors\n', '\n', '[Lunden (2023)](https://www.google.com/url?q=https://techcrunch.com/2023/09/20/corti-an-ai-co-pilot-for-healthcare-clinicians-raises-60m/?guccounter%3D1%26guce_referrer%3DaHR0cHM6Ly93d3cubGlua2VkaW4uY29tLw%26guce_referrer_sig%3DAQAAACop9bMWbQoSjSMxZkxPQ5-E9ODHLs84xlluQfcaYMNjuT0wJdl9kqEHP7jjDzGrxE6e0Pqejbe5uQRW7opHS20Od6XE--dV0bd3qPATTFKyOeuE6jFEzFyUs17-0sVSXqgaJfrjOZLnXlFHrkvKpYtOVFtKSXPwCBOMc8RdIj5v&sa=D&source=editors&ust=1717021441199213&usg=AOvVaw13nTesyLL9qX1KC44iMdO9): ‚ÄúCorti, an AI ‚Äòco-pilot‚Äô for healthcare clinicians, raises $60M‚Äù\n', '\n', '$QUOTETOBEREPLACED$ a Copenhagen startup called [Corti](https://www.google.com/url?q=https://www.corti.ai/&sa=D&source=editors&ust=1717021441199436&usg=AOvVaw0c0WUfA0Wv0usx6RmvDaif)\xa0has raised $60 million to expand its contribution to the field: an AI assistant designed to support healthcare clinicians with patient assessments in real time. Corti describes its service as an ‚ÄúAI co-pilot‚Äù for healthcare.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image42.png)\n', '\n', '## Future of Healthcare\n', '\n', '[Wang et al. (2022)](https://www.google.com/url?q=https://doi.org/10.1038/s42256-022-00549-6&sa=D&source=editors&ust=1717021441199828&usg=AOvVaw2gz0NOhMZlr00bTc_SF1yR): ‚ÄúDevelopment of metaverse for intelligent healthcare‚Äù\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image195.png)\n', '\n', '### Clinical coding\n', '\n', '[Kaushik P. Venkatesh et al. (2023)](https://www.google.com/url?q=https://doi.org/10.1038/s41746-023-00768-0&sa=D&source=editors&ust=1717021441200127&usg=AOvVaw3H1ZPI132hIBqXmEDkB801): ‚ÄúAutomating the overburdened clinical coding system: challenges and next steps‚Äù\n', '\n', '$QUOTETOBEREPLACED$ Artificial intelligence (AI) and natural language processing (NLP) have found a highly promising application****in automated clinical coding (ACC)****, an innovation that will have profound impacts on the clinical coding industry, **==**==billing and revenue management, and potentially clinical care itself==**==**. Dong et al. recently analyzed the technical challenges of ACC and proposed future directions. Primary challenges for ACC exist at the technological and implementation levels; clinical documents are redundant and complex, code sets like the ****ICD-10****\xa0are rapidly evolving, training sets are not comprehensive of codes, and ****ACC models have yet to fully capture the logic and rules of coding decisions****. Next steps include interdisciplinary collaboration with clinical coders, accessibility and transparency of datasets, and tailoring models to specific use cases.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '# Appendix: Unsorted\n', '\n', '[Nasarian et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.inffus.2024.102412&sa=D&source=editors&ust=1717021441200683&usg=AOvVaw3JyzvGEePHXY28zktsQWt3): ‚ÄúDesigning Interpretable ML System to Enhance Trust in Healthcare: A Systematic Review to Proposed Responsible Clinician-AI-Collaboration Framework‚Äù\n', '\n', '[Tracey A. Brereton et al. (2024)](https://www.google.com/url?q=https://doi.org/10.1016/j.mcpdig.2024.03.008&sa=D&source=editors&ust=1717021441200891&usg=AOvVaw2JmZc74bwvMCnTSY30HUqf): ‚ÄúAImedReport: A Prototype Tool to Facilitate Research Reporting and Translation of AI Technologies in Health Care‚Äù\n', '\n', '[Fabio A. Thiers and Zach Harned (2024)](https://www.google.com/url?q=https://www.researchgate.net/profile/Fabio-Thiers/publication/379562179_The_Emerging_Role_of_ISO_42001_Certification_in_Fostering_the_Deployment_of_Responsible_Generative_AI_Healthcare_Solutions/links/660eb6e3390c214cfd35ee01/The-Emerging-Role-of-ISO-42001-Certification-in-Fostering-the-Deployment-of-Responsible-Generative-AI-Healthcare-Solutions.pdf&sa=D&source=editors&ust=1717021441201225&usg=AOvVaw24syIcC41e3k51igl53dZ8): ‚ÄúThe Emerging Role of ISO 42001 Certification in Fostering the Deployment of Responsible Generative AI Healthcare Solutions‚Äù\n', '\n', '$QUOTETOBEREPLACED$ The growing excitement about the potential positive impact of generative AI (GenAI) solutions in healthcare has been tempered by uncertainty on how to ensure that such solutions are deployed safely and effectively. A core issue is that the current product-centric regulatory oversight model does not apply well to a technology that adapts to the operating environment and becomes enmeshed with medical practice in a non-deterministic manner. This difficulty has led to the development of alternate approaches to foster the responsible deployment of GenAI solutions that are focused on the organizations developing and using the technology, as they are uniquely positioned to prevent and quickly address issues as they occur. One emerging approach is via the ****certification with the ISO 42001 standard****, which defines the **==**==structure for auditable AI Management Systems (AIMS) in organizations developing and/or deploying AI solutions==**==**. The process of ISO 42001 certification can enable healthcare organizations to build adaptive and auditable AIMS that mitigate risks while supporting the deployment of trustworthy AI. The ****wide adoption of ISO 42001 certification by healthcare organizations would allow for the utilization of beneficial GenAI solutions while potentially facilitating the performance of oversight functions by regulators and payers****. This article introduces the ISO 42001 implementation process in healthcare organizations and describes the next steps in the operationalization of this new GenAI risk mitigation approach.\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image57.png)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image127.png)\n', '\n', 'Every year, I curate [a compilation of the top 100 digital health and AI companies](https://www.google.com/url?q=https://medicalfuturist.com/5-insights-of-the-medical-futurists-100-digital-health-and-ai-companies-of-2024&sa=D&source=editors&ust=1717021441201912&usg=AOvVaw0XTj17TOVU4H1PsDoni6O_)\xa0that I believe deserve your attention throughout the upcoming year. The infographic presented here marks the latest iteration, [showcasing the 2024 selection](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7157714540858609665/?updateEntityUrn%3Durn%253Ali%253Afs_updateV2%253A%2528urn%253Ali%253Aactivity%253A7157714540858609665%252CFEED_DETAIL%252CEMPTY%252CDEFAULT%252Cfalse%2529&sa=D&source=editors&ust=1717021441202133&usg=AOvVaw0cW5_nzWpyNITAfnrqRxGc).\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image35.png)\n', '\n', '[Now I have a Notion tracking 150 health leaders, 12 irl/online communities & 52 Newsletters/Substacks](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7158132166760034304/?updateEntityUrn%3Durn%253Ali%253Afs_updateV2%253A%2528urn%253Ali%253Aactivity%253A7158132166760034304%252CFEED_DETAIL%252CEMPTY%252CDEFAULT%252Cfalse%2529&sa=D&source=editors&ust=1717021441202536&usg=AOvVaw364D_RbqIrLHVjD-5CsZXM)\xa0\n', '\n', '$QUOTETOBEREPLACED$ Starting with newsletters/sub-stacks (no order):\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Out-of-Pocket - [Nikhil Krishnan](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAnKMCQB6_x8N7b7MrhpYRW9hSd8_asG5NI&sa=D&source=editors&ust=1717021441202849&usg=AOvVaw0LUNbLMK5-tahyumesqgnx)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Health API Guy - [Brendan Keeler](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAPkL9sB4lo5Yq0uDubv8utDDC3_gQq7qQY&sa=D&source=editors&ust=1717021441203057&usg=AOvVaw3lIHWcu7oEQKz4yjj8pszp)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Healthcare Andy - [Andy Mychkovsky](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAVJpjgBDjOqYbZvbeh20rfsprp39F7xjvg&sa=D&source=editors&ust=1717021441203271&usg=AOvVaw3_PD1KvCYdb-7xito67Jf7)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Healthcare Breakdown - [Preston Alexander](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAA0B3YEBWxAHA16kpWumvhnpowg3j8GRn4Q&sa=D&source=editors&ust=1717021441203485&usg=AOvVaw14pxc_5MQJBfDQPA7Ag8rt)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Health Populi - [Jane Sarasohn-Kahn](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAChIVQB0rQM1nC-7yAISEWboA0QUrdSCvE&sa=D&source=editors&ust=1717021441203750&usg=AOvVaw3vZMwsOQbbPzaKD-eiPp2p)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Hospitology - [Blake Madden](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAA4DZIgB9WIvzMU_ptJ2JEUehaX8LTPPXG8&sa=D&source=editors&ust=1717021441203960&usg=AOvVaw3PpPCOStZh9-HZE_MTn2Vj)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Health Policy Nerd - James Lekkie\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Health 3.0 - [Maud P.](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAABddbYBWfL86hl-cZuiCtQCff2RiSsZ4sw&sa=D&source=editors&ust=1717021441204383&usg=AOvVaw2I0kD2YSsntPZcQSR-BS5S)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ The Case Load - [Steven Hardgrove](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAUXZsMBerxnyWRpsZ75fZli95xhql5Frik&sa=D&source=editors&ust=1717021441204623&usg=AOvVaw37wUtyYabQuqgeOb3aeJ_B)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ What the Health? - [Emily Casey](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAABbEz4kBk5RvaY1umcNtdrpVaWsdQV-N2Po&sa=D&source=editors&ust=1717021441204845&usg=AOvVaw0HKui901T7havXWI_x5mml)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ HealthTech Pigeon - [Dr. James Somauroo](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAio-fEBX5IxAE6A97MO9i2Uz6N3ud0cFfE&sa=D&source=editors&ust=1717021441205060&usg=AOvVaw08FkFCBStjxPy5ussXeRDA)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ DVS - [David Van Sickle](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAESvLQBt9bnKSYlcgaDobxQ_6Dt8UL0saw&sa=D&source=editors&ust=1717021441205277&usg=AOvVaw2NtPX6Kj9L3j2QfaSEcu66)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Vital Signs - [Jacob Effron](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAAMCxmABzoEsYTMTOizAOOVGOGinmD9eJ6g&sa=D&source=editors&ust=1717021441205485&usg=AOvVaw2yrykHQEvXplkLB1FFYJ6M)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Acute Condition - [Olivia Webb](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAABZFOK0BPIGDjBUPaxAeU0PNNERtotpIfM8&sa=D&source=editors&ust=1717021441205692&usg=AOvVaw1sftJeo4snowBw9zQjE2tA)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', "$QUOTETOBEREPLACED$ Clinician Creative - [Michael R. O'Brien, MD](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAC7VJwwBUN06RzTeTfx85nDyTfPt74Etu_M&sa=D&source=editors&ust=1717021441205895&usg=AOvVaw25oFiF3ASXp64e4iLpSVaF)\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Getting Clinical - [Will M.](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAB6RlNoBSDGbDljo0zK4nMiZ3h46XGL1alU&sa=D&source=editors&ust=1717021441206114&usg=AOvVaw1A2vkU04LEoSihCYjEetn9)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Hey HealthTech - [Lauren Curtis, PharmD](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAABpucDwBPYJ-kPfTWAkatQgmdMKmLlLjUUE&sa=D&source=editors&ust=1717021441206353&usg=AOvVaw3bUrq8F3SFrzweJbanAADS)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Two Docs and a Stack - [Arpan Parikh, MD, MBA, FAPA](https://www.google.com/url?q=https://www.linkedin.com/in/ACoAAB7rvEwBl7EJgyqXoSjlN4oCPbvShc3bc08&sa=D&source=editors&ust=1717021441206575&usg=AOvVaw0dvS5uSMWHKmUGiI9gHV5J)\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', '$QUOTETOBEREPLACED$ Grateful to these folks üëÜ for sharing their knowledge üôèüèΩ\n', '\n', '$QUOTETOBEREPLACED$\n', '\n', 'This paper focuses on the [transformative impact of AI in health systems](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7155786299050729472/?updateEntityUrn%3Durn%253Ali%253Afs_updateV2%253A%2528urn%253Ali%253Aactivity%253A7155786299050729472%252CFEED_DETAIL%252CEMPTY%252CDEFAULT%252Cfalse%2529&sa=D&source=editors&ust=1717021441206903&usg=AOvVaw33kqxDa94gOxPPqQxAblTH)\xa0(OECD). It outlines the potential of AI to make health systems more resilient, sustainable, equitable, and person-centered, while also discussing the associated opportunities, risks, and barriers.\n', '\n', '[How To Conduct Due Diligence On SaMD And AIaMD Acquisitions](https://www.google.com/url?q=https://www.hardianhealth.com/insights/how-to-conduct-due-diligence-on-samd-and-aiamd-acquisitions&sa=D&source=editors&ust=1717021441207142&usg=AOvVaw26FHzPEP5s2Kb6_OqkT3z9)\n', '\n', "$QUOTETOBEREPLACED$ 2024 looks to be a year of consolidation in the health tech market. As private equity analysts sharpen their pencils, it's a good time to refresh some key clinical and regulatory due diligence points when targeting **==**==software and AI medical device (SaMD and AIaMD)==**==**\xa0companies for mergers and acquisitions. In our experience, here are the most common blindspots to look out for.\n", '\n', '$QUOTETOBEREPLACED$\n', '\n', '[Beyond off-the-shelf Machine Learning: case for clinician-in-the-loop](https://www.google.com/url?q=https://www.linkedin.com/feed/update/urn:li:activity:7156254433922756608/?updateEntityUrn%3Durn%253Ali%253Afs_updateV2%253A%2528urn%253Ali%253Aactivity%253A7156254433922756608%252CFEED_DETAIL%252CEMPTY%252CDEFAULT%252Cfalse%2529&sa=D&source=editors&ust=1717021441207508&usg=AOvVaw11Rh1ytRbYgLj56tA_6XR2)\n', '\n', '$QUOTETOBEREPLACED$ ![](HTML%20import/Attachments/image68.png)\n', '\n', '[[a]](#cmnt_ref1)1st generation mostly in this case refers to all sorts of "existing AI" things like classification, and what have you, instead of more "appified digital health"\n', '\n', '[[b]](#cmnt_ref2)Not maybe the best business model ever, but as a medical concept makes sense. To provide an array of tests that are able to distinguish normals from pathological, and do differential diagnosis on the pathologies as well\n', '\n', '[[c]](#cmnt_ref3)As a reminder, manufacturers of device software must create and maintain software-related documentation in\n', '\n', 'accordance with the requirements of the Quality System (QS) Regulation (21 CFR 820.30 Subpart C ‚Äì Design\n', '\n', 'Controls of the Quality System Regulation).\n', '\n', '[[d]](#cmnt_ref4)One example approach for providing some of the identified software specifics is by providing a Software Bill of\n', '\n', 'Materials (SBOM) that lists and provide details on software components including, but not limited to, commercial,\n', '\n', 'open source, OTS, and manufacturer-developed software components. For some devices, information related to an\n', '\n', 'SBOM may be required part of a premarket submission\n', '\n', '[[e]](#cmnt_ref5)Each manufacturer shall establish and maintain a DHF for each type of device. 21 CFR 820.30(j). A DHF is a\n', '\n', 'compilation of records which describes the design history of a finished device. The DHF shall contain or reference\n', '\n', 'the records necessary to demonstrate that the design was developed in accordance with the approved design plan and\n', '\n', 'the requirements of 21 CFR 820. See 21 CFR 820.30(j).']